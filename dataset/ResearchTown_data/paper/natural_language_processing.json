{
  "3f1049c8-d113-451b-ac0c-54f6e563ba03": {
    "pk": "3f1049c8-d113-451b-ac0c-54f6e563ba03",
    "title": "Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation",
    "abstract": "We introduce LlamaGen, a new family of image generation models that apply original ``next-token prediction'' paradigm of large language models to visual generation domain. It is an affirmative answer to whether vanilla autoregressive models, e.g., Llama, without inductive biases on visual signals can achieve state-of-the-art image generation performance if scaling properly. We reexamine design spaces of image tokenizers, scalability properties of image generation models, and their training data quality. The outcome of this exploration consists of: (1) An image tokenizer with downsample ratio of 16, reconstruction quality of 0.94 rFID and codebook usage of 97% on ImageNet benchmark. (2) A series of class-conditional image generation models ranging from 111M to 3.1B parameters, achieving 2.18 FID on ImageNet 256x256 benchmarks, outperforming the popular diffusion models such as LDM, DiT. (3) A text-conditional image generation model with 775M parameters, from two-stage training on LAION-COCO and high aesthetics quality images, demonstrating competitive performance of visual quality and text alignment. (4) We verify the effectiveness of LLM serving frameworks in optimizing the inference speed of image generation models and achieve 326% - 414% speedup. We release all models and codes to facilitate open-source community of visual generation and multimodal foundation models.",
    "authors": [
      "Peize Sun",
      "Yi Jiang",
      "Shoufa Chen",
      "Shilong Zhang",
      "Bingyue Peng",
      "Ping Luo",
      "Zehuan Yuan"
    ],
    "url": "http://arxiv.org/abs/2406.06525v1",
    "timestamp": 1718042392,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "02590153-a8f0-4719-b644-c4c6382fd2fa": {
    "pk": "02590153-a8f0-4719-b644-c4c6382fd2fa",
    "title": "NaRCan: Natural Refined Canonical Image with Integration of Diffusion Prior for Video Editing",
    "abstract": "We propose a video editing framework, NaRCan, which integrates a hybrid deformation field and diffusion prior to generate high-quality natural canonical images to represent the input video. Our approach utilizes homography to model global motion and employs multi-layer perceptrons (MLPs) to capture local residual deformations, enhancing the model's ability to handle complex video dynamics. By introducing a diffusion prior from the early stages of training, our model ensures that the generated images retain a high-quality natural appearance, making the produced canonical images suitable for various downstream tasks in video editing, a capability not achieved by current canonical-based methods. Furthermore, we incorporate low-rank adaptation (LoRA) fine-tuning and introduce a noise and diffusion prior update scheduling technique that accelerates the training process by 14 times. Extensive experimental results show that our method outperforms existing approaches in various video editing tasks and produces coherent and high-quality edited video sequences. See our project page for video results at https://koi953215.github.io/NaRCan_page/.",
    "authors": [
      "Ting-Hsuan Chen",
      "Jiewen Chan",
      "Hau-Shiang Shiu",
      "Shih-Han Yen",
      "Chang-Han Yeh",
      "Yu-Lun Liu"
    ],
    "url": "http://arxiv.org/abs/2406.06523v1",
    "timestamp": 1718042386,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "2f364b34-95a2-4201-b2a5-4a72e7e33118": {
    "pk": "2f364b34-95a2-4201-b2a5-4a72e7e33118",
    "title": "Gas Fees on the Ethereum Blockchain: From Foundations to Derivatives Valuations",
    "abstract": "The gas fee, paid for inclusion in the blockchain, is analyzed in two parts. First, we consider how effort in terms of resources required to process and store a transaction turns into a gas limit, which, through a fee, comprised of the base and priority fee in the current version of Ethereum, is converted into the cost paid by the user. We hew closely to the Ethereum protocol to simplify the analysis and to constrain the design choices when considering multidimensional gas. Second, we assume that the gas price is given deus ex machina by a fractional Ornstein-Uhlenbeck process and evaluate various derivatives. These contracts can, for example, mitigate gas cost volatility. The ability to price and trade forwards besides the existing spot inclusion into the blockchain could be beneficial.",
    "authors": [
      "Bernhard K Meister",
      "Henry CW Price"
    ],
    "url": "http://arxiv.org/abs/2406.06524v1",
    "timestamp": 1718042386,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "q-fin.PM",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "72af1511-e92e-40ee-916d-163343bae39d": {
    "pk": "72af1511-e92e-40ee-916d-163343bae39d",
    "title": "PGSR: Planar-based Gaussian Splatting for Efficient and High-Fidelity Surface Reconstruction",
    "abstract": "Recently, 3D Gaussian Splatting (3DGS) has attracted widespread attention due to its high-quality rendering, and ultra-fast training and rendering speed. However, due to the unstructured and irregular nature of Gaussian point clouds, it is difficult to guarantee geometric reconstruction accuracy and multi-view consistency simply by relying on image reconstruction loss. Although many studies on surface reconstruction based on 3DGS have emerged recently, the quality of their meshes is generally unsatisfactory. To address this problem, we propose a fast planar-based Gaussian splatting reconstruction representation (PGSR) to achieve high-fidelity surface reconstruction while ensuring high-quality rendering. Specifically, we first introduce an unbiased depth rendering method, which directly renders the distance from the camera origin to the Gaussian plane and the corresponding normal map based on the Gaussian distribution of the point cloud, and divides the two to obtain the unbiased depth. We then introduce single-view geometric, multi-view photometric, and geometric regularization to preserve global geometric accuracy. We also propose a camera exposure compensation model to cope with scenes with large illumination variations. Experiments on indoor and outdoor scenes show that our method achieves fast training and rendering while maintaining high-fidelity rendering and geometric reconstruction, outperforming 3DGS-based and NeRF-based methods.",
    "authors": [
      "Danpeng Chen",
      "Hai Li",
      "Weicai Ye",
      "Yifan Wang",
      "Weijian Xie",
      "Shangjin Zhai",
      "Nan Wang",
      "Haomin Liu",
      "Hujun Bao",
      "Guofeng Zhang"
    ],
    "url": "http://arxiv.org/abs/2406.06521v1",
    "timestamp": 1718042341,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "ec4994d0-3cb4-4b4a-8da3-c9ce621486f6": {
    "pk": "ec4994d0-3cb4-4b4a-8da3-c9ce621486f6",
    "title": "UMBRELA: UMbrela is the (Open-Source Reproduction of the) Bing RELevance Assessor",
    "abstract": "Copious amounts of relevance judgments are necessary for the effective training and accurate evaluation of retrieval systems. Conventionally, these judgments are made by human assessors, rendering this process expensive and laborious. A recent study by Thomas et al. from Microsoft Bing suggested that large language models (LLMs) can accurately perform the relevance assessment task and provide human-quality judgments, but unfortunately their study did not yield any reusable software artifacts. Our work presents UMBRELA (a recursive acronym that stands for UMbrela is the Bing RELevance Assessor), an open-source toolkit that reproduces the results of Thomas et al. using OpenAI's GPT-4o model and adds more nuance to the original paper. Across Deep Learning Tracks from TREC 2019 to 2023, we find that LLM-derived relevance judgments correlate highly with rankings generated by effective multi-stage retrieval systems. Our toolkit is designed to be easily extensible and can be integrated into existing multi-stage retrieval and evaluation pipelines, offering researchers a valuable resource for studying retrieval evaluation methodologies. UMBRELA will be used in the TREC 2024 RAG Track to aid in relevance assessments, and we envision our toolkit becoming a foundation for further innovation in the field. UMBRELA is available at https://github.com/castorini/umbrela.",
    "authors": [
      "Shivani Upadhyay",
      "Ronak Pradeep",
      "Nandan Thakur",
      "Nick Craswell",
      "Jimmy Lin"
    ],
    "url": "http://arxiv.org/abs/2406.06519v1",
    "timestamp": 1718042309,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.IR",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "6d5028b9-bc0a-4a9a-bab9-98147757c934": {
    "pk": "6d5028b9-bc0a-4a9a-bab9-98147757c934",
    "title": "Repetition Threshold for Binary Automatic Sequences",
    "abstract": "The critical exponent of an infinite word $\\bf x$ is the supremum, over all finite nonempty factors $f$, of the exponent of $f$. In this note we show that for all integers $k\\geq 2,$ there is a binary infinite $k$-automatic sequence with critical exponent $\\leq 7/3$. The same conclusion holds for Fibonacci-automatic and Tribonacci-automatic sequences.",
    "authors": [
      "J. -P. Allouche",
      "N. Rampersad",
      "J. Shallit"
    ],
    "url": "http://arxiv.org/abs/2406.06513v1",
    "timestamp": 1718042008,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.CO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "86664a07-9739-4230-9dd9-2fde51eff0ca": {
    "pk": "86664a07-9739-4230-9dd9-2fde51eff0ca",
    "title": "Merlin: A Vision Language Foundation Model for 3D Computed Tomography",
    "abstract": "Over 85 million computed tomography (CT) scans are performed annually in the US, of which approximately one quarter focus on the abdomen. Given the current radiologist shortage, there is a large impetus to use artificial intelligence to alleviate the burden of interpreting these complex imaging studies. Prior state-of-the-art approaches for automated medical image interpretation leverage vision language models (VLMs). However, current medical VLMs are generally limited to 2D images and short reports, and do not leverage electronic health record (EHR) data for supervision. We introduce Merlin - a 3D VLM that we train using paired CT scans (6+ million images from 15,331 CTs), EHR diagnosis codes (1.8+ million codes), and radiology reports (6+ million tokens). We evaluate Merlin on 6 task types and 752 individual tasks. The non-adapted (off-the-shelf) tasks include zero-shot findings classification (31 findings), phenotype classification (692 phenotypes), and zero-shot cross-modal retrieval (image to findings and image to impressions), while model adapted tasks include 5-year disease prediction (6 diseases), radiology report generation, and 3D semantic segmentation (20 organs). We perform internal validation on a test set of 5,137 CTs, and external validation on 7,000 clinical CTs and on two public CT datasets (VerSe, TotalSegmentator). Beyond these clinically-relevant evaluations, we assess the efficacy of various network architectures and training strategies to depict that Merlin has favorable performance to existing task-specific baselines. We derive data scaling laws to empirically assess training data needs for requisite downstream task performance. Furthermore, unlike conventional VLMs that require hundreds of GPUs for training, we perform all training on a single GPU.",
    "authors": [
      "Louis Blankemeier",
      "Joseph Paul Cohen",
      "Ashwin Kumar",
      "Dave Van Veen",
      "Syed Jamal Safdar Gardezi",
      "Magdalini Paschali",
      "Zhihong Chen",
      "Jean-Benoit Delbrouck",
      "Eduardo Reis",
      "Cesar Truyts",
      "Christian Bluethgen",
      "Malte Engmann Kjeldskov Jensen",
      "Sophie Ostmeier",
      "Maya Varma",
      "Jeya Maria Jose Valanarasu",
      "Zhongnan Fang",
      "Zepeng Huo",
      "Zaid Nabulsi",
      "Diego Ardila",
      "Wei-Hung Weng",
      "Edson Amaro Junior",
      "Neera Ahuja",
      "Jason Fries",
      "Nigam H. Shah",
      "Andrew Johnston",
      "Robert D. Boutin",
      "Andrew Wentland",
      "Curtis P. Langlotz",
      "Jason Hom",
      "Sergios Gatidis",
      "Akshay S. Chaudhari"
    ],
    "url": "http://arxiv.org/abs/2406.06512v1",
    "timestamp": 1718041981,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "30e7ec8e-1bc8-4168-ad9b-f791aaf8abea": {
    "pk": "30e7ec8e-1bc8-4168-ad9b-f791aaf8abea",
    "title": "Most nearby young star clusters formed in three massive complexes",
    "abstract": "Efforts to unveil the structure of the local interstellar medium and its recent star formation history have spanned the past seventy years. Recent studies utilizing precise data from space astrometry missions have revealed nearby, newly formed star clusters with connected origins. Nonetheless, mapping young clusters across the entire sky back to their natal regions has been hindered by a lack of clusters with precise radial velocity data. Here we show that 155 out of 272 (57 percent) high-quality young clusters within one kiloparsec of the Sun arise from three distinct spatial volumes. This conclusion is based upon the analysis of data from the third Gaia release and other large-scale spectroscopic surveys. Currently dispersed throughout the Solar Neighborhood, their past positions over 30 Myr ago reveal that these families of clusters each formed in one of three compact, massive star-forming complexes. One of these families includes all of the young clusters near the Sun -- the Taurus and Sco-Cen star-forming complexes. We estimate that over 200 supernovae were produced from these families and argue that these clustered supernovae produced both the Local Bubble and the largest nearby supershell GSH 238+00+09, both of which are clearly visible in modern three-dimensional dust maps.",
    "authors": [
      "Cameren Swiggum",
      "Jo\u00e3o Alves",
      "Robert Benjamin",
      "Sebastian Ratzenb\u00f6ck",
      "N\u00faria Miret-Roig",
      "Josefa Gro\u00dfschedl",
      "Stefan Meingast",
      "Alyssa Goodman",
      "Ralf Konietzka",
      "Catherine Zucker",
      "Emily L. Hunt",
      "Sabine Reffert"
    ],
    "url": "http://arxiv.org/abs/2406.06510v1",
    "timestamp": 1718041816,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.GA",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f8a14285-bf36-42e3-8eb4-2755e2dd6d2b": {
    "pk": "f8a14285-bf36-42e3-8eb4-2755e2dd6d2b",
    "title": "Robust Distribution Learning with Local and Global Adversarial Corruptions",
    "abstract": "We consider learning in an adversarial environment, where an $\\varepsilon$-fraction of samples from a distribution $P$ are arbitrarily modified (*global* corruptions) and the remaining perturbations have average magnitude bounded by $\\rho$ (*local* corruptions). Given access to $n$ such corrupted samples, we seek a computationally efficient estimator $\\hat{P}_n$ that minimizes the Wasserstein distance $\\mathsf{W}_1(\\hat{P}_n,P)$. In fact, we attack the fine-grained task of minimizing $\\mathsf{W}_1(\\Pi_\\# \\hat{P}_n, \\Pi_\\# P)$ for all orthogonal projections $\\Pi \\in \\mathbb{R}^{d \\times d}$, with performance scaling with $\\mathrm{rank}(\\Pi) = k$. This allows us to account simultaneously for mean estimation ($k=1$), distribution estimation ($k=d$), as well as the settings interpolating between these two extremes. We characterize the optimal population-limit risk for this task and then develop an efficient finite-sample algorithm with error bounded by $\\sqrt{\\varepsilon k} + \\rho + d^{O(1)}\\tilde{O}(n^{-1/k})$ when $P$ has bounded moments of order $2+\\delta$, for constant $\\delta > 0$. For data distributions with bounded covariance, our finite-sample bounds match the minimax population-level optimum for large sample sizes. Our efficient procedure relies on a novel trace norm approximation of an ideal yet intractable 2-Wasserstein projection estimator. We apply this algorithm to robust stochastic optimization, and, in the process, uncover a new method for overcoming the curse of dimensionality in Wasserstein distributionally robust optimization.",
    "authors": [
      "Sloan Nietert",
      "Ziv Goldfeld",
      "Soroosh Shafiee"
    ],
    "url": "http://arxiv.org/abs/2406.06509v1",
    "timestamp": 1718041716,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c8e934d7-27cc-45c2-8c9f-f307364b404e": {
    "pk": "c8e934d7-27cc-45c2-8c9f-f307364b404e",
    "title": "Monkey See, Monkey Do: Harnessing Self-attention in Motion Diffusion for Zero-shot Motion Transfer",
    "abstract": "Given the remarkable results of motion synthesis with diffusion models, a natural question arises: how can we effectively leverage these models for motion editing? Existing diffusion-based motion editing methods overlook the profound potential of the prior embedded within the weights of pre-trained models, which enables manipulating the latent feature space; hence, they primarily center on handling the motion space. In this work, we explore the attention mechanism of pre-trained motion diffusion models. We uncover the roles and interactions of attention elements in capturing and representing intricate human motion patterns, and carefully integrate these elements to transfer a leader motion to a follower one while maintaining the nuanced characteristics of the follower, resulting in zero-shot motion transfer. Editing features associated with selected motions allows us to confront a challenge observed in prior motion diffusion approaches, which use general directives (e.g., text, music) for editing, ultimately failing to convey subtle nuances effectively. Our work is inspired by how a monkey closely imitates what it sees while maintaining its unique motion patterns; hence we call it Monkey See, Monkey Do, and dub it MoMo. Employing our technique enables accomplishing tasks such as synthesizing out-of-distribution motions, style transfer, and spatial editing. Furthermore, diffusion inversion is seldom employed for motions; as a result, editing efforts focus on generated motions, limiting the editability of real ones. MoMo harnesses motion inversion, extending its application to both real and generated motions. Experimental results show the advantage of our approach over the current art. In particular, unlike methods tailored for specific applications through training, our approach is applied at inference time, requiring no training. Our webpage is at https://monkeyseedocg.github.io.",
    "authors": [
      "Sigal Raab",
      "Inbar Gat",
      "Nathan Sala",
      "Guy Tevet",
      "Rotem Shalev-Arkushin",
      "Ohad Fried",
      "Amit H. Bermano",
      "Daniel Cohen-Or"
    ],
    "url": "http://arxiv.org/abs/2406.06508v1",
    "timestamp": 1718041634,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "16e8ca4c-11bb-431a-96bf-66f6bfc3f816": {
    "pk": "16e8ca4c-11bb-431a-96bf-66f6bfc3f816",
    "title": "Verification-Guided Shielding for Deep Reinforcement Learning",
    "abstract": "In recent years, Deep Reinforcement Learning (DRL) has emerged as an effective approach to solving real-world tasks. However, despite their successes, DRL-based policies suffer from poor reliability, which limits their deployment in safety-critical domains. As a result, various methods have been put forth to address this issue by providing formal safety guarantees. Two main approaches include shielding and verification. While shielding ensures the safe behavior of the policy by employing an external online component (i.e., a ``shield'') that overruns potentially dangerous actions, this approach has a significant computational cost as the shield must be invoked at runtime to validate every decision. On the other hand, verification is an offline process that can identify policies that are unsafe, prior to their deployment, yet, without providing alternative actions when such a policy is deemed unsafe. In this work, we present verification-guided shielding -- a novel approach that bridges the DRL reliability gap by integrating these two methods. Our approach combines both formal and probabilistic verification tools to partition the input domain into safe and unsafe regions. In addition, we employ clustering and symbolic representation procedures that compress the unsafe regions into a compact representation. This, in turn, allows to temporarily activate the shield solely in (potentially) unsafe regions, in an efficient manner. Our novel approach allows to significantly reduce runtime overhead while still preserving formal safety guarantees. We extensively evaluate our approach on two benchmarks from the robotic navigation domain, as well as provide an in-depth analysis of its scalability and completeness.",
    "authors": [
      "Davide Corsi",
      "Guy Amir",
      "Andoni Rodriguez",
      "Cesar Sanchez",
      "Guy Katz",
      "Roy Fox"
    ],
    "url": "http://arxiv.org/abs/2406.06507v1",
    "timestamp": 1718041499,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c975e906-d1af-43c3-b184-ae870aa4c7ad": {
    "pk": "c975e906-d1af-43c3-b184-ae870aa4c7ad",
    "title": "NarrativeBridge: Enhancing Video Captioning with Causal-Temporal Narrative",
    "abstract": "Existing video captioning benchmarks and models lack coherent representations of causal-temporal narrative, which is sequences of events linked through cause and effect, unfolding over time and driven by characters or agents. This lack of narrative restricts models' ability to generate text descriptions that capture the causal and temporal dynamics inherent in video content. To address this gap, we propose NarrativeBridge, an approach comprising of: (1) a novel Causal-Temporal Narrative (CTN) captions benchmark generated using a large language model and few-shot prompting, explicitly encoding cause-effect temporal relationships in video descriptions, evaluated automatically to ensure caption quality and relevance; and (2) a dedicated Cause-Effect Network (CEN) architecture with separate encoders for capturing cause and effect dynamics independently, enabling effective learning and generation of captions with causal-temporal narrative. Extensive experiments demonstrate that CEN is more accurate in articulating the causal and temporal aspects of video content than the second best model (GIT): 17.88 and 17.44 CIDEr on the MSVD and MSR-VTT datasets, respectively. The proposed framework understands and generates nuanced text descriptions with intricate causal-temporal narrative structures present in videos, addressing a critical limitation in video captioning. For project details, visit https://narrativebridge.github.io/.",
    "authors": [
      "Asmar Nadeem",
      "Faegheh Sardari",
      "Robert Dawes",
      "Syed Sameed Husain",
      "Adrian Hilton",
      "Armin Mustafa"
    ],
    "url": "http://arxiv.org/abs/2406.06499v1",
    "timestamp": 1718040864,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "29c2feee-9e06-4ad0-93f1-1bd3cff21537": {
    "pk": "29c2feee-9e06-4ad0-93f1-1bd3cff21537",
    "title": "Direct Preference Optimization for Suppressing Hallucinated Prior Exams in Radiology Report Generation",
    "abstract": "Recent advances in generative vision-language models (VLMs) have exciting potential implications for AI in radiology, yet VLMs are also known to produce hallucinations, nonsensical text, and other unwanted behaviors that can waste clinicians' time and cause patient harm. Drawing on recent work on direct preference optimization (DPO), we propose a simple method for modifying the behavior of pretrained VLMs performing radiology report generation by suppressing unwanted types of generations. We apply our method to the prevention of hallucinations of prior exams, addressing a long-established problem behavior in models performing chest X-ray report generation. Across our experiments, we find that DPO fine-tuning achieves a 3.2-4.8x reduction in lines hallucinating prior exams while maintaining model performance on clinical accuracy metrics. Our work is, to the best of our knowledge, the first work to apply DPO to medical VLMs, providing a data- and compute- efficient way to suppress problem behaviors while maintaining overall clinical accuracy.",
    "authors": [
      "Oishi Banerjee",
      "Hong-Yu Zhou",
      "Subathra Adithan",
      "Stephen Kwak",
      "Kay Wu",
      "Pranav Rajpurkar"
    ],
    "url": "http://arxiv.org/abs/2406.06496v1",
    "timestamp": 1718040696,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "8642102c-66d5-4e91-ad5b-a56196c44d09": {
    "pk": "8642102c-66d5-4e91-ad5b-a56196c44d09",
    "title": "Scaling Continuous Latent Variable Models as Probabilistic Integral Circuits",
    "abstract": "Probabilistic integral circuits (PICs) have been recently introduced as probabilistic models enjoying the key ingredient behind expressive generative models: continuous latent variables (LVs). PICs are symbolic computational graphs defining continuous LV models as hierarchies of functions that are summed and multiplied together, or integrated over some LVs. They are tractable if LVs can be analytically integrated out, otherwise they can be approximated by tractable probabilistic circuits (PC) encoding a hierarchical numerical quadrature process, called QPCs.   So far, only tree-shaped PICs have been explored, and training them via numerical quadrature requires memory-intensive processing at scale. In this paper, we address these issues, and present: (i) a pipeline for building DAG-shaped PICs out of arbitrary variable decompositions, (ii) a procedure for training PICs using tensorized circuit architectures, and (iii) neural functional sharing techniques to allow scalable training. In extensive experiments, we showcase the effectiveness of functional sharing and the superiority of QPCs over traditional PCs.",
    "authors": [
      "Gennaro Gala",
      "Cassio de Campos",
      "Antonio Vergari",
      "Erik Quaeghebeur"
    ],
    "url": "http://arxiv.org/abs/2406.06494v1",
    "timestamp": 1718040617,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "38686b58-1bfc-47bc-85aa-f15f0bdf982d": {
    "pk": "38686b58-1bfc-47bc-85aa-f15f0bdf982d",
    "title": "When is Multicalibration Post-Processing Necessary?",
    "abstract": "Calibration is a well-studied property of predictors which guarantees meaningful uncertainty estimates. Multicalibration is a related notion -- originating in algorithmic fairness -- which requires predictors to be simultaneously calibrated over a potentially complex and overlapping collection of protected subpopulations (such as groups defined by ethnicity, race, or income). We conduct the first comprehensive study evaluating the usefulness of multicalibration post-processing across a broad set of tabular, image, and language datasets for models spanning from simple decision trees to 90 million parameter fine-tuned LLMs. Our findings can be summarized as follows: (1) models which are calibrated out of the box tend to be relatively multicalibrated without any additional post-processing; (2) multicalibration post-processing can help inherently uncalibrated models; and (3) traditional calibration measures may sometimes provide multicalibration implicitly. More generally, we also distill many independent observations which may be useful for practical and effective applications of multicalibration post-processing in real-world contexts.",
    "authors": [
      "Dutch Hansen",
      "Siddartha Devic",
      "Preetum Nakkiran",
      "Vatsal Sharan"
    ],
    "url": "http://arxiv.org/abs/2406.06487v1",
    "timestamp": 1718040399,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "99492802-62d1-47d6-a5ac-b1cb48e578af": {
    "pk": "99492802-62d1-47d6-a5ac-b1cb48e578af",
    "title": "Continuum Attention for Neural Operators",
    "abstract": "Transformers, and the attention mechanism in particular, have become ubiquitous in machine learning. Their success in modeling nonlocal, long-range correlations has led to their widespread adoption in natural language processing, computer vision, and time-series problems. Neural operators, which map spaces of functions into spaces of functions, are necessarily both nonlinear and nonlocal if they are universal; it is thus natural to ask whether the attention mechanism can be used in the design of neural operators. Motivated by this, we study transformers in the function space setting. We formulate attention as a map between infinite dimensional function spaces and prove that the attention mechanism as implemented in practice is a Monte Carlo or finite difference approximation of this operator. The function space formulation allows for the design of transformer neural operators, a class of architectures designed to learn mappings between function spaces, for which we prove a universal approximation result. The prohibitive cost of applying the attention operator to functions defined on multi-dimensional domains leads to the need for more efficient attention-based architectures. For this reason we also introduce a function space generalization of the patching strategy from computer vision, and introduce a class of associated neural operators. Numerical results, on an array of operator learning problems, demonstrate the promise of our approaches to function space formulations of attention and their use in neural operators.",
    "authors": [
      "Edoardo Calvello",
      "Nikola B. Kovachki",
      "Matthew E. Levine",
      "Andrew M. Stuart"
    ],
    "url": "http://arxiv.org/abs/2406.06486v1",
    "timestamp": 1718040346,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "85db3721-0c0e-461b-aefb-25399c0e249f": {
    "pk": "85db3721-0c0e-461b-aefb-25399c0e249f",
    "title": "Can Language Models Serve as Text-Based World Simulators?",
    "abstract": "Virtual environments play a key role in benchmarking advances in complex planning and decision-making tasks but are expensive and complicated to build by hand. Can current language models themselves serve as world simulators, correctly predicting how actions change different world states, thus bypassing the need for extensive manual coding? Our goal is to answer this question in the context of text-based simulators. Our approach is to build and use a new benchmark, called ByteSized32-State-Prediction, containing a dataset of text game state transitions and accompanying game tasks. We use this to directly quantify, for the first time, how well LLMs can serve as text-based world simulators. We test GPT-4 on this dataset and find that, despite its impressive performance, it is still an unreliable world simulator without further innovations. This work thus contributes both new insights into current LLM's capabilities and weaknesses, as well as a novel benchmark to track future progress as new models appear.",
    "authors": [
      "Ruoyao Wang",
      "Graham Todd",
      "Ziang Xiao",
      "Xingdi Yuan",
      "Marc-Alexandre C\u00f4t\u00e9",
      "Peter Clark",
      "Peter Jansen"
    ],
    "url": "http://arxiv.org/abs/2406.06485v1",
    "timestamp": 1718040284,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "2179d802-2f85-45b7-8bc3-69c335932779": {
    "pk": "2179d802-2f85-45b7-8bc3-69c335932779",
    "title": "Parallelizing Linear Transformers with the Delta Rule over Sequence Length",
    "abstract": "Transformers with linear attention (i.e., linear transformers) and state-space models have recently been suggested as a viable linear-time alternative to transformers with softmax attention. However, these models still underperform transformers especially on tasks that require in-context retrieval. While more expressive variants of linear transformers which replace the additive outer-product update in linear transformers with the delta rule have been found to be more effective at associative recall, existing algorithms for training such models do not parallelize over sequence length and are thus inefficient to train on modern hardware. This work describes a hardware-efficient algorithm for training linear transformers with the delta rule, which exploits a memory-efficient representation for computing products of Householder matrices. This algorithm allows us to scale up DeltaNet to standard language modeling settings. We train a 1.3B model for 100B tokens and find that it outperforms recent linear-time baselines such as Mamba and GLA in terms of perplexity and zero-shot performance on downstream tasks (including on tasks that focus on recall). We also experiment with two hybrid models which combine DeltaNet layers with (1) sliding-window attention layers every other layer or (2) two global attention layers, and find that these hybrid models outperform strong transformer baselines.",
    "authors": [
      "Songlin Yang",
      "Bailin Wang",
      "Yu Zhang",
      "Yikang Shen",
      "Yoon Kim"
    ],
    "url": "http://arxiv.org/abs/2406.06484v1",
    "timestamp": 1718040282,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "9ef8529b-ef9d-4701-9c2f-c0a579e34042": {
    "pk": "9ef8529b-ef9d-4701-9c2f-c0a579e34042",
    "title": "Quantum Equilibrium Propagation for efficient training of quantum systems based on Onsager reciprocity",
    "abstract": "The widespread adoption of machine learning and artificial intelligence in all branches of science and technology has created a need for energy-efficient, alternative hardware platforms. While such neuromorphic approaches have been proposed and realised for a wide range of platforms, physically extracting the gradients required for training remains challenging as generic approaches only exist in certain cases. Equilibrium propagation (EP) is such a procedure that has been introduced and applied to classical energy-based models which relax to an equilibrium. Here, we show a direct connection between EP and Onsager reciprocity and exploit this to derive a quantum version of EP. This can be used to optimize loss functions that depend on the expectation values of observables of an arbitrary quantum system. Specifically, we illustrate this new concept with supervised and unsupervised learning examples in which the input or the solvable task is of quantum mechanical nature, e.g., the recognition of quantum many-body ground states, quantum phase exploration, sensing and phase boundary exploration. We propose that in the future quantum EP may be used to solve tasks such as quantum phase discovery with a quantum simulator even for Hamiltonians which are numerically hard to simulate or even partially unknown. Our scheme is relevant for a variety of quantum simulation platforms such as ion chains, superconducting qubit arrays, neutral atom Rydberg tweezer arrays and strongly interacting atoms in optical lattices.",
    "authors": [
      "Clara C. Wanjura",
      "Florian Marquardt"
    ],
    "url": "http://arxiv.org/abs/2406.06482v1",
    "timestamp": 1718040129,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "d84fdc00-a8ed-468b-bcec-8b453e130a63": {
    "pk": "d84fdc00-a8ed-468b-bcec-8b453e130a63",
    "title": "Survey for Landing Generative AI in Social and E-commerce Recsys -- the Industry Perspectives",
    "abstract": "Recently, generative AI (GAI), with their emerging capabilities, have presented unique opportunities for augmenting and revolutionizing industrial recommender systems (Recsys). Despite growing research efforts at the intersection of these fields, the integration of GAI into industrial Recsys remains in its infancy, largely due to the intricate nature of modern industrial Recsys infrastructure, operations, and product sophistication. Drawing upon our experiences in successfully integrating GAI into several major social and e-commerce platforms, this survey aims to comprehensively examine the underlying system and AI foundations, solution frameworks, connections to key research advancements, as well as summarize the practical insights and challenges encountered in the endeavor to integrate GAI into industrial Recsys. As pioneering work in this domain, we hope outline the representative developments of relevant fields, shed lights on practical GAI adoptions in the industry, and motivate future research.",
    "authors": [
      "Da Xu",
      "Danqing Zhang",
      "Guangyu Yang",
      "Bo Yang",
      "Shuyuan Xu",
      "Lingling Zheng",
      "Cindy Liang"
    ],
    "url": "http://arxiv.org/abs/2406.06475v1",
    "timestamp": 1718039819,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.IR",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b827aa35-5d9c-425b-a37c-01e3c49fd0a4": {
    "pk": "b827aa35-5d9c-425b-a37c-01e3c49fd0a4",
    "title": "Towards a Personal Health Large Language Model",
    "abstract": "In health, most large language model (LLM) research has focused on clinical tasks. However, mobile and wearable devices, which are rarely integrated into such tasks, provide rich, longitudinal data for personal health monitoring. Here we present Personal Health Large Language Model (PH-LLM), fine-tuned from Gemini for understanding and reasoning over numerical time-series personal health data. We created and curated three datasets that test 1) production of personalized insights and recommendations from sleep patterns, physical activity, and physiological responses, 2) expert domain knowledge, and 3) prediction of self-reported sleep outcomes. For the first task we designed 857 case studies in collaboration with domain experts to assess real-world scenarios in sleep and fitness. Through comprehensive evaluation of domain-specific rubrics, we observed that Gemini Ultra 1.0 and PH-LLM are not statistically different from expert performance in fitness and, while experts remain superior for sleep, fine-tuning PH-LLM provided significant improvements in using relevant domain knowledge and personalizing information for sleep insights. We evaluated PH-LLM domain knowledge using multiple choice sleep medicine and fitness examinations. PH-LLM achieved 79% on sleep and 88% on fitness, exceeding average scores from a sample of human experts. Finally, we trained PH-LLM to predict self-reported sleep quality outcomes from textual and multimodal encoding representations of wearable data, and demonstrate that multimodal encoding is required to match performance of specialized discriminative models. Although further development and evaluation are necessary in the safety-critical personal health domain, these results demonstrate both the broad knowledge and capabilities of Gemini models and the benefit of contextualizing physiological data for personal health applications as done with PH-LLM.",
    "authors": [
      "Justin Cosentino",
      "Anastasiya Belyaeva",
      "Xin Liu",
      "Nicholas A. Furlotte",
      "Zhun Yang",
      "Chace Lee",
      "Erik Schenck",
      "Yojan Patel",
      "Jian Cui",
      "Logan Douglas Schneider",
      "Robby Bryant",
      "Ryan G. Gomes",
      "Allen Jiang",
      "Roy Lee",
      "Yun Liu",
      "Javier Perez",
      "Jameson K. Rogers",
      "Cathy Speed",
      "Shyam Tailor",
      "Megan Walker",
      "Jeffrey Yu",
      "Tim Althoff",
      "Conor Heneghan",
      "John Hernandez",
      "Mark Malhotra",
      "Leor Stern",
      "Yossi Matias",
      "Greg S. Corrado",
      "Shwetak Patel",
      "Shravya Shetty",
      "Jiening Zhan",
      "Shruthi Prabhakara",
      "Daniel McDuff",
      "Cory Y. McLean"
    ],
    "url": "http://arxiv.org/abs/2406.06474v1",
    "timestamp": 1718039809,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "21db0bc5-851b-4708-9b6b-a0c82a159deb": {
    "pk": "21db0bc5-851b-4708-9b6b-a0c82a159deb",
    "title": "DiffAudit: Auditing Privacy Practices of Online Services for Children and Adolescents",
    "abstract": "Children's and adolescents' online data privacy are regulated by laws such as the Children's Online Privacy Protection Act (COPPA) and the California Consumer Privacy Act (CCPA). Online services that are directed towards general audiences (i.e., including children, adolescents, and adults) must comply with these laws. In this paper, first, we present DiffAudit, a platform-agnostic privacy auditing methodology for general audience services. DiffAudit performs differential analysis of network traffic data flows to compare data processing practices (i) between child, adolescent, and adult users and (ii) before and after consent is given and user age is disclosed. We also present a data type classification method that utilizes GPT-4 and our data type ontology based on COPPA and CCPA, allowing us to identify considerably more data types than prior work. Second, we apply DiffAudit to a set of popular general audience mobile and web services and observe a rich set of behaviors extracted from over 440K outgoing requests, containing 3,968 unique data types we extracted and classified. We reveal problematic data processing practices prior to consent and age disclosure, lack of differentiation between age-specific data flows, inconsistent privacy policy disclosures, and sharing of linkable data with third parties, including advertising and tracking services.",
    "authors": [
      "Olivia Figueira",
      "Rahmadi Trimananda",
      "Athina Markopoulou",
      "Scott Jordan"
    ],
    "url": "http://arxiv.org/abs/2406.06473v1",
    "timestamp": 1718039693,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CR",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "0d2ad48e-f166-46b3-bfdb-eb63138f29c3": {
    "pk": "0d2ad48e-f166-46b3-bfdb-eb63138f29c3",
    "title": "GKAN: Graph Kolmogorov-Arnold Networks",
    "abstract": "We introduce Graph Kolmogorov-Arnold Networks (GKAN), an innovative neural network architecture that extends the principles of the recently proposed Kolmogorov-Arnold Networks (KAN) to graph-structured data. By adopting the unique characteristics of KANs, notably the use of learnable univariate functions instead of fixed linear weights, we develop a powerful model for graph-based learning tasks. Unlike traditional Graph Convolutional Networks (GCNs) that rely on a fixed convolutional architecture, GKANs implement learnable spline-based functions between layers, transforming the way information is processed across the graph structure. We present two different ways to incorporate KAN layers into GKAN: architecture 1 -- where the learnable functions are applied to input features after aggregation and architecture 2 -- where the learnable functions are applied to input features before aggregation. We evaluate GKAN empirically using a semi-supervised graph learning task on a real-world dataset (Cora). We find that architecture generally performs better. We find that GKANs achieve higher accuracy in semi-supervised learning tasks on graphs compared to the traditional GCN model. For example, when considering 100 features, GCN provides an accuracy of 53.5 while a GKAN with a comparable number of parameters gives an accuracy of 61.76; with 200 features, GCN provides an accuracy of 61.24 while a GKAN with a comparable number of parameters gives an accuracy of 67.66. We also present results on the impact of various parameters such as the number of hidden nodes, grid-size, and the polynomial-degree of the spline on the performance of GKAN.",
    "authors": [
      "Mehrdad Kiamari",
      "Mohammad Kiamari",
      "Bhaskar Krishnamachari"
    ],
    "url": "http://arxiv.org/abs/2406.06470v1",
    "timestamp": 1718039378,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "972228ab-1d95-4da9-95d5-59eb3f6a1ce6": {
    "pk": "972228ab-1d95-4da9-95d5-59eb3f6a1ce6",
    "title": "Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning",
    "abstract": "Language agents perform complex tasks by using tools to execute each step precisely. However, most existing agents are based on proprietary models or designed to target specific tasks, such as mathematics or multi-hop question answering. We introduce Husky, a holistic, open-source language agent that learns to reason over a unified action space to address a diverse set of complex tasks involving numerical, tabular, and knowledge-based reasoning. Husky iterates between two stages: 1) generating the next action to take towards solving a given task and 2) executing the action using expert models and updating the current solution state. We identify a thorough ontology of actions for addressing complex tasks and curate high-quality data to train expert models for executing these actions. Our experiments show that Husky outperforms prior language agents across 14 evaluation datasets. Moreover, we introduce HuskyQA, a new evaluation set which stress tests language agents for mixed-tool reasoning, with a focus on retrieving missing knowledge and performing numerical reasoning. Despite using 7B models, Husky matches or even exceeds frontier LMs such as GPT-4 on these tasks, showcasing the efficacy of our holistic approach in addressing complex reasoning problems. Our code and models are available at https://github.com/agent-husky/Husky-v1.",
    "authors": [
      "Joongwon Kim",
      "Bhargavi Paranjape",
      "Tushar Khot",
      "Hannaneh Hajishirzi"
    ],
    "url": "http://arxiv.org/abs/2406.06469v1",
    "timestamp": 1718039245,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "4b6b6db4-e839-4e4c-915b-c763c02312b1": {
    "pk": "4b6b6db4-e839-4e4c-915b-c763c02312b1",
    "title": "Randomized Binary and Tree Search under Pressure",
    "abstract": "We study a generalized binary search problem on the line and general trees. On the line (e.g., a sorted array), binary search finds a target node in $O(\\log n)$ queries in the worst case, where $n$ is the number of nodes. In situations with limited budget or time, we might only be able to perform a few queries, possibly sub-logarithmic many. In this case, it is impossible to guarantee that the target will be found regardless of its position. Our main result is the construction of a randomized strategy that maximizes the minimum (over the target position) probability of finding the target. Such a strategy provides a natural solution where there is no apriori (stochastic) information of the target's position. As with regular binary search, we can find and run the strategy in $O(\\log n)$ time (and using only $O(\\log n)$ random bits). Our construction is obtained by reinterpreting the problem as a two-player (\\textit{seeker} and \\textit{hider}) zero-sum game and exploiting an underlying number theoretical structure.   Furthermore, we generalize the setting to study a search game on trees. In this case, a query returns the edge's endpoint closest to the target. Again, when the number of queries is bounded by some given $k$, we quantify a \\emph{the-less-queries-the-better} approach by defining a seeker's profit $p$ depending on the number of queries needed to locate the hider. For the linear programming formulation of the corresponding zero-sum game, we show that computing the best response for the hider (i.e., the separation problem of the underlying dual LP) can be done in time $O(n^2 2^{2k})$, where $n$ is the size of the tree. This result allows to compute a Nash equilibrium in polynomial time whenever $k=O(\\log n)$. In contrast, computing the best response for the hider is NP-hard.",
    "authors": [
      "Agust\u00edn Caracci",
      "Christoph D\u00fcrr",
      "Jos\u00e9 Verschae"
    ],
    "url": "http://arxiv.org/abs/2406.06468v1",
    "timestamp": 1718039195,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.DS",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "73fa8f12-5a66-40fd-8961-e14a9615bfe5": {
    "pk": "73fa8f12-5a66-40fd-8961-e14a9615bfe5",
    "title": "AID: Adapting Image2Video Diffusion Models for Instruction-guided Video Prediction",
    "abstract": "Text-guided video prediction (TVP) involves predicting the motion of future frames from the initial frame according to an instruction, which has wide applications in virtual reality, robotics, and content creation. Previous TVP methods make significant breakthroughs by adapting Stable Diffusion for this task. However, they struggle with frame consistency and temporal stability primarily due to the limited scale of video datasets. We observe that pretrained Image2Video diffusion models possess good priors for video dynamics but they lack textual control. Hence, transferring Image2Video models to leverage their video dynamic priors while injecting instruction control to generate controllable videos is both a meaningful and challenging task. To achieve this, we introduce the Multi-Modal Large Language Model (MLLM) to predict future video states based on initial frames and text instructions. More specifically, we design a dual query transformer (DQFormer) architecture, which integrates the instructions and frames into the conditional embeddings for future frame prediction. Additionally, we develop Long-Short Term Temporal Adapters and Spatial Adapters that can quickly transfer general video diffusion models to specific scenarios with minimal training costs. Experimental results show that our method significantly outperforms state-of-the-art techniques on four datasets: Something Something V2, Epic Kitchen-100, Bridge Data, and UCF-101. Notably, AID achieves 91.2% and 55.5% FVD improvements on Bridge and SSv2 respectively, demonstrating its effectiveness in various domains. More examples can be found at our website https://chenhsing.github.io/AID.",
    "authors": [
      "Zhen Xing",
      "Qi Dai",
      "Zejia Weng",
      "Zuxuan Wu",
      "Yu-Gang Jiang"
    ],
    "url": "http://arxiv.org/abs/2406.06465v1",
    "timestamp": 1718038928,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "2efb58d4-8ab0-42e2-a221-89fb452967cd": {
    "pk": "2efb58d4-8ab0-42e2-a221-89fb452967cd",
    "title": "Transforming Wearable Data into Health Insights using Large Language Model Agents",
    "abstract": "Despite the proliferation of wearable health trackers and the importance of sleep and exercise to health, deriving actionable personalized insights from wearable data remains a challenge because doing so requires non-trivial open-ended analysis of these data. The recent rise of large language model (LLM) agents, which can use tools to reason about and interact with the world, presents a promising opportunity to enable such personalized analysis at scale. Yet, the application of LLM agents in analyzing personal health is still largely untapped. In this paper, we introduce the Personal Health Insights Agent (PHIA), an agent system that leverages state-of-the-art code generation and information retrieval tools to analyze and interpret behavioral health data from wearables. We curate two benchmark question-answering datasets of over 4000 health insights questions. Based on 650 hours of human and expert evaluation we find that PHIA can accurately address over 84% of factual numerical questions and more than 83% of crowd-sourced open-ended questions. This work has implications for advancing behavioral health across the population, potentially enabling individuals to interpret their own wearable data, and paving the way for a new era of accessible, personalized wellness regimens that are informed by data-driven insights.",
    "authors": [
      "Mike A. Merrill",
      "Akshay Paruchuri",
      "Naghmeh Rezaei",
      "Geza Kovacs",
      "Javier Perez",
      "Yun Liu",
      "Erik Schenck",
      "Nova Hammerquist",
      "Jake Sunshine",
      "Shyam Tailor",
      "Kumar Ayush",
      "Hao-Wei Su",
      "Qian He",
      "Cory McLean",
      "Mark Malhotra",
      "Shwetak Patel",
      "Jiening Zhan",
      "Tim Althoff",
      "Daniel McDuff",
      "Xin Liu"
    ],
    "url": "http://arxiv.org/abs/2406.06464v1",
    "timestamp": 1718038854,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "aa36d12b-6933-4fdf-a50b-3556c9f52fe6": {
    "pk": "aa36d12b-6933-4fdf-a50b-3556c9f52fe6",
    "title": "VCR: Visual Caption Restoration",
    "abstract": "We introduce Visual Caption Restoration (VCR), a novel vision-language task that challenges models to accurately restore partially obscured texts using pixel-level hints within images. This task stems from the observation that text embedded in images is intrinsically different from common visual elements and natural language due to the need to align the modalities of vision, text, and text embedded in images. While numerous works have integrated text embedded in images into visual question-answering tasks, approaches to these tasks generally rely on optical character recognition or masked language modeling, thus reducing the task to mainly text-based processing. However, text-based processing becomes ineffective in VCR as accurate text restoration depends on the combined information from provided images, context, and subtle cues from the tiny exposed areas of masked texts. We develop a pipeline to generate synthetic images for the VCR task using image-caption pairs, with adjustable caption visibility to control the task difficulty. With this pipeline, we construct a dataset for VCR called VCR-Wiki using images with captions from Wikipedia, comprising 2.11M English and 346K Chinese entities in both easy and hard split variants. Our results reveal that current vision language models significantly lag behind human performance in the VCR task, and merely fine-tuning the models on our dataset does not lead to notable improvements. We release VCR-Wiki and the data construction code to facilitate future research.",
    "authors": [
      "Tianyu Zhang",
      "Suyuchen Wang",
      "Lu Li",
      "Ge Zhang",
      "Perouz Taslakian",
      "Sai Rajeswar",
      "Jie Fu",
      "Bang Liu",
      "Yoshua Bengio"
    ],
    "url": "http://arxiv.org/abs/2406.06462v1",
    "timestamp": 1718038728,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c037e560-b5d0-40e3-a0d3-62e17b57a406": {
    "pk": "c037e560-b5d0-40e3-a0d3-62e17b57a406",
    "title": "Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies",
    "abstract": "A diverse array of reasoning strategies has been proposed to elicit the capabilities of large language models. However, in this paper, we point out that traditional evaluations which focus solely on performance metrics miss a key factor: the increased effectiveness due to additional compute. By overlooking this aspect, a skewed view of strategy efficiency is often presented. This paper introduces a framework that incorporates the compute budget into the evaluation, providing a more informative comparison that takes into account both performance metrics and computational cost. In this budget-aware perspective, we find that complex reasoning strategies often don't surpass simpler baselines purely due to algorithmic ingenuity, but rather due to the larger computational resources allocated. When we provide a simple baseline like chain-of-thought self-consistency with comparable compute resources, it frequently outperforms reasoning strategies proposed in the literature. In this scale-aware perspective, we find that unlike self-consistency, certain strategies such as multi-agent debate or Reflexion can become worse if more compute budget is utilized.",
    "authors": [
      "Junlin Wang",
      "Siddhartha Jain",
      "Dejiao Zhang",
      "Baishakhi Ray",
      "Varun Kumar",
      "Ben Athiwaratkun"
    ],
    "url": "http://arxiv.org/abs/2406.06461v1",
    "timestamp": 1718038508,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "8283a649-233a-4030-9ddd-91e72e445b3b": {
    "pk": "8283a649-233a-4030-9ddd-91e72e445b3b",
    "title": "How Useful is Intermittent, Asynchronous Expert Feedback for Bayesian Optimization?",
    "abstract": "Bayesian optimization (BO) is an integral part of automated scientific discovery -- the so-called self-driving lab -- where human inputs are ideally minimal or at least non-blocking. However, scientists often have strong intuition, and thus human feedback is still useful. Nevertheless, prior works in enhancing BO with expert feedback, such as by incorporating it in an offline or online but blocking (arrives at each BO iteration) manner, are incompatible with the spirit of self-driving labs. In this work, we study whether a small amount of randomly arriving expert feedback that is being incorporated in a non-blocking manner can improve a BO campaign. To this end, we run an additional, independent computing thread on top of the BO loop to handle the feedback-gathering process. The gathered feedback is used to learn a Bayesian preference model that can readily be incorporated into the BO thread, to steer its exploration-exploitation process. Experiments on toy and chemistry datasets suggest that even just a few intermittent, asynchronous expert feedback can be useful for improving or constraining BO. This can especially be useful for its implication in improving self-driving labs, e.g. making them more data-efficient and less costly.",
    "authors": [
      "Agustinus Kristiadi",
      "Felix Strieth-Kalthoff",
      "Sriram Ganapathi Subramanian",
      "Vincent Fortuin",
      "Pascal Poupart",
      "Geoff Pleiss"
    ],
    "url": "http://arxiv.org/abs/2406.06459v1",
    "timestamp": 1718038438,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "baa947a3-fa1f-4a70-9d44-3c9bd8c01a4c": {
    "pk": "baa947a3-fa1f-4a70-9d44-3c9bd8c01a4c",
    "title": "Evaluating the Retrieval Component in LLM-Based Question Answering Systems",
    "abstract": "Question answering systems (QA) utilizing Large Language Models (LLMs) heavily depend on the retrieval component to provide them with domain-specific information and reduce the risk of generating inaccurate responses or hallucinations. Although the evaluation of retrievers dates back to the early research in Information Retrieval, assessing their performance within LLM-based chatbots remains a challenge.   This study proposes a straightforward baseline for evaluating retrievers in Retrieval-Augmented Generation (RAG)-based chatbots. Our findings demonstrate that this evaluation framework provides a better image of how the retriever performs and is more aligned with the overall performance of the QA system. Although conventional metrics such as precision, recall, and F1 score may not fully capture LLMs' capabilities - as they can yield accurate responses despite imperfect retrievers - our method considers LLMs' strengths to ignore irrelevant contexts, as well as potential errors and hallucinations in their responses.",
    "authors": [
      "Ashkan Alinejad",
      "Krtin Kumar",
      "Ali Vahdat"
    ],
    "url": "http://arxiv.org/abs/2406.06458v1",
    "timestamp": 1718037982,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "9f8bafa1-f5e9-455b-a90c-1ed229814261": {
    "pk": "9f8bafa1-f5e9-455b-a90c-1ed229814261",
    "title": "A Large Language Model Pipeline for Breast Cancer Oncology",
    "abstract": "Large language models (LLMs) have demonstrated potential in the innovation of many disciplines. However, how they can best be developed for oncology remains underdeveloped. State-of-the-art OpenAI models were fine-tuned on a clinical dataset and clinical guidelines text corpus for two important cancer treatment factors, adjuvant radiation therapy and chemotherapy, using a novel Langchain prompt engineering pipeline. A high accuracy (0.85+) was achieved in the classification of adjuvant radiation therapy and chemotherapy for breast cancer patients. Furthermore, a confidence interval was formed from observational data on the quality of treatment from human oncologists to estimate the proportion of scenarios in which the model must outperform the original oncologist in its treatment prediction to be a better solution overall as 8.2% to 13.3%. Due to indeterminacy in the outcomes of cancer treatment decisions, future investigation, potentially a clinical trial, would be required to determine if this threshold was met by the models. Nevertheless, with 85% of U.S. cancer patients receiving treatment at local community facilities, these kinds of models could play an important part in expanding access to quality care with outcomes that lie, at minimum, close to a human oncologist.",
    "authors": [
      "Tristen Pool",
      "Dennis Trujillo"
    ],
    "url": "http://arxiv.org/abs/2406.06455v1",
    "timestamp": 1718037888,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "0177616e-fe95-486c-970c-8017a4ae1f29": {
    "pk": "0177616e-fe95-486c-970c-8017a4ae1f29",
    "title": "Which topics are best represented by science maps? An analysis of clustering effectiveness for citation and text similarity networks",
    "abstract": "A science map of topics is a visualization that shows topics identified algorithmically based on the bibliographic metadata of scientific publications. In practice not all topics are well represented in a science map. We analyzed how effectively different topics are represented in science maps created by clustering biomedical publications. To achieve this, we investigated which topic categories, obtained from MeSH terms, are better represented in science maps based on citation or text similarity networks. To evaluate the clustering effectiveness of topics, we determined the extent to which documents belonging to the same topic are grouped together in the same cluster. We found that the best and worst represented topic categories are the same for citation and text similarity networks. The best represented topic categories are diseases, psychology, anatomy, organisms and the techniques and equipment used for diagnostics and therapy, while the worst represented topic categories are natural science fields, geographical entities, information sciences and health care and occupations. Furthermore, for the diseases and organisms topic categories and for science maps with smaller clusters, we found that topics tend to be better represented in citation similarity networks than in text similarity networks.",
    "authors": [
      "Juan Pablo Bascur",
      "Suzan Verberne",
      "Nees Jan van Eck",
      "Ludo Waltman"
    ],
    "url": "http://arxiv.org/abs/2406.06454v1",
    "timestamp": 1718037827,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.DL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "12b704ce-2a3b-4ce3-90f5-39ea86a808c0": {
    "pk": "12b704ce-2a3b-4ce3-90f5-39ea86a808c0",
    "title": "Time Series Analysis: yesterday, today, tomorrow",
    "abstract": "Forecasts of various processes have always been a sophisticated problem for statistics and data science. Over the past decades the solution procedures were updated by deep learning and kernel methods. According to many specialists, these approaches are much more precise, stable, and suitable compared to the classical statistical linear time series methods. Here we investigate how true this point of view is.",
    "authors": [
      "Igor Mackarov"
    ],
    "url": "http://arxiv.org/abs/2406.06453v1",
    "timestamp": 1718037764,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CY",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "42fdab85-62b6-4768-99d7-c8efbffd890d": {
    "pk": "42fdab85-62b6-4768-99d7-c8efbffd890d",
    "title": "Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course",
    "abstract": "The capability of large language models (LLMs) to generate, debug, and explain code has sparked the interest of researchers and educators in undergraduate programming, with many anticipating their transformative potential in programming education. However, decisions about why and how to use LLMs in programming education may involve more than just the assessment of an LLM's technical capabilities. Using the social shaping of technology theory as a guiding framework, our study explores how students' social perceptions influence their own LLM usage. We then examine the correlation of self-reported LLM usage with students' self-efficacy and midterm performances in an undergraduate programming course. Triangulating data from an anonymous end-of-course student survey (n = 158), a mid-course self-efficacy survey (n=158), student interviews (n = 10), self-reported LLM usage on homework, and midterm performances, we discovered that students' use of LLMs was associated with their expectations for their future careers and their perceptions of peer usage. Additionally, early self-reported LLM usage in our context correlated with lower self-efficacy and lower midterm scores, while students' perceived over-reliance on LLMs, rather than their usage itself, correlated with decreased self-efficacy later in the course.",
    "authors": [
      "Aadarsh Padiyath",
      "Xinying Hou",
      "Amy Pang",
      "Diego Viramontes Vargas",
      "Xingjian Gu",
      "Tamara Nelson-Fromm",
      "Zihan Wu",
      "Mark Guzdial",
      "Barbara Ericson"
    ],
    "url": "http://arxiv.org/abs/2406.06451v1",
    "timestamp": 1718037614,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.HC",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "7ff16239-6bb9-4db2-863f-40bfcb6ac1b3": {
    "pk": "7ff16239-6bb9-4db2-863f-40bfcb6ac1b3",
    "title": "Cometh: A continuous-time discrete-state graph diffusion model",
    "abstract": "Discrete-state denoising diffusion models led to state-of-the-art performance in graph generation, especially in the molecular domain. Recently, they have been transposed to continuous time, allowing more flexibility in the reverse process and a better trade-off between sampling efficiency and quality. Here, to leverage the benefits of both approaches, we propose Cometh, a continuous-time discrete-state graph diffusion model, integrating graph data into a continuous-time diffusion model framework. Empirically, we show that integrating continuous time leads to significant improvements across various metrics over state-of-the-art discrete-state diffusion models on a large set of molecular and non-molecular benchmark datasets.",
    "authors": [
      "Antoine Siraudin",
      "Fragkiskos D. Malliaros",
      "Christopher Morris"
    ],
    "url": "http://arxiv.org/abs/2406.06449v1",
    "timestamp": 1718037579,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "2e52ea1d-6f9f-4d47-a179-204b8e3b7172": {
    "pk": "2e52ea1d-6f9f-4d47-a179-204b8e3b7172",
    "title": "Parallel Quantum Local Search via Evolutionary Mechanism",
    "abstract": "We propose an innovative Parallel Quantum Local Search (PQLS) methodology that leverages the capabilities of small-scale quantum computers to efficiently address complex combinatorial optimization problems. Traditional Quantum Local Search (QLS) methods face limitations due to the sequential nature of solving sub-problems, which arises from dependencies between their solutions. Our approach transcends this constraint by simultaneously executing multiple QLS pathways and aggregating their most effective outcomes at certain intervals to establish a ``generation''. Each subsequent generation commences with the optimal solution from its predecessor, thereby significantly accelerating the convergence towards an optimal solution. Our findings demonstrate the profound impact of parallel quantum computing in enhancing the resolution of Ising problems, which are synonymous with combinatorial optimization challenges.",
    "authors": [
      "Chen-Yu Liu",
      "Kuan-Cheng Chen"
    ],
    "url": "http://arxiv.org/abs/2406.06445v1",
    "timestamp": 1718037352,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f98ba01c-1f59-46a3-a82a-7b88707f3728": {
    "pk": "f98ba01c-1f59-46a3-a82a-7b88707f3728",
    "title": "QSSEP describes the fluctuations of quantum coherences in the Anderson model",
    "abstract": "Using the transfer matrix method, we numerically investigate the structure of spatial coherences and their fluctuations in the 3d Anderson model in the metallic phase when driven out-of-equilibrium by external leads at zero temperature and in linear response. We find that the stationary state entails non-local non-Gaussian correlations in the longitudinal direction, which are characteristic of diffusive non equilibrium steady states. These correlations are quantitatively matched, at least up to third order, by those analytically derived in the Quantum Symmetric Simple Exclusion Process (QSSEP) which describes diffusive fermions in 1d subject to dynamical disorder. Furthermore, the large deviation scaling and $U(1)$ invariance of these correlations imply a link between the Anderson model and free probability theory. Our findings suggest the existence of a universal structure of correlations in non-interacting diffusive quantum systems that might be captured by QSSEP.",
    "authors": [
      "Ludwig Hruza",
      "Tony Jin"
    ],
    "url": "http://arxiv.org/abs/2406.06444v1",
    "timestamp": 1718037322,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cond-mat.stat-mech",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "bb0b1d1a-6859-4b51-8cb2-a412c6672bc1": {
    "pk": "bb0b1d1a-6859-4b51-8cb2-a412c6672bc1",
    "title": "LLM Dataset Inference: Did you train on my dataset?",
    "abstract": "The proliferation of large language models (LLMs) in the real world has come with a rise in copyright cases against companies for training their models on unlicensed data from the internet. Recent works have presented methods to identify if individual text sequences were members of the model's training data, known as membership inference attacks (MIAs). We demonstrate that the apparent success of these MIAs is confounded by selecting non-members (text sequences not used for training) belonging to a different distribution from the members (e.g., temporally shifted recent Wikipedia articles compared with ones used to train the model). This distribution shift makes membership inference appear successful. However, most MIA methods perform no better than random guessing when discriminating between members and non-members from the same distribution (e.g., in this case, the same period of time). Even when MIAs work, we find that different MIAs succeed at inferring membership of samples from different distributions. Instead, we propose a new dataset inference method to accurately identify the datasets used to train large language models. This paradigm sits realistically in the modern-day copyright landscape, where authors claim that an LLM is trained over multiple documents (such as a book) written by them, rather than one particular paragraph. While dataset inference shares many of the challenges of membership inference, we solve it by selectively combining the MIAs that provide positive signal for a given distribution, and aggregating them to perform a statistical test on a given dataset. Our approach successfully distinguishes the train and test sets of different subsets of the Pile with statistically significant p-values < 0.1, without any false positives.",
    "authors": [
      "Pratyush Maini",
      "Hengrui Jia",
      "Nicolas Papernot",
      "Adam Dziedzic"
    ],
    "url": "http://arxiv.org/abs/2406.06443v1",
    "timestamp": 1718037283,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "6885fa80-4b37-40e9-bcfc-f2ba6137bdb3": {
    "pk": "6885fa80-4b37-40e9-bcfc-f2ba6137bdb3",
    "title": "Interpretability of Language Models via Task Spaces",
    "abstract": "The usual way to interpret language models (LMs) is to test their performance on different benchmarks and subsequently infer their internal processes. In this paper, we present an alternative approach, concentrating on the quality of LM processing, with a focus on their language abilities. To this end, we construct 'linguistic task spaces' -- representations of an LM's language conceptualisation -- that shed light on the connections LMs draw between language phenomena. Task spaces are based on the interactions of the learning signals from different linguistic phenomena, which we assess via a method we call 'similarity probing'. To disentangle the learning signals of linguistic phenomena, we further introduce a method called 'fine-tuning via gradient differentials' (FTGD). We apply our methods to language models of three different scales and find that larger models generalise better to overarching general concepts for linguistic tasks, making better use of their shared structure. Further, the distributedness of linguistic processing increases with pre-training through increased parameter sharing between related linguistic tasks. The overall generalisation patterns are mostly stable throughout training and not marked by incisive stages, potentially explaining the lack of successful curriculum strategies for LMs.",
    "authors": [
      "Lucas Weber",
      "Jaap Jumelet",
      "Elia Bruni",
      "Dieuwke Hupkes"
    ],
    "url": "http://arxiv.org/abs/2406.06441v1",
    "timestamp": 1718037270,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "d99137c9-aa85-43f0-83a5-88664a87f6dd": {
    "pk": "d99137c9-aa85-43f0-83a5-88664a87f6dd",
    "title": "Messengers: Breaking Echo Chambers in Collective Opinion Dynamics with Homophily",
    "abstract": "Collective estimation manifests computational intelligence emerging from inter-individual local interactions, e.g., by aggregating opinions from neighbors to estimate a quantity. Use cases of collective estimation may include directed motion in physical space, such that agents, for example, have to collectively explore a distributed feature, and collectively agree on a numerical value. In doing so, collectives face several challenges in achieving precise estimations. These challenges exhibit complex behaviors, particularly when the interaction network and opinion of agents evolve simultaneously. We take homophilic networks as an example, where disproportionate interaction with like-minded neighbors leads to the emergence of echo chambers, preventing collective consensus. Our simulation results confirm that, besides a lack of exposure to attitude-challenging opinions, seeking reaffirming information entraps agents in echo chambers. We propose a generic novel approach based on a Dichotomous Markov Process (DMP) where stubborn agents (called Messengers) connect the disconnected clusters by physically transporting their opinions to other clusters to inform and direct the other agents. We show that diverse collective behaviors arise from the DMP and study a continuum between task specialization with no switching (full-time Messengers), generalization with slow task switching (part-time Messengers), and rapid task switching (short-time Messengers) and its impact on system performance. Our results show that stubborn agents can, in various ways, break the echo chambers and promote consensus in collective opinion.",
    "authors": [
      "Mohsen Raoufi",
      "Heiko Hamann",
      "Pawel Romanczuk"
    ],
    "url": "http://arxiv.org/abs/2406.06440v1",
    "timestamp": 1718037203,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.SI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "68d2c4c9-e548-4248-891b-f368e23eab4e": {
    "pk": "68d2c4c9-e548-4248-891b-f368e23eab4e",
    "title": "Multimodal Contextualized Semantic Parsing from Speech",
    "abstract": "We introduce Semantic Parsing in Contextual Environments (SPICE), a task designed to enhance artificial agents' contextual awareness by integrating multimodal inputs with prior contexts. SPICE goes beyond traditional semantic parsing by offering a structured, interpretable framework for dynamically updating an agent's knowledge with new information, mirroring the complexity of human communication. We develop the VG-SPICE dataset, crafted to challenge agents with visual scene graph construction from spoken conversational exchanges, highlighting speech and visual data integration. We also present the Audio-Vision Dialogue Scene Parser (AViD-SP) developed for use on VG-SPICE. These innovations aim to improve multimodal information processing and integration. Both the VG-SPICE dataset and the AViD-SP model are publicly available.",
    "authors": [
      "Jordan Voas",
      "Raymond Mooney",
      "David Harwath"
    ],
    "url": "http://arxiv.org/abs/2406.06438v1",
    "timestamp": 1718037094,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "0ee7fd29-736a-4353-9f84-dd0fb1b9cd7e": {
    "pk": "0ee7fd29-736a-4353-9f84-dd0fb1b9cd7e",
    "title": "Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain",
    "abstract": "In difficult decision-making scenarios, it is common to have conflicting opinions among expert human decision-makers as there may not be a single right answer. Such decisions may be guided by different attributes that can be used to characterize an individual's decision. We introduce a novel dataset for medical triage decision-making, labeled with a set of decision-maker attributes (DMAs). This dataset consists of 62 scenarios, covering six different DMAs, including ethical principles such as fairness and moral desert. We present a novel software framework for human-aligned decision-making by utilizing these DMAs, paving the way for trustworthy AI with better guardrails. Specifically, we demonstrate how large language models (LLMs) can serve as ethical decision-makers, and how their decisions can be aligned to different DMAs using zero-shot prompting. Our experiments focus on different open-source models with varying sizes and training techniques, such as Falcon, Mistral, and Llama 2. Finally, we also introduce a new form of weighted self-consistency that improves the overall quantified performance. Our results provide new research directions in the use of LLMs as alignable decision-makers. The dataset and open-source software are publicly available at: https://github.com/ITM-Kitware/llm-alignable-dm.",
    "authors": [
      "Brian Hu",
      "Bill Ray",
      "Alice Leung",
      "Amy Summerville",
      "David Joy",
      "Christopher Funk",
      "Arslan Basharat"
    ],
    "url": "http://arxiv.org/abs/2406.06435v1",
    "timestamp": 1718036723,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "4f624c60-3716-4995-bcde-4ad9ccaf2cfd": {
    "pk": "4f624c60-3716-4995-bcde-4ad9ccaf2cfd",
    "title": "Spatiotemporal Graph Neural Network Modelling Perfusion MRI",
    "abstract": "Perfusion MRI (pMRI) offers valuable insights into tumor vascularity and promises to predict tumor genotypes, thus benefiting prognosis for glioma patients, yet effective models tailored to 4D pMRI are still lacking. This study presents the first attempt to model 4D pMRI using a GNN-based spatiotemporal model PerfGAT, integrating spatial information and temporal kinetics to predict Isocitrate DeHydrogenase (IDH) mutation status in glioma patients. Specifically, we propose a graph structure learning approach based on edge attention and negative graphs to optimize temporal correlations modeling. Moreover, we design a dual-attention feature fusion module to integrate spatiotemporal features while addressing tumor-related brain regions. Further, we develop a class-balanced augmentation methods tailored to spatiotemporal data, which could mitigate the common label imbalance issue in clinical datasets. Our experimental results demonstrate that the proposed method outperforms other state-of-the-art approaches, promising to model pMRI effectively for patient characterization.",
    "authors": [
      "Ruodan Yan",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Chao Li"
    ],
    "url": "http://arxiv.org/abs/2406.06434v1",
    "timestamp": 1718036686,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.IV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f9bae142-866b-449f-b5f7-4a5c96f8e8cb": {
    "pk": "f9bae142-866b-449f-b5f7-4a5c96f8e8cb",
    "title": "DISCO: An End-to-End Bandit Framework for Personalised Discount Allocation",
    "abstract": "Personalised discount codes provide a powerful mechanism for managing customer relationships and operational spend in e-commerce. Bandits are well suited for this product area, given the partial information nature of the problem, as well as the need for adaptation to the changing business environment. Here, we introduce DISCO, an end-to-end contextual bandit framework for personalised discount code allocation at ASOS.com. DISCO adapts the traditional Thompson Sampling algorithm by integrating it within an integer program, thereby allowing for operational cost control. Because bandit learning is often worse with high dimensional actions, we focused on building low dimensional action and context representations that were nonetheless capable of good accuracy. Additionally, we sought to build a model that preserved the relationship between price and sales, in which customers increasing their purchasing in response to lower prices (\"negative price elasticity\"). These aims were achieved by using radial basis functions to represent the continuous (i.e. infinite armed) action space, in combination with context embeddings extracted from a neural network. These feature representations were used within a Thompson Sampling framework to facilitate exploration, and further integrated with an integer program to allocate discount codes across ASOS's customer base. These modelling decisions result in a reward model that (a) enables pooled learning across similar actions, (b) is highly accurate, including in extrapolation, and (c) preserves the expected negative price elasticity. Through offline analysis, we show that DISCO is able to effectively enact exploration and improves its performance over time, despite the global constraint. Finally, we subjected DISCO to a rigorous online A/B test, and find that it achieves a significant improvement of >1% in average basket value, relative to the legacy systems.",
    "authors": [
      "Jason Shuo Zhang",
      "Benjamin Howson",
      "Panayiota Savva",
      "Eleanor Loh"
    ],
    "url": "http://arxiv.org/abs/2406.06433v1",
    "timestamp": 1718036675,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "42dbb164-a92e-48d8-b60d-e849fc1a372c": {
    "pk": "42dbb164-a92e-48d8-b60d-e849fc1a372c",
    "title": "SYM3D: Learning Symmetric Triplanes for Better 3D-Awareness of GANs",
    "abstract": "Despite the growing success of 3D-aware GANs, which can be trained on 2D images to generate high-quality 3D assets, they still rely on multi-view images with camera annotations to synthesize sufficient details from all viewing directions. However, the scarce availability of calibrated multi-view image datasets, especially in comparison to single-view images, has limited the potential of 3D GANs. Moreover, while bypassing camera pose annotations with a camera distribution constraint reduces dependence on exact camera parameters, it still struggles to generate a consistent orientation of 3D assets. To this end, we propose SYM3D, a novel 3D-aware GAN designed to leverage the prevalent reflectional symmetry structure found in natural and man-made objects, alongside a proposed view-aware spatial attention mechanism in learning the 3D representation. We evaluate SYM3D on both synthetic (ShapeNet Chairs, Cars, and Airplanes) and real-world datasets (ABO-Chair), demonstrating its superior performance in capturing detailed geometry and texture, even when trained on only single-view images. Finally, we demonstrate the effectiveness of incorporating symmetry regularization in helping reduce artifacts in the modeling of 3D assets in the text-to-3D task.",
    "authors": [
      "Jing Yang",
      "Kyle Fogarty",
      "Fangcheng Zhong",
      "Cengiz Oztireli"
    ],
    "url": "http://arxiv.org/abs/2406.06432v1",
    "timestamp": 1718036647,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "4dc102f1-7cfa-4f91-a79f-0a76b75e029f": {
    "pk": "4dc102f1-7cfa-4f91-a79f-0a76b75e029f",
    "title": "Multivariate Stochastic Dominance via Optimal Transport and Applications to Models Benchmarking",
    "abstract": "Stochastic dominance is an important concept in probability theory, econometrics and social choice theory for robustly modeling agents' preferences between random outcomes. While many works have been dedicated to the univariate case, little has been done in the multivariate scenario, wherein an agent has to decide between different multivariate outcomes. By exploiting a characterization of multivariate first stochastic dominance in terms of couplings, we introduce a statistic that assesses multivariate almost stochastic dominance under the framework of Optimal Transport with a smooth cost. Further, we introduce an entropic regularization of this statistic, and establish a central limit theorem (CLT) and consistency of the bootstrap procedure for the empirical statistic. Armed with this CLT, we propose a hypothesis testing framework as well as an efficient implementation using the Sinkhorn algorithm. We showcase our method in comparing and benchmarking Large Language Models that are evaluated on multiple metrics. Our multivariate stochastic dominance test allows us to capture the dependencies between the metrics in order to make an informed and statistically significant decision on the relative performance of the models.",
    "authors": [
      "Gabriel Rioux",
      "Apoorva Nitsure",
      "Mattia Rigotti",
      "Kristjan Greenewald",
      "Youssef Mroueh"
    ],
    "url": "http://arxiv.org/abs/2406.06425v1",
    "timestamp": 1718036090,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "stat.ML",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "84bae7bb-bbf2-4949-9f40-cb01abd4ad30": {
    "pk": "84bae7bb-bbf2-4949-9f40-cb01abd4ad30",
    "title": "Margin-aware Preference Optimization for Aligning Diffusion Models without Reference",
    "abstract": "Modern alignment techniques based on human preferences, such as RLHF and DPO, typically employ divergence regularization relative to the reference model to ensure training stability. However, this often limits the flexibility of models during alignment, especially when there is a clear distributional discrepancy between the preference data and the reference model. In this paper, we focus on the alignment of recent text-to-image diffusion models, such as Stable Diffusion XL (SDXL), and find that this \"reference mismatch\" is indeed a significant problem in aligning these models due to the unstructured nature of visual modalities: e.g., a preference for a particular stylistic aspect can easily induce such a discrepancy. Motivated by this observation, we propose a novel and memory-friendly preference alignment method for diffusion models that does not depend on any reference model, coined margin-aware preference optimization (MaPO). MaPO jointly maximizes the likelihood margin between the preferred and dispreferred image sets and the likelihood of the preferred sets, simultaneously learning general stylistic features and preferences. For evaluation, we introduce two new pairwise preference datasets, which comprise self-generated image pairs from SDXL, Pick-Style and Pick-Safety, simulating diverse scenarios of reference mismatch. Our experiments validate that MaPO can significantly improve alignment on Pick-Style and Pick-Safety and general preference alignment when used with Pick-a-Pic v2, surpassing the base SDXL and other existing methods. Our code, models, and datasets are publicly available via https://mapo-t2i.github.io",
    "authors": [
      "Jiwoo Hong",
      "Sayak Paul",
      "Noah Lee",
      "Kashif Rasul",
      "James Thorne",
      "Jongheon Jeong"
    ],
    "url": "http://arxiv.org/abs/2406.06424v1",
    "timestamp": 1718036085,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "002e25eb-d71d-4834-921c-616a670a079e": {
    "pk": "002e25eb-d71d-4834-921c-616a670a079e",
    "title": "An Improved Empirical Fisher Approximation for Natural Gradient Descent",
    "abstract": "Approximate Natural Gradient Descent (NGD) methods are an important family of optimisers for deep learning models, which use approximate Fisher information matrices to pre-condition gradients during training. The empirical Fisher (EF) method approximates the Fisher information matrix empirically by reusing the per-sample gradients collected during back-propagation. Despite its ease of implementation, the EF approximation has its theoretical and practical limitations. This paper first investigates the inversely-scaled projection issue of EF, which is shown to be a major cause of the poor empirical approximation quality. An improved empirical Fisher (iEF) method, motivated as a generalised NGD method from a loss reduction perspective, is proposed to address this issue, meanwhile retaining the practical convenience of EF. The exact iEF and EF methods are experimentally evaluated using practical deep learning setups, including widely-used setups for parameter-efficient fine-tuning of pre-trained models (T5-base with LoRA and Prompt-Tuning on GLUE tasks, and ViT with LoRA for CIFAR100). Optimisation experiments show that applying exact iEF as an optimiser provides strong convergence and generalisation. It achieves the best test performance and the lowest training loss for majority of the tasks, even when compared with well-tuned AdamW/Adafactor baselines. Additionally, under a novel empirical evaluation framework, the proposed iEF method shows consistently better approximation quality to the exact Natural Gradient updates than both EF and the more expensive sampled Fisher (SF). Further investigation also shows that the superior approximation quality of iEF is robust to damping across tasks and training stages. Improving existing approximate NGD optimisers with iEF is expected to lead to better convergence ability and stronger robustness to choice of damping.",
    "authors": [
      "Xiaodong Wu",
      "Wenyi Yu",
      "Chao Zhang",
      "Philip Woodland"
    ],
    "url": "http://arxiv.org/abs/2406.06420v1",
    "timestamp": 1718035952,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c6daefaa-8642-4814-9503-6dce8d193bc8": {
    "pk": "c6daefaa-8642-4814-9503-6dce8d193bc8",
    "title": "Foundation Inference Models for Markov Jump Processes",
    "abstract": "Markov jump processes are continuous-time stochastic processes which describe dynamical systems evolving in discrete state spaces. These processes find wide application in the natural sciences and machine learning, but their inference is known to be far from trivial. In this work we introduce a methodology for zero-shot inference of Markov jump processes (MJPs), on bounded state spaces, from noisy and sparse observations, which consists of two components. First, a broad probability distribution over families of MJPs, as well as over possible observation times and noise mechanisms, with which we simulate a synthetic dataset of hidden MJPs and their noisy observation process. Second, a neural network model that processes subsets of the simulated observations, and that is trained to output the initial condition and rate matrix of the target MJP in a supervised way. We empirically demonstrate that one and the same (pretrained) model can infer, in a zero-shot fashion, hidden MJPs evolving in state spaces of different dimensionalities. Specifically, we infer MJPs which describe (i) discrete flashing ratchet systems, which are a type of Brownian motors, and the conformational dynamics in (ii) molecular simulations, (iii) experimental ion channel data and (iv) simple protein folding models. What is more, we show that our model performs on par with state-of-the-art models which are finetuned to the target datasets.",
    "authors": [
      "David Berghaus",
      "Kostadin Cvejoski",
      "Patrick Seifner",
      "Cesar Ojeda",
      "Ramses J. Sanchez"
    ],
    "url": "http://arxiv.org/abs/2406.06419v1",
    "timestamp": 1718035920,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "e5774661-2723-4a11-b299-c799be9384f6": {
    "pk": "e5774661-2723-4a11-b299-c799be9384f6",
    "title": "Explainable Graph Neural Networks Under Fire",
    "abstract": "Predictions made by graph neural networks (GNNs) usually lack interpretability due to their complex computational behavior and the abstract nature of graphs. In an attempt to tackle this, many GNN explanation methods have emerged. Their goal is to explain a model's predictions and thereby obtain trust when GNN models are deployed in decision critical applications. Most GNN explanation methods work in a post-hoc manner and provide explanations in the form of a small subset of important edges and/or nodes. In this paper we demonstrate that these explanations can unfortunately not be trusted, as common GNN explanation methods turn out to be highly susceptible to adversarial perturbations. That is, even small perturbations of the original graph structure that preserve the model's predictions may yield drastically different explanations. This calls into question the trustworthiness and practical utility of post-hoc explanation methods for GNNs. To be able to attack GNN explanation models, we devise a novel attack method dubbed \\textit{GXAttack}, the first \\textit{optimization-based} adversarial attack method for post-hoc GNN explanations under such settings. Due to the devastating effectiveness of our attack, we call for an adversarial evaluation of future GNN explainers to demonstrate their robustness.",
    "authors": [
      "Zhong Li",
      "Simon Geisler",
      "Yuhang Wang",
      "Stephan G\u00fcnnemann",
      "Matthijs van Leeuwen"
    ],
    "url": "http://arxiv.org/abs/2406.06417v1",
    "timestamp": 1718035756,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "501e8661-6f42-4cf0-8ef8-c61d3ae39760": {
    "pk": "501e8661-6f42-4cf0-8ef8-c61d3ae39760",
    "title": "Controlling Emotion in Text-to-Speech with Natural Language Prompts",
    "abstract": "In recent years, prompting has quickly become one of the standard ways of steering the outputs of generative machine learning models, due to its intuitive use of natural language. In this work, we propose a system conditioned on embeddings derived from an emotionally rich text that serves as prompt. Thereby, a joint representation of speaker and prompt embeddings is integrated at several points within a transformer-based architecture. Our approach is trained on merged emotional speech and text datasets and varies prompts in each training iteration to increase the generalization capabilities of the model. Objective and subjective evaluation results demonstrate the ability of the conditioned synthesis system to accurately transfer the emotions present in a prompt to speech. At the same time, precise tractability of speaker identities as well as overall high speech quality and intelligibility are maintained.",
    "authors": [
      "Thomas Bott",
      "Florian Lux",
      "Ngoc Thang Vu"
    ],
    "url": "http://arxiv.org/abs/2406.06406v1",
    "timestamp": 1718035122,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "dd6fad14-756d-4e65-bb32-4a434a544fb9": {
    "pk": "dd6fad14-756d-4e65-bb32-4a434a544fb9",
    "title": "Relevant information in TDD experiment reporting",
    "abstract": "Experiments are a commonly used method of research in software engineering (SE). Researchers report their experiments following detailed guidelines. However, researchers do not, in the field of test-driven development (TDD) at least, specify how they operationalized the response variables and the measurement process. This article has three aims: (i) identify the response variable operationalization components in TDD experiments that study external quality; (ii) study their influence on the experimental results;(ii) determine if the experiment reports describe the measurement process components that have an impact on the results. Sequential mixed method. The first part of the research adopts a quantitative approach applying a statistical an\\'alisis (SA) of the impact of the operationalization components on the experimental results. The second part follows on with a qualitative approach applying a systematic mapping study (SMS). The test suites, intervention types and measurers have an influence on the measurements and results of the SA of TDD experiments in SE. The test suites have a major impact on both the measurements and the results of the experiments. The intervention type has less impact on the results than on the measurements. While the measurers have an impact on the measurements, this is not transferred to the experimental results. On the other hand, the results of our SMS confirm that TDD experiments do not usually report either the test suites, the test case generation method, or the details of how external quality was measured. A measurement protocol should be used to assure that the measurements made by different measurers are similar. It is necessary to report the test cases, the experimental task and the intervention type in order to be able to reproduce the measurements and SA, as well as to replicate experiments and build dependable families of experiments.",
    "authors": [
      "Fernando Uyaguari",
      "Silvia T. Acu\u00f1a",
      "John W. Castro",
      "Davide Fucci",
      "Oscar Dieste",
      "Sira Vegas"
    ],
    "url": "http://arxiv.org/abs/2406.06405v1",
    "timestamp": 1718035076,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.SE",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "05f729fb-9383-4d0f-b4b2-0e0bfa2105d4": {
    "pk": "05f729fb-9383-4d0f-b4b2-0e0bfa2105d4",
    "title": "Meta Learning Text-to-Speech Synthesis in over 7000 Languages",
    "abstract": "In this work, we take on the challenging task of building a single text-to-speech synthesis system that is capable of generating speech in over 7000 languages, many of which lack sufficient data for traditional TTS development. By leveraging a novel integration of massively multilingual pretraining and meta learning to approximate language representations, our approach enables zero-shot speech synthesis in languages without any available data. We validate our system's performance through objective measures and human evaluation across a diverse linguistic landscape. By releasing our code and models publicly, we aim to empower communities with limited linguistic resources and foster further innovation in the field of speech technology.",
    "authors": [
      "Florian Lux",
      "Sarina Meyer",
      "Lyonel Behringer",
      "Frank Zalkow",
      "Phat Do",
      "Matt Coler",
      "Emanu\u00ebl A. P. Habets",
      "Ngoc Thang Vu"
    ],
    "url": "http://arxiv.org/abs/2406.06403v1",
    "timestamp": 1718035012,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "1562196b-53a6-4d5f-9a0a-a12b72cde8a5": {
    "pk": "1562196b-53a6-4d5f-9a0a-a12b72cde8a5",
    "title": "Early Acceptance Matching Game for User-Centric Clustering in Scalable Cell-free MIMO Networks",
    "abstract": "The canonical setup is the primary approach adopted in cell-free multiple-input multiple-output (MIMO) networks, in which all access points (APs) jointly serve every user equipment (UE). This approach is not scalable in terms of computational complexity and fronthaul signaling becoming impractical in large networks. This work adopts a user-centric approach, a scalable alternative in which only a set of preferred APs jointly serve a UE. Forming the optimal cluster of APs for each UE is a challenging task, especially, when it needs to be dynamically adjusted to meet the quality of service (QoS) requirements of the UE. This complexity is even exacerbated when considering the constrained fronthaul capacity of the UE and the AP. We solve this problem with a novel many-to-many matching game. More specifically, we devise an early acceptance matching algorithm, which immediately admits or rejects UEs based on their requests and available radio resources. The proposed solution significantly reduces the fronthaul signaling while satisfying the maximum of UEs in terms of requested QoS compared to state-of-the-art approaches.",
    "authors": [
      "Ala Eddine Nouali",
      "Mohamed Sana",
      "Jean-Paul Jamont"
    ],
    "url": "http://arxiv.org/abs/2406.06402v1",
    "timestamp": 1718034974,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.SP",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "bbe45aba-e405-4093-bc95-a004a4da4607": {
    "pk": "bbe45aba-e405-4093-bc95-a004a4da4607",
    "title": "INTERSPEECH 2009 Emotion Challenge Revisited: Benchmarking 15 Years of Progress in Speech Emotion Recognition",
    "abstract": "We revisit the INTERSPEECH 2009 Emotion Challenge -- the first ever speech emotion recognition (SER) challenge -- and evaluate a series of deep learning models that are representative of the major advances in SER research in the time since then. We start by training each model using a fixed set of hyperparameters, and further fine-tune the best-performing models of that initial setup with a grid search. Results are always reported on the official test set with a separate validation set only used for early stopping. Most models score below or close to the official baseline, while they marginally outperform the original challenge winners after hyperparameter tuning. Our work illustrates that, despite recent progress, FAU-AIBO remains a very challenging benchmark. An interesting corollary is that newer methods do not consistently outperform older ones, showing that progress towards `solving' SER is not necessarily monotonic.",
    "authors": [
      "Andreas Triantafyllopoulos",
      "Anton Batliner",
      "Simon Rampp",
      "Manuel Milling",
      "Bj\u00f6rn Schuller"
    ],
    "url": "http://arxiv.org/abs/2406.06401v1",
    "timestamp": 1718034906,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "950255c7-3594-477b-b8eb-4d103c6153e0": {
    "pk": "950255c7-3594-477b-b8eb-4d103c6153e0",
    "title": "An Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics",
    "abstract": "The integration of Large Language Models (LLMs) in social robotics presents a unique set of ethical challenges and social impacts. This research is set out to identify ethical considerations that arise in the design and development of these two technologies in combination. Using LLMs for social robotics may provide benefits, such as enabling natural language open-domain dialogues. However, the intersection of these two technologies also gives rise to ethical concerns related to misinformation, non-verbal cues, emotional disruption, and biases. The robot's physical social embodiment adds complexity, as ethical hazards associated with LLM-based Social AI, such as hallucinations and misinformation, can be exacerbated due to the effects of physical embodiment on social perception and communication. To address these challenges, this study employs an empirical design justice-based methodology, focusing on identifying socio-technical ethical considerations through a qualitative co-design and interaction study. The purpose of the study is to identify ethical considerations relevant to the process of co-design of, and interaction with a humanoid social robot as the interface of a LLM, and to evaluate how a design justice methodology can be used in the context of designing LLMs-based social robotics. The findings reveal a mapping of ethical considerations arising in four conceptual dimensions: interaction, co-design, terms of service and relationship and evaluates how a design justice approach can be used empirically in the intersection of LLMs and social robotics.",
    "authors": [
      "Alva Markelius"
    ],
    "url": "http://arxiv.org/abs/2406.06400v1",
    "timestamp": 1718034830,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c4eaf780-7d46-411b-8b8a-34956c7617d4": {
    "pk": "c4eaf780-7d46-411b-8b8a-34956c7617d4",
    "title": "Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue",
    "abstract": "We study the limitations of Large Language Models (LLMs) for the task of response generation in human-machine dialogue. Several techniques have been proposed in the literature for different dialogue types (e.g., Open-Domain). However, the evaluations of these techniques have been limited in terms of base LLMs, dialogue types and evaluation metrics. In this work, we extensively analyze different LLM adaptation techniques when applied to different dialogue types. We have selected two base LLMs, Llama-2 and Mistral, and four dialogue types Open-Domain, Knowledge-Grounded, Task-Oriented, and Question Answering. We evaluate the performance of in-context learning and fine-tuning techniques across datasets selected for each dialogue type. We assess the impact of incorporating external knowledge to ground the generation in both scenarios of Retrieval-Augmented Generation (RAG) and gold knowledge. We adopt consistent evaluation and explainability criteria for automatic metrics and human evaluation protocols. Our analysis shows that there is no universal best-technique for adapting large language models as the efficacy of each technique depends on both the base LLM and the specific type of dialogue. Last but not least, the assessment of the best adaptation technique should include human evaluation to avoid false expectations and outcomes derived from automatic metrics.",
    "authors": [
      "Simone Alghisi",
      "Massimo Rizzoli",
      "Gabriel Roccabruna",
      "Seyed Mahed Mousavi",
      "Giuseppe Riccardi"
    ],
    "url": "http://arxiv.org/abs/2406.06399v1",
    "timestamp": 1718034769,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f7368143-3e44-4ab4-83da-45ff7fd93874": {
    "pk": "f7368143-3e44-4ab4-83da-45ff7fd93874",
    "title": "Contrastive learning of T cell receptor representations",
    "abstract": "Computational prediction of the interaction of T cell receptors (TCRs) and their ligands is a grand challenge in immunology. Despite advances in high-throughput assays, specificity-labelled TCR data remains sparse. In other domains, the pre-training of language models on unlabelled data has been successfully used to address data bottlenecks. However, it is unclear how to best pre-train protein language models for TCR specificity prediction. Here we introduce a TCR language model called SCEPTR (Simple Contrastive Embedding of the Primary sequence of T cell Receptors), capable of data-efficient transfer learning. Through our model, we introduce a novel pre-training strategy combining autocontrastive learning and masked-language modelling, which enables SCEPTR to achieve its state-of-the-art performance. In contrast, existing protein language models and a variant of SCEPTR pre-trained without autocontrastive learning are outperformed by sequence alignment-based methods. We anticipate that contrastive learning will be a useful paradigm to decode the rules of TCR specificity.",
    "authors": [
      "Yuta Nagano",
      "Andrew Pyo",
      "Martina Milighetti",
      "James Henderson",
      "John Shawe-Taylor",
      "Benny Chain",
      "Andreas Tiffeau-Mayer"
    ],
    "url": "http://arxiv.org/abs/2406.06397v1",
    "timestamp": 1718034645,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "q-bio.BM",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "1af085b4-97ca-485c-979b-825bb038a621": {
    "pk": "1af085b4-97ca-485c-979b-825bb038a621",
    "title": "STimage-1K4M: A histopathology image-gene expression dataset for spatial transcriptomics",
    "abstract": "Recent advances in multi-modal algorithms have driven and been driven by the increasing availability of large image-text datasets, leading to significant strides in various fields, including computational pathology. However, in most existing medical image-text datasets, the text typically provides high-level summaries that may not sufficiently describe sub-tile regions within a large pathology image. For example, an image might cover an extensive tissue area containing cancerous and healthy regions, but the accompanying text might only specify that this image is a cancer slide, lacking the nuanced details needed for in-depth analysis. In this study, we introduce STimage-1K4M, a novel dataset designed to bridge this gap by providing genomic features for sub-tile images. STimage-1K4M contains 1,149 images derived from spatial transcriptomics data, which captures gene expression information at the level of individual spatial spots within a pathology image. Specifically, each image in the dataset is broken down into smaller sub-image tiles, with each tile paired with 15,000-30,000 dimensional gene expressions. With 4,293,195 pairs of sub-tile images and gene expressions, STimage-1K4M offers unprecedented granularity, paving the way for a wide range of advanced research in multi-modal data analysis an innovative applications in computational pathology, and beyond.",
    "authors": [
      "Jiawen Chen",
      "Muqing Zhou",
      "Wenrong Wu",
      "Jinwei Zhang",
      "Yun Li",
      "Didong Li"
    ],
    "url": "http://arxiv.org/abs/2406.06393v1",
    "timestamp": 1718034487,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "3bd1bce4-db18-4954-ac70-d8339e45ab23": {
    "pk": "3bd1bce4-db18-4954-ac70-d8339e45ab23",
    "title": "Tackling Delayed CSI in a Distributed Multi-Satellite MIMO Communication System",
    "abstract": "In this study, we explore the integration of satellites with ground-based communication networks. Specifically, we analyze downlink data transmission from a constellation of satellites to terrestrial users and address the issue of delayed channel state information (CSI). The satellites cooperate in data transmission within a cluster to create a unified, distributed massive multiple input, multiple output (MIMO) system. The CSI used for this process is inherently outdated, particularly due to the delay from the most distant satellite in the cluster. Therefore, in this paper, we develop a precoding strategy that leverages the long-term characteristics of CSI uncertainty to compensate for the undesirable impact of these unavoidable delays. Our proposed method is computationally efficient and particularly effective in lower frequency bands. As such, it holds significant promise for facilitating the integration of satellite and terrestrial communication, especially within frequency bands of up to 1 GHz.",
    "authors": [
      "Yasaman Omid",
      "Sangarapillai Lambotharan",
      "Mahsa Derakhshani"
    ],
    "url": "http://arxiv.org/abs/2406.06392v1",
    "timestamp": 1718034403,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.SP",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "901eaa12-f306-442f-ab61-c3166e98937f": {
    "pk": "901eaa12-f306-442f-ab61-c3166e98937f",
    "title": "Towards Lifelong Learning of Large Language Models: A Survey",
    "abstract": "As the applications of large language models (LLMs) expand across diverse fields, the ability of these models to adapt to ongoing changes in data, tasks, and user preferences becomes crucial. Traditional training methods, relying on static datasets, are increasingly inadequate for coping with the dynamic nature of real-world information. Lifelong learning, also known as continual or incremental learning, addresses this challenge by enabling LLMs to learn continuously and adaptively over their operational lifetime, integrating new knowledge while retaining previously learned information and preventing catastrophic forgetting. This survey delves into the sophisticated landscape of lifelong learning, categorizing strategies into two primary groups: Internal Knowledge and External Knowledge. Internal Knowledge includes continual pretraining and continual finetuning, each enhancing the adaptability of LLMs in various scenarios. External Knowledge encompasses retrieval-based and tool-based lifelong learning, leveraging external data sources and computational tools to extend the model's capabilities without modifying core parameters. The key contributions of our survey are: (1) Introducing a novel taxonomy categorizing the extensive literature of lifelong learning into 12 scenarios; (2) Identifying common techniques across all lifelong learning scenarios and classifying existing literature into various technique groups within each scenario; (3) Highlighting emerging techniques such as model expansion and data selection, which were less explored in the pre-LLM era. Through a detailed examination of these groups and their respective categories, this survey aims to enhance the adaptability, reliability, and overall performance of LLMs in real-world applications.",
    "authors": [
      "Junhao Zheng",
      "Shengjie Qiu",
      "Chengming Shi",
      "Qianli Ma"
    ],
    "url": "http://arxiv.org/abs/2406.06391v1",
    "timestamp": 1718034385,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "add14742-8e71-4bcb-83a0-d6a4f19e6acf": {
    "pk": "add14742-8e71-4bcb-83a0-d6a4f19e6acf",
    "title": "Reconstructing the genealogy of LIGO-Virgo black holes",
    "abstract": "We propose a Bayesian inference framework to predict the merger history of LIGO-Virgo binary black holes, whose binary components may have undergone hierarchical mergers in the past. The framework relies on numerical relativity predictions for the mass, spin, and kick velocity of the remnant black holes. This proposed framework computes the masses, spins, and kicks imparted to the remnant of the parent binaries, given the initial masses and spin magnitudes of the binary constituents. We validate our approach by performing an \"injection study\" based on a constructed sequence of hierarchically-formed binaries. Noise is added to the final binary in the sequence, and the parameters of the 'parent' and 'grandparent' binaries in the merger chain are then reconstructed. This method is then applied to three GWTC-3 events: GW190521, GW200220_061928, GW190426_190642. These events were selected because at least one of the binary companions lies in the putative pair-instability supernova mass gap, in which stellar processes alone cannot produce black holes. Hierarchical mergers offer a natural explanation for the formation of black holes in the pair-instability mass-gap. We use the backward evolution framework to predict the parameters of the parents of the primary companion of these three binaries. Our results indicate that at least one component of these three observed binaries was formed through a prior binary black hole merger. This approach can be readily applied to future high-mass gravitational wave events to predict their formation history under the hierarchical merger assumption.",
    "authors": [
      "Parthapratim Mahapatra",
      "Debatri Chattopadhyay",
      "Anuradha Gupta",
      "Fabio Antonini",
      "Marc Favata",
      "B. S. Sathyaprakash",
      "K. G. Arun"
    ],
    "url": "http://arxiv.org/abs/2406.06390v1",
    "timestamp": 1718034338,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.HE",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f34b21ae-2288-44a8-945f-a435e6eca496": {
    "pk": "f34b21ae-2288-44a8-945f-a435e6eca496",
    "title": "Low-Rank Quantization-Aware Training for LLMs",
    "abstract": "Large language models (LLMs) are omnipresent, however their practical deployment is challenging due to their ever increasing computational and memory demands. Quantization is one of the most effective ways to make them more compute and memory efficient. Quantization-aware training (QAT) methods, generally produce the best quantized performance, however it comes at the cost of potentially long training time and excessive memory usage, making it impractical when applying for LLMs. Inspired by parameter-efficient fine-tuning (PEFT) and low-rank adaptation (LoRA) literature, we propose LR-QAT -- a lightweight and memory-efficient QAT algorithm for LLMs. LR-QAT employs several components to save memory without sacrificing predictive performance: (a) low-rank auxiliary weights that are aware of the quantization grid; (b) a downcasting operator using fixed-point or double-packed integers and (c) checkpointing. Unlike most related work, our method (i) is inference-efficient, leading to no additional overhead compared to traditional PTQ; (ii) can be seen as a general extended pretraining framework, meaning that the resulting model can still be utilized for any downstream task afterwards; (iii) can be applied across a wide range of quantization settings, such as different choices quantization granularity, activation quantization, and seamlessly combined with many PTQ techniques. We apply LR-QAT to the LLaMA-2/3 and Mistral model families and validate its effectiveness on several downstream tasks. Our method outperforms common post-training quantization (PTQ) approaches and reaches the same model performance as full-model QAT at the fraction of its memory usage. Specifically, we can train a 7B LLM on a single consumer grade GPU with 24GB of memory.",
    "authors": [
      "Yelysei Bondarenko",
      "Riccardo Del Chiaro",
      "Markus Nagel"
    ],
    "url": "http://arxiv.org/abs/2406.06385v1",
    "timestamp": 1718034262,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "81f84562-c0e4-4d52-8428-3f63160f2490": {
    "pk": "81f84562-c0e4-4d52-8428-3f63160f2490",
    "title": "Diffusion-RPO: Aligning Diffusion Models through Relative Preference Optimization",
    "abstract": "Aligning large language models with human preferences has emerged as a critical focus in language modeling research. Yet, integrating preference learning into Text-to-Image (T2I) generative models is still relatively uncharted territory. The Diffusion-DPO technique made initial strides by employing pairwise preference learning in diffusion models tailored for specific text prompts. We introduce Diffusion-RPO, a new method designed to align diffusion-based T2I models with human preferences more effectively. This approach leverages both prompt-image pairs with identical prompts and those with semantically related content across various modalities. Furthermore, we have developed a new evaluation metric, style alignment, aimed at overcoming the challenges of high costs, low reproducibility, and limited interpretability prevalent in current evaluations of human preference alignment. Our findings demonstrate that Diffusion-RPO outperforms established methods such as Supervised Fine-Tuning and Diffusion-DPO in tuning Stable Diffusion versions 1.5 and XL-1.0, achieving superior results in both automated evaluations of human preferences and style alignment. Our code is available at https://github.com/yigu1008/Diffusion-RPO",
    "authors": [
      "Yi Gu",
      "Zhendong Wang",
      "Yueqin Yin",
      "Yujia Xie",
      "Mingyuan Zhou"
    ],
    "url": "http://arxiv.org/abs/2406.06382v1",
    "timestamp": 1718034123,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "7331fc97-e9cc-4e59-aeb6-74aae66f446d": {
    "pk": "7331fc97-e9cc-4e59-aeb6-74aae66f446d",
    "title": "Feature Characterization for Profile Surface Texture",
    "abstract": "Conventional field parameters for surface measurement use all data points, while feature characterization focuses on subsets extracted by watershed segmentation. This approach enables the extraction of specific features that are potentially responsible for the function of the surface or are a direct reflection of the manufacturing process, allowing for a more accurate assessment of both aspects. Feature characterization with the underlying watershed segmentation for areal surface topographies has been standardized for over a decade and is well established in industry and research. In contrast, feature characterization for surface profiles has been standardized recently, and the corresponding standard for watershed segmentation is planned to be published in the near future. Since the standards do not provide guidelines for implementation, this paper presents an unambiguous algorithm of the watershed segmentation and the feature characterization for surface profiles. This framework provides the basis for future work, mainly investigating the relationship between feature parameters based on feature characterization and the function of the surface or manufacturing process. For this purpose, recommendations for the configuration and extensions of the toolbox can also be developed, which could find their way into the ISO standards.",
    "authors": [
      "Alexander M\u00fcller",
      "Matthias Eifler",
      "Arsalan Jawaid",
      "J\u00f6rg Seewig"
    ],
    "url": "http://arxiv.org/abs/2406.06381v1",
    "timestamp": 1718034062,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.SP",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "72dbc245-c529-4b99-aa09-60e92d0721c5": {
    "pk": "72dbc245-c529-4b99-aa09-60e92d0721c5",
    "title": "The number of connected components in sub-critical random graph processes",
    "abstract": "We present a detailed study of the evolution of the number of connected components in sub-critical multiplicative random graph processes. We consider a model where edges appear independently after an exponential time at rate equal to the product of the sizes of the vertices. We provide an explicit expression for the fluid limit of the number of connected components normalized by its initial value, when the time is smaller than the inverse of the sum of the square of the initial vertex sizes. We also identify the diffusion limit of the rescaled fluctuations around the fluid limit. This is applied to several examples. In the particular setting of the Erd\\H{o}s-R\\'enyi graph process, we explicit the fluid limit of the number of connected components normalized, and the diffusion limit of the scaled fluctuations in the sub-critical regime, where the mean degree is between zero and one.",
    "authors": [
      "Josu\u00e9 Corujo"
    ],
    "url": "http://arxiv.org/abs/2406.06380v1",
    "timestamp": 1718034025,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.PR",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "54d624f5-5f19-4a1c-8789-6af6b35f0ecd": {
    "pk": "54d624f5-5f19-4a1c-8789-6af6b35f0ecd",
    "title": "FinVerse: An Autonomous Agent System for Versatile Financial Analysis",
    "abstract": "With the significant advancements in cognitive intelligence driven by LLMs, autonomous agent systems have attracted extensive attention. Despite this growing interest, the development of stable and efficient agent systems poses substantial practical challenges. In this paper, we introduce FinVerse, a meticulously crafted agent system designed for a broad range of financial topics. FinVerse integrates over 600 financial APIs, enabling access to more accurate and extensive financial information compared to generalist agents. To enhance financial information processing capabilities, FinVerse is equipped with an embedded code interpreter, enabling the execution of complex data analysis tasks with precision and efficiency. Our work includes an empirical comparison of several LLMs in driving FinVerse. Specifically, we propose our own scheme for training LLMs using SFT to optimize LLM performance within FinVerse. Recognizing the scarcity of specialized datasets to build LLMs for agents, we have constructed a dataset and plan to make it open-source, providing a valuable resource for peer application developers. The demo video has been released on YouTube at https://www.youtube.com/watch?v=sk8L9_Wv7J4",
    "authors": [
      "Siyu An",
      "Qin Li",
      "Junru Lu",
      "Di Yin",
      "Xing Sun"
    ],
    "url": "http://arxiv.org/abs/2406.06379v1",
    "timestamp": 1718034023,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CE",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "30e2b528-ec2a-4521-a737-3f0a9de86046": {
    "pk": "30e2b528-ec2a-4521-a737-3f0a9de86046",
    "title": "MOSA: Music Motion with Semantic Annotation Dataset for Cross-Modal Music Processing",
    "abstract": "In cross-modal music processing, translation between visual, auditory, and semantic content opens up new possibilities as well as challenges. The construction of such a transformative scheme depends upon a benchmark corpus with a comprehensive data infrastructure. In particular, the assembly of a large-scale cross-modal dataset presents major challenges. In this paper, we present the MOSA (Music mOtion with Semantic Annotation) dataset, which contains high quality 3-D motion capture data, aligned audio recordings, and note-by-note semantic annotations of pitch, beat, phrase, dynamic, articulation, and harmony for 742 professional music performances by 23 professional musicians, comprising more than 30 hours and 570 K notes of data. To our knowledge, this is the largest cross-modal music dataset with note-level annotations to date. To demonstrate the usage of the MOSA dataset, we present several innovative cross-modal music information retrieval (MIR) and musical content generation tasks, including the detection of beats, downbeats, phrase, and expressive contents from audio, video and motion data, and the generation of musicians' body motion from given music audio. The dataset and codes are available alongside this publication (https://github.com/yufenhuang/MOSA-Music-mOtion-and-Semantic-Annotation-dataset).",
    "authors": [
      "Yu-Fen Huang",
      "Nikki Moran",
      "Simon Coleman",
      "Jon Kelly",
      "Shun-Hwa Wei",
      "Po-Yin Chen",
      "Yun-Hsin Huang",
      "Tsung-Ping Chen",
      "Yu-Chia Kuo",
      "Yu-Chi Wei",
      "Chih-Hsuan Li",
      "Da-Yu Huang",
      "Hsuan-Kai Kao",
      "Ting-Wei Lin",
      "Li Su"
    ],
    "url": "http://arxiv.org/abs/2406.06375v1",
    "timestamp": 1718033866,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.SD",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "fec1fda5-cdac-4b1a-9fd7-b38b34807f81": {
    "pk": "fec1fda5-cdac-4b1a-9fd7-b38b34807f81",
    "title": "mHuBERT-147: A Compact Multilingual HuBERT Model",
    "abstract": "We present mHuBERT-147, the first general-purpose massively multilingual HuBERT speech representation model trained on 90K hours of clean, open-license data. To scale up the multi-iteration HuBERT approach, we use faiss-based clustering, achieving 5.2x faster label assignment over the original method. We also apply a new multilingual batching up-sampling strategy, leveraging both language and dataset diversity. After 3 training iterations and with only 95M parameters, mHuBERT-147 outperforms larger models trained on substantially more data. We rank second and first on the ML-SUPERB 10min/1h leaderboards respectively, with SOTA scores for all LID tasks. Across ASR/LID tasks, our model consistently surpasses XLS-R (300M params; 436K hours) and demonstrates strong competitiveness against the much larger MMS (1B params; 491K hours). Our findings suggest that mHuBERT-147 is a promising model for multilingual speech processing tasks, offering an unprecedented balance between high performance and parameter efficiency.",
    "authors": [
      "Marcely Zanon Boito",
      "Vivek Iyer",
      "Nikolaos Lagos",
      "Laurent Besacier",
      "Ioan Calapodescu"
    ],
    "url": "http://arxiv.org/abs/2406.06371v1",
    "timestamp": 1718033562,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "26d6f147-05c1-4b23-af4f-bf851635616a": {
    "pk": "26d6f147-05c1-4b23-af4f-bf851635616a",
    "title": "Annotation alignment: Comparing LLM and human annotations of conversational safety",
    "abstract": "To what extent to do LLMs align with human perceptions of safety? We study this question via *annotation alignment*, the extent to which LLMs and humans agree when annotating the safety of user-chatbot conversations. We leverage the recent DICES dataset (Aroyo et al., 2023), in which 350 conversations are each rated for safety by 112 annotators spanning 10 race-gender groups. GPT-4 achieves a Pearson correlation of $r = 0.59$ with the average annotator rating, higher than the median annotator's correlation with the average ($r=0.51$). We show that larger datasets are needed to resolve whether GPT-4 exhibits disparities in how well it correlates with demographic groups. Also, there is substantial idiosyncratic variation in correlation *within* groups, suggesting that race & gender do not fully capture differences in alignment. Finally, we find that GPT-4 cannot predict when one demographic group finds a conversation more unsafe than another.",
    "authors": [
      "Rajiv Movva",
      "Pang Wei Koh",
      "Emma Pierson"
    ],
    "url": "http://arxiv.org/abs/2406.06369v1",
    "timestamp": 1718033413,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "079af4bb-5484-46bf-877c-20e156f52977": {
    "pk": "079af4bb-5484-46bf-877c-20e156f52977",
    "title": "Symmetric Dot-Product Attention for Efficient Training of BERT Language Models",
    "abstract": "Initially introduced as a machine translation model, the Transformer architecture has now become the foundation for modern deep learning architecture, with applications in a wide range of fields, from computer vision to natural language processing. Nowadays, to tackle increasingly more complex tasks, Transformer-based models are stretched to enormous sizes, requiring increasingly larger training datasets, and unsustainable amount of compute resources. The ubiquitous nature of the Transformer and its core component, the attention mechanism, are thus prime targets for efficiency research. In this work, we propose an alternative compatibility function for the self-attention mechanism introduced by the Transformer architecture. This compatibility function exploits an overlap in the learned representation of the traditional scaled dot-product attention, leading to a symmetric with pairwise coefficient dot-product attention. When applied to the pre-training of BERT-like models, this new symmetric attention mechanism reaches a score of 79.36 on the GLUE benchmark against 78.74 for the traditional implementation, leads to a reduction of 6% in the number of trainable parameters, and reduces the number of training steps required before convergence by half.",
    "authors": [
      "Martin Courtois",
      "Malte Ostendorff",
      "Leonhard Hennig",
      "Georg Rehm"
    ],
    "url": "http://arxiv.org/abs/2406.06366v1",
    "timestamp": 1718033055,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "aa3022a6-c597-4545-b2e0-43ad25d56b58": {
    "pk": "aa3022a6-c597-4545-b2e0-43ad25d56b58",
    "title": "MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows",
    "abstract": "Scientific innovation relies on detailed workflows, which include critical steps such as analyzing literature, generating ideas, validating these ideas, interpreting results, and inspiring follow-up research. However, scientific publications that document these workflows are extensive and unstructured. This makes it difficult for both human researchers and AI systems to effectively navigate and explore the space of scientific innovation. To address this issue, we introduce MASSW, a comprehensive text dataset on Multi-Aspect Summarization of Scientific Workflows. MASSW includes more than 152,000 peer-reviewed publications from 17 leading computer science conferences spanning the past 50 years. Using Large Language Models (LLMs), we automatically extract five core aspects from these publications -- context, key idea, method, outcome, and projected impact -- which correspond to five key steps in the research workflow. These structured summaries facilitate a variety of downstream tasks and analyses. The quality of the LLM-extracted summaries is validated by comparing them with human annotations. We demonstrate the utility of MASSW through multiple novel machine-learning tasks that can be benchmarked using this new dataset, which make various types of predictions and recommendations along the scientific workflow. MASSW holds significant potential for researchers to create and benchmark new AI methods for optimizing scientific workflows and fostering scientific innovation in the field. Our dataset is openly available at \\url{https://github.com/xingjian-zhang/massw}.",
    "authors": [
      "Xingjian Zhang",
      "Yutong Xie",
      "Jin Huang",
      "Jinge Ma",
      "Zhaoying Pan",
      "Qijia Liu",
      "Ziyang Xiong",
      "Tolga Ergen",
      "Dongsub Shim",
      "Honglak Lee",
      "Qiaozhu Mei"
    ],
    "url": "http://arxiv.org/abs/2406.06357v1",
    "timestamp": 1718032749,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "58f666f2-59d3-43e3-9ed6-d1b92c8aae3c": {
    "pk": "58f666f2-59d3-43e3-9ed6-d1b92c8aae3c",
    "title": "Sustained Vowels for Pre- vs Post-Treatment COPD Classification",
    "abstract": "Chronic obstructive pulmonary disease (COPD) is a serious inflammatory lung disease affecting millions of people around the world. Due to an obstructed airflow from the lungs, it also becomes manifest in patients' vocal behaviour. Of particular importance is the detection of an exacerbation episode, which marks an acute phase and often requires hospitalisation and treatment. Previous work has shown that it is possible to distinguish between a pre- and a post-treatment state using automatic analysis of read speech. In this contribution, we examine whether sustained vowels can provide a complementary lens for telling apart these two states. Using a cohort of 50 patients, we show that the inclusion of sustained vowels can improve performance to up to 79\\% unweighted average recall, from a 71\\% baseline using read speech. We further identify and interpret the most important acoustic features that characterise the manifestation of COPD in sustained vowels.",
    "authors": [
      "Andreas Triantafyllopoulos",
      "Anton Batliner",
      "Wolfgang Mayr",
      "Markus Fendler",
      "Florian Pokorny",
      "Maurice Gerczuk",
      "Shahin Amiriparian",
      "Thomas Berghaus",
      "Bj\u00f6rn Schuller"
    ],
    "url": "http://arxiv.org/abs/2406.06355v1",
    "timestamp": 1718032637,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "89049bf2-8efd-481a-810b-b031ca83645d": {
    "pk": "89049bf2-8efd-481a-810b-b031ca83645d",
    "title": "A quantitative investigation for deployment of mobile collaborative robots in high-value manufacturing",
    "abstract": "Component inspection is often the bottleneck in high-value manufacturing, driving industries like aerospace toward automated inspection technologies. Current systems often employ fixed arm robots, but they lack the flexibility in adapting to new components or orientations Advanced mobile robotic platforms with updated sensor technologies and algorithms have improved localization and path planning capabilities, making them ideal for bringing inspection processes directly to parts. However, mobile platforms introduce challenges in localization and maneuverability, leading to potential errors. Their positional uncertainty is higher than fixed systems due to the lack of a fixed calibrated location, posing challenges for position-sensitive inspection sensors. Therefore, it's essential to assess the positional accuracy and repeatability of mobile manipulator platforms. The KUKA KMR iiwa was chosen for its collaborative features, robust build, and scalability within the KUKA product range. The accuracy and repeatability of the mobile platform were evaluated through a series of tests to evaluate the performance of its integrated feature mapping, the effect of various speeds on positional accuracy, and the efficiency of the omnidirectional wheels for a range of translation orientations. Experimental evaluation revealed that enabling feature mapping substantially improves the KUKA KMR iiwa's performance, with accuracy gains and error reductions exceeding 90%. Repeatability errors were under 7 mm with mapping activated and around 2.5 mm in practical scenarios, demonstrating that mobile manipulators, incorporating both the manipulator and platform, can fulfil the precise requirements of industries with high precision needs. Providing a highly diverse alternative to traditional fixed-base industrial manipulators.",
    "authors": [
      "Amine Hifi",
      "W. Jackson",
      "C. Loukas",
      "M. Shields",
      "A. Poole",
      "E. Mohseni",
      "C. N. MacLeod",
      "G. Dobie",
      "S. G. Pierce",
      "T. O'Hare",
      "G. Munro",
      "J. O'Brian-O'Reilly",
      "R. W. K. Vithanage"
    ],
    "url": "http://arxiv.org/abs/2406.06353v1",
    "timestamp": 1718032437,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "a0b14d45-af81-4de8-bd5c-590500602b34": {
    "pk": "a0b14d45-af81-4de8-bd5c-590500602b34",
    "title": "Latent Directions: A Simple Pathway to Bias Mitigation in Generative AI",
    "abstract": "Mitigating biases in generative AI and, particularly in text-to-image models, is of high importance given their growing implications in society. The biased datasets used for training pose challenges in ensuring the responsible development of these models, and mitigation through hard prompting or embedding alteration, are the most common present solutions. Our work introduces a novel approach to achieve diverse and inclusive synthetic images by learning a direction in the latent space and solely modifying the initial Gaussian noise provided for the diffusion process. Maintaining a neutral prompt and untouched embeddings, this approach successfully adapts to diverse debiasing scenarios, such as geographical biases. Moreover, our work proves it is possible to linearly combine these learned latent directions to introduce new mitigations, and if desired, integrate it with text embedding adjustments. Furthermore, text-to-image models lack transparency for assessing bias in outputs, unless visually inspected. Thus, we provide a tool to empower developers to select their desired concepts to mitigate. The project page with code is available online.",
    "authors": [
      "Carolina Lopez Olmos",
      "Alexandros Neophytou",
      "Sunando Sengupta",
      "Dim P. Papadopoulos"
    ],
    "url": "http://arxiv.org/abs/2406.06352v1",
    "timestamp": 1718032431,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "beeaa11f-48cf-485e-bd87-03dedab799de": {
    "pk": "beeaa11f-48cf-485e-bd87-03dedab799de",
    "title": "Cascading Unknown Detection with Known Classification for Open Set Recognition",
    "abstract": "Deep learners tend to perform well when trained under the closed set assumption but struggle when deployed under open set conditions. This motivates the field of Open Set Recognition in which we seek to give deep learners the ability to recognize whether a data sample belongs to the known classes trained on or comes from the surrounding infinite world. Existing open set recognition methods typically rely upon a single function for the dual task of distinguishing between knowns and unknowns as well as making known class distinction. This dual process leaves performance on the table as the function is not specialized for either task. In this work, we introduce Cascading Unknown Detection with Known Classification (Cas-DC), where we instead learn specialized functions in a cascading fashion for both known/unknown detection and fine class classification amongst the world of knowns. Our experiments and analysis demonstrate that Cas-DC handily outperforms modern methods in open set recognition when compared using AUROC scores and correct classification rate at various true positive rates.",
    "authors": [
      "Daniel Brignac",
      "Abhijit Mahalanobis"
    ],
    "url": "http://arxiv.org/abs/2406.06351v1",
    "timestamp": 1718032387,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f1b036fc-f9ea-491c-ae37-09e9a8efa767": {
    "pk": "f1b036fc-f9ea-491c-ae37-09e9a8efa767",
    "title": "ARMA Processes with Discrete-Continuous Excitation: Compressibility Beyond Sparsity",
    "abstract": "R\\'enyi Information Dimension (RID) plays a central role in quantifying the compressibility of random variables with singularities in their distribution, encompassing and extending beyond the class of sparse sources. The RID, from a high perspective, presents the average number of bits that is needed for coding the i.i.d. samples of a random variable with high precision. There are two main extensions of the RID for stochastic processes: information dimension rate (IDR) and block information dimension (BID). In addition, a more recent approach towards the compressibility of stochastic processes revolves around the concept of $\\epsilon$-achievable compression rates, which treat a random process as the limiting point of finite-dimensional random vectors and apply the compressed sensing tools on these random variables. While there is limited knowledge about the interplay of the the BID, the IDR, and $\\epsilon$-achievable compression rates, the value of IDR and BID themselves are known only for very specific types of processes, namely i.i.d. sequences (i.e., discrete-domain white noise) and moving-average (MA) processes. This paper investigates the IDR and BID of discrete-time Auto-Regressive Moving-Average (ARMA) processes in general, and their relations with $\\epsilon$-achievable compression rates when the excitation noise has a discrete-continuous measure. To elaborate, this paper shows that the RID and $\\epsilon$-achievable compression rates of this type of processes are equal to that of their excitation noise. In other words, the samples of such ARMA processes can be compressed as much as their sparse excitation noise, although the samples themselves are by no means sparse. The results of this paper can be used to evaluate the compressibility of various types of locally correlated data with finite- or infinite-memory as they are often modelled via ARMA processes.",
    "authors": [
      "Mohammad-Amin Charusaie",
      "Stefano Rini",
      "Arash Amini"
    ],
    "url": "http://arxiv.org/abs/2406.06349v1",
    "timestamp": 1718032198,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.IT",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "568cba02-5c17-4098-a89e-b19cd35f1a86": {
    "pk": "568cba02-5c17-4098-a89e-b19cd35f1a86",
    "title": "Thin Film Reconfigurable Intelligent Surface for Harmonic Beam Steering",
    "abstract": "This letter explores the development and implementation of a novel thin film 1-by-4 reconfigurable intelligent surface (RIS) designed for future communication and sensing scenarios. Utilizing cost-effective inkjet printing methods and additive manufacturing, our approach significantly simplifies the RIS construction process and reduces production costs. The RIS, fabricated on a flexible and lightweight polyethylene terephthalate (PET) substrate, integrates antennas, switching circuitry, and a microcontroller unit (MCU). This setup enables individual and simultaneous control of each RIS element, manipulating the captured carrier signal by steering its dominant harmonics toward multiple desired directions. Measurement results of the beam steering show the manufactured RIS has the potential to enable RIS-aided communication and sensing applications.",
    "authors": [
      "Boxuan Xie",
      "Aleksandr Kuznetsov",
      "Lauri Mela",
      "Jari Lietz\u00e9n",
      "Kalle Ruttik",
      "Alp Karako\u00e7",
      "Riku J\u00e4ntti"
    ],
    "url": "http://arxiv.org/abs/2406.06343v1",
    "timestamp": 1718031792,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.SP",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "057f9150-5f7c-4632-90b8-17a2ef498771": {
    "pk": "057f9150-5f7c-4632-90b8-17a2ef498771",
    "title": "Predicting Heart Activity from Speech using Data-driven and Knowledge-based features",
    "abstract": "Accurately predicting heart activity and other biological signals is crucial for diagnosis and monitoring. Given that speech is an outcome of multiple physiological systems, a significant body of work studied the acoustic correlates of heart activity. Recently, self-supervised models have excelled in speech-related tasks compared to traditional acoustic methods. However, the robustness of data-driven representations in predicting heart activity remained unexplored. In this study, we demonstrate that self-supervised speech models outperform acoustic features in predicting heart activity parameters. We also emphasize the impact of individual variability on model generalizability. These findings underscore the value of data-driven representations in such tasks and the need for more speech-based physiological data to mitigate speaker-related challenges.",
    "authors": [
      "Gasser Elbanna",
      "Zohreh Mostaani",
      "Mathew Magimai. -Doss"
    ],
    "url": "http://arxiv.org/abs/2406.06341v1",
    "timestamp": 1718031706,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.SD",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "ac6bb959-33e6-4397-ad29-2962de5970df": {
    "pk": "ac6bb959-33e6-4397-ad29-2962de5970df",
    "title": "Audio-based Step-count Estimation for Running -- Windowing and Neural Network Baselines",
    "abstract": "In recent decades, running has become an increasingly popular pastime activity due to its accessibility, ease of practice, and anticipated health benefits. However, the risk of running-related injuries is substantial for runners of different experience levels. Several common forms of injuries result from overuse -- extending beyond the recommended running time and intensity. Recently, audio-based tracking has emerged as yet another modality for monitoring running behaviour and performance, with previous studies largely concentrating on predicting runner fatigue. In this work, we investigate audio-based step count estimation during outdoor running, achieving a mean absolute error of 1.098 in window-based step-count differences and a Pearson correlation coefficient of 0.479 when predicting the number of steps in a 5-second window of audio. Our work thus showcases the feasibility of audio-based monitoring for estimating important physiological variables and lays the foundations for further utilising audio sensors for a more thorough characterisation of runner behaviour.",
    "authors": [
      "Philipp Wagner",
      "Andreas Triantafyllopoulos",
      "Alexander Gebhard",
      "Bj\u00f6rn Schuller"
    ],
    "url": "http://arxiv.org/abs/2406.06339v1",
    "timestamp": 1718031541,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.SD",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "22313506-64f8-4067-ad51-8ea199e3cc0d": {
    "pk": "22313506-64f8-4067-ad51-8ea199e3cc0d",
    "title": "System- and Sample-agnostic Isotropic 3D Microscopy by Weakly Physics-informed, Domain-shift-resistant Axial Deblurring",
    "abstract": "Three-dimensional (3D) subcellular imaging is essential for biomedical research, but the diffraction limit of optical microscopy compromises axial resolution, hindering accurate 3D structural analysis. This challenge is particularly pronounced in label-free imaging of thick, heterogeneous tissues, where assumptions about data distribution (e.g. sparsity, label-specific distribution, and lateral-axial similarity) and system priors (e.g. independent and identically distributed (i.i.d.) noise and linear shift-invariant (LSI) point-spread functions (PSFs)) are often invalid. Here, we introduce SSAI-3D, a weakly physics-informed, domain-shift-resistant framework for robust isotropic 3D imaging. SSAI-3D enables robust axial deblurring by generating a PSF-flexible, noise-resilient, sample-informed training dataset and sparsely fine-tuning a large pre-trained blind deblurring network. SSAI-3D was applied to label-free nonlinear imaging of living organoids, freshly excised human endometrium tissue, and mouse whisker pads, and further validated in publicly available ground-truth-paired experimental datasets of 3D heterogeneous biological tissues with unknown blurring and noise across different microscopy systems.",
    "authors": [
      "Jiashu Han",
      "Kunzan Liu",
      "Keith B. Isaacson",
      "Kristina Monakhova",
      "Linda G. Griffith",
      "Sixian You"
    ],
    "url": "http://arxiv.org/abs/2406.06337v1",
    "timestamp": 1718031455,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "physics.optics",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "19973fae-2824-4b06-8086-c8a1b5ae6762": {
    "pk": "19973fae-2824-4b06-8086-c8a1b5ae6762",
    "title": "Feasibility of accelerating homogeneous catalyst discovery with fault-tolerant quantum computers",
    "abstract": "The industrial manufacturing of chemicals consumes a significant amount of energy and raw materials. In principle, the development of new catalysts could greatly improve the efficiency of chemical production. However, the discovery of viable catalysts can be exceedingly challenging because it is difficult to know the efficacy of a candidate without experimentally synthesizing and characterizing it. This study explores the feasibility of using fault-tolerant quantum computers to accelerate the discovery of homogeneous catalysts for nitrogen fixation, an industrially important chemical process. It introduces a set of ground-state energy estimation problems representative of calculations needed for the discovery of homogeneous catalysts and analyzes them on three dimensions: economic utility, classical hardness, and quantum resource requirements. For the highest utility problem considered, two steps of a catalytic cycle for the generation of cyanate anion from dinitrogen, the economic utility of running these computations is estimated to be $200,000, and the required runtime for double-factorized phase estimation on a fault-tolerant superconducting device is estimated under conservative assumptions to be 139,000 QPU-hours. The computational cost of an equivalent DMRG calculation is estimated to be about 400,000 CPU-hours. These results suggest that, with continued development, it will be feasible for fault-tolerant quantum computers to accelerate the discovery of homogeneous catalysts.",
    "authors": [
      "Nicole Bellonzi",
      "Alexander Kunitsa",
      "Joshua T. Cantin",
      "Jorge A. Campos-Gonzalez-Angulo",
      "Maxwell D. Radin",
      "Yanbing Zhou",
      "Peter D. Johnson",
      "Luis A. Mart\u00ednez-Mart\u00ednez",
      "Mohammad Reza Jangrouei",
      "Aritra Sankar Brahmachari",
      "Linjun Wang",
      "Smik Patel",
      "Monika Kodrycka",
      "Ignacio Loaiza",
      "Robert A. Lang",
      "Al\u00e1n Aspuru-Guzik",
      "Artur F. Izmaylov",
      "Jhonathan Romero Fontalvo",
      "Yudong Cao"
    ],
    "url": "http://arxiv.org/abs/2406.06335v1",
    "timestamp": 1718031140,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "33416b48-fd01-435d-8ef4-88e850241a92": {
    "pk": "33416b48-fd01-435d-8ef4-88e850241a92",
    "title": "An automatic analysis of ultrasound vocalisations for the prediction of interaction context in captive Egyptian fruit bats",
    "abstract": "Prior work in computational bioacoustics has mostly focused on the detection of animal presence in a particular habitat. However, animal sounds contain much richer information than mere presence; among others, they encapsulate the interactions of those animals with other members of their species. Studying these interactions is almost impossible in a naturalistic setting, as the ground truth is often lacking. The use of animals in captivity instead offers a viable alternative pathway. However, most prior works follow a traditional, statistics-based approach to analysing interactions. In the present work, we go beyond this standard framework by attempting to predict the underlying context in interactions between captive \\emph{Rousettus Aegyptiacus} using deep neural networks. We reach an unweighted average recall of over 30\\% -- more than thrice the chance level -- and show error patterns that differ from our statistical analysis. This work thus represents an important step towards the automatic analysis of states in animals from sound.",
    "authors": [
      "Andreas Triantafyllopoulos",
      "Alexander Gebhard",
      "Manuel Milling",
      "Simon Rampp",
      "Bj\u00f6rn Schuller"
    ],
    "url": "http://arxiv.org/abs/2406.06332v1",
    "timestamp": 1718031032,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.SD",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "d782867d-33fc-45af-8f7a-86b0748a8a2d": {
    "pk": "d782867d-33fc-45af-8f7a-86b0748a8a2d",
    "title": "MedExQA: Medical Question Answering Benchmark with Multiple Explanations",
    "abstract": "This paper introduces MedExQA, a novel benchmark in medical question-answering, to evaluate large language models' (LLMs) understanding of medical knowledge through explanations. By constructing datasets across five distinct medical specialties that are underrepresented in current datasets and further incorporating multiple explanations for each question-answer pair, we address a major gap in current medical QA benchmarks which is the absence of comprehensive assessments of LLMs' ability to generate nuanced medical explanations. Our work highlights the importance of explainability in medical LLMs, proposes an effective methodology for evaluating models beyond classification accuracy, and sheds light on one specific domain, speech language pathology, where current LLMs including GPT4 lack good understanding. Our results show generation evaluation with multiple explanations aligns better with human assessment, highlighting an opportunity for a more robust automated comprehension assessment for LLMs. To diversify open-source medical LLMs (currently mostly based on Llama2), this work also proposes a new medical model, MedPhi-2, based on Phi-2 (2.7B). The model outperformed medical LLMs based on Llama2-70B in generating explanations, showing its effectiveness in the resource-constrained medical domain. We will share our benchmark datasets and the trained model.",
    "authors": [
      "Yunsoo Kim",
      "Jinge Wu",
      "Yusuf Abdulle",
      "Honghan Wu"
    ],
    "url": "http://arxiv.org/abs/2406.06331v1",
    "timestamp": 1718030824,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "bd229c85-2764-4a1f-ab08-d126bd93cf18": {
    "pk": "bd229c85-2764-4a1f-ab08-d126bd93cf18",
    "title": "A Parameter-efficient Language Extension Framework for Multilingual ASR",
    "abstract": "Covering all languages with a multilingual speech recognition model (MASR) is very difficult. Performing language extension on top of an existing MASR is a desirable choice. In this study, the MASR continual learning problem is probabilistically decomposed into language identity prediction (LP) and cross-lingual adaptation (XLA) sub-problems. Based on this, we propose an architecture-based framework for language extension that can fundamentally solve catastrophic forgetting, debudded as PELE. PELE is designed to be parameter-efficient, incrementally incorporating an add-on module to adapt to a new language. Specifically, different parameter-efficient fine-tuning (PEFT) modules and their variants are explored as potential candidates to perform XLA. Experiments are carried out on 5 new languages with a wide range of low-resourced data sizes. The best-performing PEFT candidate can achieve satisfactory performance across all languages and demonstrates superiority in three of five languages over the continual joint learning setting. Notably, PEFT methods focusing on weight parameters or input features are revealed to be limited in performance, showing significantly inferior extension capabilities compared to inserting a lightweight module in between layers such as an Adapter.",
    "authors": [
      "Wei Liu",
      "Jingyong Hou",
      "Dong Yang",
      "Muyong Cao",
      "Tan Lee"
    ],
    "url": "http://arxiv.org/abs/2406.06329v1",
    "timestamp": 1718030767,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "97744e73-6a24-4946-b00b-13b4f86c18c6": {
    "pk": "97744e73-6a24-4946-b00b-13b4f86c18c6",
    "title": "Exploring the generation and annihilation of three dimensional nulls through MHD simulations in initially chaotic magnetic field devoid of nulls",
    "abstract": "Three-dimensional (3D) magnetic nulls are abundant in the solar atmosphere, as been firmly established through contemporary observations. They are established to be important magnetic structures in, for example, jets and circular ribbon flares. While simulations and extrapolations support this, the mechanisms behind 3D null generation remain an open question. Recent magnetohydrodynamics (MHD) simulations propose that magnetic reconnection is responsible for both generating and annihilating 3D nulls, a novel concept. However, these simulations began with initial magnetic fields already supporting pre-existing nulls, raising the question of whether magnetic reconnection can create nulls in fields initially devoid of them. Previously, this question was briefly explored in a simulation with an initial chaotic magnetic field. However, the study failed to precisely identify locations, topological degrees, and natures (spiral or radial) of nulls, and it approximated magnetic reconnection without fully tracking field line in time. In this paper these findings are revisited in light of recent advancements and tools used to locate and trace nulls, along with the tracing of field lines, through which the concept of generation/annihilation of 3D nulls from chaotic fields is established in a precise manner.",
    "authors": [
      "Yogesh Kumar Maurya",
      "Ramit Bhattacharyya",
      "David I. Pontin",
      "Sanjay Kumar"
    ],
    "url": "http://arxiv.org/abs/2406.06328v1",
    "timestamp": 1718030623,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.SR",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "e9928d38-4850-4ef8-9d44-108056a6f295": {
    "pk": "e9928d38-4850-4ef8-9d44-108056a6f295",
    "title": "Leveraging Hyperscanning EEG and VR Omnidirectional Treadmill to Explore Inter-Brain Synchrony in Collaborative Spatial Navigation",
    "abstract": "Navigating through a physical environment to reach a desired location involves a complex interplay of cognitive, sensory, and motor functions. When navigating with others, experiencing a degree of behavioral and cognitive synchronization is both natural and ubiquitous. This synchronization facilitates a harmonious effort toward achieving a common goal, reflecting how individuals instinctively align their actions and thoughts in collaborative settings. Collaborative spatial tasks, which are crucial in daily and professional settings, require coordinated navigation and problem-solving skills. This study explores the neural mechanisms underlying such tasks by using hyperscanning electroencephalography (EEG) technology to examine brain dynamics in dyadic route planning within a virtual reality setting. By analyzing intra- and inter-brain couplings across delta, theta, alpha, beta, and gamma EEG bands using both functional and effective connectivity measures, we identified significant neural synchronization patterns associated with collaborative task performance in both leaders and followers. Functional intra-brain connectivity analyses revealed distinct neural engagement across EEG frequency bands, with increased delta couplings observed in both leaders and followers. Theta connectivity was particularly enhanced in followers, whereas the alpha band exhibited divergent patterns that indicate role-specific neural strategies. Inter-brain analysis revealed increased delta causality between interacting members but decreased theta and gamma couplings from followers to leaders. Additionally, inter-brain analysis indicated decreased couplings in faster-performing dyads, especially in theta bands. These insights enhance our understanding of the neural mechanisms driving collaborative spatial navigation and demonstrate the effectiveness of hyperscanning in studying complex brain-to-brain interactions.",
    "authors": [
      "Chun-Hsiang Chuang",
      "Po-Hsun Peng",
      "Yi-Chieh Chen"
    ],
    "url": "http://arxiv.org/abs/2406.06327v1",
    "timestamp": 1718030557,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "q-bio.NC",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b9075b58-579e-484e-86d3-06ea55f38471": {
    "pk": "b9075b58-579e-484e-86d3-06ea55f38471",
    "title": "Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching",
    "abstract": "Large language models (LLMs) often struggle to provide up-to-date information due to their one-time training and the constantly evolving nature of the world. To keep LLMs current, existing approaches typically involve continued pre-training on new documents. However, they frequently face difficulties in extracting stored knowledge. Motivated by the remarkable success of the Feynman Technique in efficient human learning, we introduce Self-Tuning, a learning framework aimed at improving an LLM's ability to effectively acquire new knowledge from raw documents through self-teaching. Specifically, we develop a Self-Teaching strategy that augments the documents with a set of knowledge-intensive tasks created in a self-supervised manner, focusing on three crucial aspects: memorization, comprehension, and self-reflection. Additionally, we introduce three Wiki-Newpages-2023-QA datasets to facilitate an in-depth analysis of an LLM's knowledge acquisition ability concerning memorization, extraction, and reasoning. Extensive experimental results on Llama2 family models reveal that Self-Tuning consistently exhibits superior performance across all knowledge acquisition tasks and excels in preserving previous knowledge.",
    "authors": [
      "Xiaoying Zhang",
      "Baolin Peng",
      "Ye Tian",
      "Jingyan Zhou",
      "Yipeng Zhang",
      "Haitao Mi",
      "Helen Meng"
    ],
    "url": "http://arxiv.org/abs/2406.06326v1",
    "timestamp": 1718030540,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "70644f30-faa4-4db0-9cef-2ae7c79e5aab": {
    "pk": "70644f30-faa4-4db0-9cef-2ae7c79e5aab",
    "title": "Feasibility of accelerating incompressible computational fluid dynamics simulations with fault-tolerant quantum computers",
    "abstract": "Across industries, traditional design and engineering workflows are being upgraded to simulation-driven processes. Many workflows include computational fluid dynamics (CFD). Simulations of turbulent flow are notorious for high compute costs and reliance on approximate methods that compromise accuracy. Improvements in the speed and accuracy of CFD calculations would potentially reduce design workflow costs by reducing computational costs and eliminating the need for experimental testing. This study explores the feasibility of using fault-tolerant quantum computers to improve the speed and accuracy of CFD simulations in the incompressible or weakly compressible regime. For the example of simulation-driven ship design, we consider simulations for calculating the drag force in steady-state flows, and provide analysis on economic utility and classical hardness. As a waypoint toward assessing the feasibility of our chosen quantum approach, we estimate the quantum resources required for the simpler case of drag force on a sphere. We estimate the product of logical qubits $\\times$ $T$ gates to range from $10^{22}$ to $10^{28}$. These high initial estimates suggest that future quantum computers are unlikely to provide utility for incompressible CFD applications unless significant algorithmic advancements or alternative quantum approaches are developed. Encouraged by applications in quantum chemistry that have realized orders-of-magnitude improvements as they matured, we identify the most promising next steps for quantum resource reduction as we work to scale up our estimates from spheres to utility-scale problems with more complex geometry.",
    "authors": [
      "John Penuel",
      "Amara Katabarwa",
      "Peter D. Johnson",
      "Collin Farquhar",
      "Yudong Cao",
      "Michael C. Garrett"
    ],
    "url": "http://arxiv.org/abs/2406.06323v1",
    "timestamp": 1718030326,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "61d534c2-bc76-4357-862e-f9ba6696f81d": {
    "pk": "61d534c2-bc76-4357-862e-f9ba6696f81d",
    "title": "Should my Blockchain Learn to Drive? A Study of Hyperledger Fabric",
    "abstract": "Similar to other transaction processing frameworks, blockchain systems need to be dynamically reconfigured to adapt to varying workloads and changes in network conditions. However, achieving optimal reconfiguration is particularly challenging due to the complexity of the blockchain stack, which has diverse configurable parameters. This paper explores the concept of self-driving blockchains, which have the potential to predict workload changes and reconfigure themselves for optimal performance without human intervention. We compare and contrast our discussions with existing research on databases and highlight aspects unique to blockchains. We identify specific parameters and components in Hyperledger Fabric, a popular permissioned blockchain system, that are suitable for autonomous adaptation and offer potential solutions for the challenges involved. Further, we implement three demonstrative locally autonomous systems, each targeting a different layer of the blockchain stack, and conduct experiments to understand the feasibility of our findings. Our experiments indicate up to 11% improvement in success throughput and a 30% decrease in latency, making this a significant step towards implementing a fully autonomous blockchain system in the future.",
    "authors": [
      "Jeeta Ann Chacko",
      "Ruben Mayer",
      "Hans-Arno Jacobsen"
    ],
    "url": "http://arxiv.org/abs/2406.06318v1",
    "timestamp": 1718030039,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.DC",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "6913f895-35a6-41a4-8116-0d1d641c4fb8": {
    "pk": "6913f895-35a6-41a4-8116-0d1d641c4fb8",
    "title": "Tx-LLM: A Large Language Model for Therapeutics",
    "abstract": "Developing therapeutics is a lengthy and expensive process that requires the satisfaction of many different criteria, and AI models capable of expediting the process would be invaluable. However, the majority of current AI approaches address only a narrowly defined set of tasks, often circumscribed within a particular domain. To bridge this gap, we introduce Tx-LLM, a generalist large language model (LLM) fine-tuned from PaLM-2 which encodes knowledge about diverse therapeutic modalities. Tx-LLM is trained using a collection of 709 datasets that target 66 tasks spanning various stages of the drug discovery pipeline. Using a single set of weights, Tx-LLM simultaneously processes a wide variety of chemical or biological entities(small molecules, proteins, nucleic acids, cell lines, diseases) interleaved with free-text, allowing it to predict a broad range of associated properties, achieving competitive with state-of-the-art (SOTA) performance on 43 out of 66 tasks and exceeding SOTA on 22. Among these, Tx-LLM is particularly powerful and exceeds best-in-class performance on average for tasks combining molecular SMILES representations with text such as cell line names or disease names, likely due to context learned during pretraining. We observe evidence of positive transfer between tasks with diverse drug types (e.g.,tasks involving small molecules and tasks involving proteins), and we study the impact of model size, domain finetuning, and prompting strategies on performance. We believe Tx-LLM represents an important step towards LLMs encoding biochemical knowledge and could have a future role as an end-to-end tool across the drug discovery development pipeline.",
    "authors": [
      "Juan Manuel Zambrano Chaves",
      "Eric Wang",
      "Tao Tu",
      "Eeshit Dhaval Vaishnav",
      "Byron Lee",
      "S. Sara Mahdavi",
      "Christopher Semturs",
      "David Fleet",
      "Vivek Natarajan",
      "Shekoofeh Azizi"
    ],
    "url": "http://arxiv.org/abs/2406.06316v1",
    "timestamp": 1718029982,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "e94905b2-ddb4-48f9-8169-f272cdaaf44f": {
    "pk": "e94905b2-ddb4-48f9-8169-f272cdaaf44f",
    "title": "ProAct: Progressive Training for Hybrid Clipped Activation Function to Enhance Resilience of DNNs",
    "abstract": "Deep Neural Networks (DNNs) are extensively employed in safety-critical applications where ensuring hardware reliability is a primary concern. To enhance the reliability of DNNs against hardware faults, activation restriction techniques significantly mitigate the fault effects at the DNN structure level, irrespective of accelerator architectures. State-of-the-art methods offer either neuron-wise or layer-wise clipping activation functions. They attempt to determine optimal clipping thresholds using heuristic and learning-based approaches. Layer-wise clipped activation functions cannot preserve DNNs resilience at high bit error rates. On the other hand, neuron-wise clipping activation functions introduce considerable memory overhead due to the addition of parameters, which increases their vulnerability to faults. Moreover, the heuristic-based optimization approach demands numerous fault injections during the search process, resulting in time-consuming threshold identification. On the other hand, learning-based techniques that train thresholds for entire layers concurrently often yield sub-optimal results. In this work, first, we demonstrate that it is not essential to incorporate neuron-wise activation functions throughout all layers in DNNs. Then, we propose a hybrid clipped activation function that integrates neuron-wise and layer-wise methods that apply neuron-wise clipping only in the last layer of DNNs. Additionally, to attain optimal thresholds in the clipping activation function, we introduce ProAct, a progressive training methodology. This approach iteratively trains the thresholds on a layer-by-layer basis, aiming to obtain optimal threshold values in each layer separately.",
    "authors": [
      "Seyedhamidreza Mousavi",
      "Mohammad Hasan Ahmadilivani",
      "Jaan Raik",
      "Maksim Jenihhin",
      "Masoud Daneshtalab"
    ],
    "url": "http://arxiv.org/abs/2406.06313v1",
    "timestamp": 1718029898,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "aa620c03-ea11-4edc-a433-da1c78a9bf32": {
    "pk": "aa620c03-ea11-4edc-a433-da1c78a9bf32",
    "title": "Unsupervised Improved MVDR Beamforming for Sound Enhancement",
    "abstract": "Neural networks have recently become the dominant approach to sound separation. Their good performance relies on large datasets of isolated recordings. For speech and music, isolated single channel data are readily available; however the same does not hold in the multi-channel case, and with most other sound classes. Multi-channel methods have the potential to outperform single channel approaches as they can exploit both spatial and spectral features, but the lack of training data remains a challenge. We propose unsupervised improved minimum variation distortionless response (UIMVDR), which enables multi-channel separation to leverage in-the-wild single-channel data through unsupervised training and beamforming. Results show that UIMVDR generalizes well and improves separation performance compared to supervised models, particularly in cases with limited supervised data. By using data available online, it also reduces the effort required to gather data for multi-channel approaches.",
    "authors": [
      "Jacob Kealey",
      "John Hershey",
      "Fran\u00e7ois Grondin"
    ],
    "url": "http://arxiv.org/abs/2406.06310v1",
    "timestamp": 1718029569,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.SD",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "8418912c-36cd-4abb-ad9b-557d1399fba5": {
    "pk": "8418912c-36cd-4abb-ad9b-557d1399fba5",
    "title": "Building Continuous Quantum-Classical Bayesian Neural Networks for a Classical Clinical Dataset",
    "abstract": "In this work, we are introducing a Quantum-Classical Bayesian Neural Network (QCBNN) that is capable to perform uncertainty-aware classification of classical medical dataset. This model is a symbiosis of a classical Convolutional NN that performs ultra-sound image processing and a quantum circuit that generates its stochastic weights, within a Bayesian learning framework. To test the utility of this idea for the possible future deployment in the medical sector we track multiple behavioral metrics that capture both predictive performance as well as model's uncertainty. It is our ambition to create a hybrid model that is capable to classify samples in a more uncertainty aware fashion, which will advance the trustworthiness of these models and thus bring us step closer to utilizing them in the industry. We test multiple setups for quantum circuit for this task, and our best architectures display bigger uncertainty gap between correctly and incorrectly identified samples than its classical benchmark at an expense of a slight drop in predictive performance. The innovation of this paper is two-fold: (1) combining of different approaches that allow the stochastic weights from the quantum circuit to be continues thus allowing the model to classify application-driven dataset; (2) studying architectural features of quantum circuit that make-or-break these models, which pave the way into further investigation of more informed architectural designs.",
    "authors": [
      "Alona Sakhnenko",
      "Julian Sikora",
      "Jeanette Miriam Lorenz"
    ],
    "url": "http://arxiv.org/abs/2406.06307v1",
    "timestamp": 1718029405,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "3a100871-c27b-4acf-bca4-ea8467993410": {
    "pk": "3a100871-c27b-4acf-bca4-ea8467993410",
    "title": "Unified Fourier bases for GSP on stochastic block model graphs",
    "abstract": "We consider a recently proposed approach to graph signal processing based on graphons. We show how the graphon-based approach to GSP applies to graphs sampled from a stochastic block model. We obtain a basis for the graphon Fourier transform on such samples directly from the link probability matrix and the block sizes of the model. This formulation allows us to bound the sensitivity of the Fourier transform to small changes in block sizes. We then focus on the case where the probability matrix corresponds to a (weighted) Cayley graph. If block sizes are equal, a nice Fourier basis can be derived from the underlying group. We explore how, in the case where block sizes are not equal, some or all nice properties of the group basis can be maintained. We complement the theoretical results with simulations.",
    "authors": [
      "Mahya Ghandehari",
      "Jeannette Janssen",
      "Silo Murphy"
    ],
    "url": "http://arxiv.org/abs/2406.06306v1",
    "timestamp": 1718029301,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.SP",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "52baf8f5-6cac-41cc-813a-46c28e204bfe": {
    "pk": "52baf8f5-6cac-41cc-813a-46c28e204bfe",
    "title": "Large dynamical magnetic effective charges and anti-magnetoelectricity from spin and orbital origin in multiferroic BiCoO$_3$",
    "abstract": "Using first-principles calculations, we explore the magnetoelectric properties of the room-temperature multiferroic crystal BiCoO$_3$. We use both applied magnetic field and finite-difference techniques to show that BiCoO$_3$ is anti-magnetoelectric at the linear level. The calculation of the dynamical effective charges reveals that the total magnetoelectric response is zero due to the compensating non-zero magnetoelectric response of each magnetic sublattice. This calculation also highlights that the the orbital contribution to the response is remarkably larger than the spin one and that each sublattice has a rather large total magnetoelectric response of 85 ps/m. Furthermore, we provide an intuitive recipe to visualize the dynamical magnetic effective charge, allowing to examine its multipolar nature which we confirm by means of ab initio calculations. Given the large value of the local response, we investigate the ferromagnetic phase as well, which gives a giant magnetoelectric response of about 1000 ps/m and coming mainly from the spin contribution this time. Finally, we discuss the possible reasons for such a large magnetoelectric response in BiCoO3 and propose possible strategies to unveil this potentially large response.",
    "authors": [
      "Maxime Braun",
      "Bogdan Guster",
      "Andrea Urru",
      "Houria Kabbour",
      "Eric Bousquet"
    ],
    "url": "http://arxiv.org/abs/2406.06298v1",
    "timestamp": 1718029054,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cond-mat.mtrl-sci",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b9b10b6a-2564-4f61-b244-7a2c7a3e5e0c": {
    "pk": "b9b10b6a-2564-4f61-b244-7a2c7a3e5e0c",
    "title": "Exploring the discrepancy between Planck PR3 and ACT DR4",
    "abstract": "We explore the scales and the extent of disagreement between $Planck$ PR3 and Atacama Cosmology Telescope (ACT) DR4 data. $Planck$ and ACT data have substantial overlap in the temperature anisotropy data between scales corresponding to multipoles $\\ell\\simeq 600-2500$ with complementing coverage of larger angular scales by $Planck$ and smaller angular scales by ACT. Since the same cosmology should govern the anisotropy spectrum at all scales, we probe this disagreement in the primordial power spectrum. We use a parametric form of power law primordial spectrum that allows changes in the spectral tilt. We also reconstruct the primordial spectrum with a non-parametric method from both $Planck$ and ACT temperature data. We find the disagreement exists within scales 0.08 - 0.16 ${\\rm Mpc}^{-1}$ where ACT temperature data prefers a scale invariant/blue spectrum. At scales larger and smaller than this window, ACT data strongly prefers a red tilt, which is consistent with $Planck$. This change in the spectral tilt can be identified in the ACT data at 2$\\sigma$ C.L. without using $Planck$ data, indicating that the tension is driven by different preferences for tilts within the ACT data. The addition of $Planck$ data up to intermediate scales ($\\ell\\le650$) increases this significance to 3$\\sigma$. Given the large overlap between $Planck$ and ACT within 0.08 - 0.16 ${\\rm Mpc}^{-1}$ and considering the internal consistency between different $Planck$ temperature and polarization spectra, the scope of new physics as a solution to the tension remains limited. Our results -- a strong preference for an intermediate transition in spectral tilt and the variation of this preference in different data combinations -- indicate that systematic effects can be misperceived as new physics emerging from different non-standard cosmological processes.",
    "authors": [
      "Dhiraj Kumar Hazra",
      "Benjamin Beringue",
      "Josquin Errard",
      "Arman Shafieloo",
      "George F. Smoot"
    ],
    "url": "http://arxiv.org/abs/2406.06296v1",
    "timestamp": 1718029015,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.CO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "47764040-3083-4172-90c9-4627a8da10ae": {
    "pk": "47764040-3083-4172-90c9-4627a8da10ae",
    "title": "Zero-Shot Audio Captioning Using Soft and Hard Prompts",
    "abstract": "In traditional audio captioning methods, a model is usually trained in a fully supervised manner using a human-annotated dataset containing audio-text pairs and then evaluated on the test sets from the same dataset. Such methods have two limitations. First, these methods are often data-hungry and require time-consuming and expensive human annotations to obtain audio-text pairs. Second, these models often suffer from performance degradation in cross-domain scenarios, i.e., when the input audio comes from a different domain than the training set, which, however, has received little attention. We propose an effective audio captioning method based on the contrastive language-audio pre-training (CLAP) model to address these issues. Our proposed method requires only textual data for training, enabling the model to generate text from the textual feature in the cross-modal semantic space.In the inference stage, the model generates the descriptive text for the given audio from the audio feature by leveraging the audio-text alignment from CLAP.We devise two strategies to mitigate the discrepancy between text and audio embeddings: a mixed-augmentation-based soft prompt and a retrieval-based acoustic-aware hard prompt. These approaches are designed to enhance the generalization performance of our proposed model, facilitating the model to generate captions more robustly and accurately. Extensive experiments on AudioCaps and Clotho benchmarks show the effectiveness of our proposed method, which outperforms other zero-shot audio captioning approaches for in-domain scenarios and outperforms the compared methods for cross-domain scenarios, underscoring the generalization ability of our method.",
    "authors": [
      "Yiming Zhang",
      "Xuenan Xu",
      "Ruoyi Du",
      "Haohe Liu",
      "Yuan Dong",
      "Zheng-Hua Tan",
      "Wenwu Wang",
      "Zhanyu Ma"
    ],
    "url": "http://arxiv.org/abs/2406.06295v1",
    "timestamp": 1718028988,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.SD",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "2f57f13b-f538-4dee-9be2-fb434a4a9d5a": {
    "pk": "2f57f13b-f538-4dee-9be2-fb434a4a9d5a",
    "title": "Sample Rate Independent Recurrent Neural Networks for Audio Effects Processing",
    "abstract": "In recent years, machine learning approaches to modelling guitar amplifiers and effects pedals have been widely investigated and have become standard practice in some consumer products. In particular, recurrent neural networks (RNNs) are a popular choice for modelling non-linear devices such as vacuum tube amplifiers and distortion circuitry. One limitation of such models is that they are trained on audio at a specific sample rate and therefore give unreliable results when operating at another rate. Here, we investigate several methods of modifying RNN structures to make them approximately sample rate independent, with a focus on oversampling. In the case of integer oversampling, we demonstrate that a previously proposed delay-based approach provides high fidelity sample rate conversion whilst additionally reducing aliasing. For non-integer sample rate adjustment, we propose two novel methods and show that one of these, based on cubic Lagrange interpolation of a delay-line, provides a significant improvement over existing methods. To our knowledge, this work provides the first in-depth study into this problem.",
    "authors": [
      "Alistair Carson",
      "Alec Wright",
      "Jatin Chowdhury",
      "Vesa V\u00e4lim\u00e4ki",
      "Stefan Bilbao"
    ],
    "url": "http://arxiv.org/abs/2406.06293v1",
    "timestamp": 1718028863,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.AS",
    "references": null,
    "citation_count": 0,
    "award": null
  }
}