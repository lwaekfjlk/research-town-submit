{
  "41cbf176-e802-4b42-bf33-811940f347b6": {
    "pk": "41cbf176-e802-4b42-bf33-811940f347b6",
    "title": "IllumiNeRF: 3D Relighting without Inverse Rendering",
    "abstract": "Existing methods for relightable view synthesis -- using a set of images of an object under unknown lighting to recover a 3D representation that can be rendered from novel viewpoints under a target illumination -- are based on inverse rendering, and attempt to disentangle the object geometry, materials, and lighting that explain the input images. Furthermore, this typically involves optimization through differentiable Monte Carlo rendering, which is brittle and computationally-expensive. In this work, we propose a simpler approach: we first relight each input image using an image diffusion model conditioned on lighting and then reconstruct a Neural Radiance Field (NeRF) with these relit images, from which we render novel views under the target lighting. We demonstrate that this strategy is surprisingly competitive and achieves state-of-the-art results on multiple relighting benchmarks. Please see our project page at https://illuminerf.github.io/.",
    "authors": [
      "Xiaoming Zhao",
      "Pratul P. Srinivasan",
      "Dor Verbin",
      "Keunhong Park",
      "Ricardo Martin Brualla",
      "Philipp Henzler"
    ],
    "url": "http://arxiv.org/abs/2406.06527v1",
    "timestamp": 1718042399,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c3b3549f-e33e-4877-b0ec-c7c0f1eb9b13": {
    "pk": "c3b3549f-e33e-4877-b0ec-c7c0f1eb9b13",
    "title": "GaussianCity: Generative Gaussian Splatting for Unbounded 3D City Generation",
    "abstract": "3D city generation with NeRF-based methods shows promising generation results but is computationally inefficient. Recently 3D Gaussian Splatting (3D-GS) has emerged as a highly efficient alternative for object-level 3D generation. However, adapting 3D-GS from finite-scale 3D objects and humans to infinite-scale 3D cities is non-trivial. Unbounded 3D city generation entails significant storage overhead (out-of-memory issues), arising from the need to expand points to billions, often demanding hundreds of Gigabytes of VRAM for a city scene spanning 10km^2. In this paper, we propose GaussianCity, a generative Gaussian Splatting framework dedicated to efficiently synthesizing unbounded 3D cities with a single feed-forward pass. Our key insights are two-fold: 1) Compact 3D Scene Representation: We introduce BEV-Point as a highly compact intermediate representation, ensuring that the growth in VRAM usage for unbounded scenes remains constant, thus enabling unbounded city generation. 2) Spatial-aware Gaussian Attribute Decoder: We present spatial-aware BEV-Point decoder to produce 3D Gaussian attributes, which leverages Point Serializer to integrate the structural and contextual characteristics of BEV points. Extensive experiments demonstrate that GaussianCity achieves state-of-the-art results in both drone-view and street-view 3D city generation. Notably, compared to CityDreamer, GaussianCity exhibits superior performance with a speedup of 60 times (10.72 FPS v.s. 0.18 FPS).",
    "authors": [
      "Haozhe Xie",
      "Zhaoxi Chen",
      "Fangzhou Hong",
      "Ziwei Liu"
    ],
    "url": "http://arxiv.org/abs/2406.06526v1",
    "timestamp": 1718042395,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "a55fdab1-e2a2-4b8a-9239-9e8a9df7ebb6": {
    "pk": "a55fdab1-e2a2-4b8a-9239-9e8a9df7ebb6",
    "title": "Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation",
    "abstract": "We introduce LlamaGen, a new family of image generation models that apply original ``next-token prediction'' paradigm of large language models to visual generation domain. It is an affirmative answer to whether vanilla autoregressive models, e.g., Llama, without inductive biases on visual signals can achieve state-of-the-art image generation performance if scaling properly. We reexamine design spaces of image tokenizers, scalability properties of image generation models, and their training data quality. The outcome of this exploration consists of: (1) An image tokenizer with downsample ratio of 16, reconstruction quality of 0.94 rFID and codebook usage of 97% on ImageNet benchmark. (2) A series of class-conditional image generation models ranging from 111M to 3.1B parameters, achieving 2.18 FID on ImageNet 256x256 benchmarks, outperforming the popular diffusion models such as LDM, DiT. (3) A text-conditional image generation model with 775M parameters, from two-stage training on LAION-COCO and high aesthetics quality images, demonstrating competitive performance of visual quality and text alignment. (4) We verify the effectiveness of LLM serving frameworks in optimizing the inference speed of image generation models and achieve 326% - 414% speedup. We release all models and codes to facilitate open-source community of visual generation and multimodal foundation models.",
    "authors": [
      "Peize Sun",
      "Yi Jiang",
      "Shoufa Chen",
      "Shilong Zhang",
      "Bingyue Peng",
      "Ping Luo",
      "Zehuan Yuan"
    ],
    "url": "http://arxiv.org/abs/2406.06525v1",
    "timestamp": 1718042392,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5ba37421-19b2-45a9-82c5-d877fe6f053c": {
    "pk": "5ba37421-19b2-45a9-82c5-d877fe6f053c",
    "title": "NaRCan: Natural Refined Canonical Image with Integration of Diffusion Prior for Video Editing",
    "abstract": "We propose a video editing framework, NaRCan, which integrates a hybrid deformation field and diffusion prior to generate high-quality natural canonical images to represent the input video. Our approach utilizes homography to model global motion and employs multi-layer perceptrons (MLPs) to capture local residual deformations, enhancing the model's ability to handle complex video dynamics. By introducing a diffusion prior from the early stages of training, our model ensures that the generated images retain a high-quality natural appearance, making the produced canonical images suitable for various downstream tasks in video editing, a capability not achieved by current canonical-based methods. Furthermore, we incorporate low-rank adaptation (LoRA) fine-tuning and introduce a noise and diffusion prior update scheduling technique that accelerates the training process by 14 times. Extensive experimental results show that our method outperforms existing approaches in various video editing tasks and produces coherent and high-quality edited video sequences. See our project page for video results at https://koi953215.github.io/NaRCan_page/.",
    "authors": [
      "Ting-Hsuan Chen",
      "Jiewen Chan",
      "Hau-Shiang Shiu",
      "Shih-Han Yen",
      "Chang-Han Yeh",
      "Yu-Lun Liu"
    ],
    "url": "http://arxiv.org/abs/2406.06523v1",
    "timestamp": 1718042386,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "91ca3260-c295-4cb0-ab9b-ad0c27f9d1b4": {
    "pk": "91ca3260-c295-4cb0-ab9b-ad0c27f9d1b4",
    "title": "PGSR: Planar-based Gaussian Splatting for Efficient and High-Fidelity Surface Reconstruction",
    "abstract": "Recently, 3D Gaussian Splatting (3DGS) has attracted widespread attention due to its high-quality rendering, and ultra-fast training and rendering speed. However, due to the unstructured and irregular nature of Gaussian point clouds, it is difficult to guarantee geometric reconstruction accuracy and multi-view consistency simply by relying on image reconstruction loss. Although many studies on surface reconstruction based on 3DGS have emerged recently, the quality of their meshes is generally unsatisfactory. To address this problem, we propose a fast planar-based Gaussian splatting reconstruction representation (PGSR) to achieve high-fidelity surface reconstruction while ensuring high-quality rendering. Specifically, we first introduce an unbiased depth rendering method, which directly renders the distance from the camera origin to the Gaussian plane and the corresponding normal map based on the Gaussian distribution of the point cloud, and divides the two to obtain the unbiased depth. We then introduce single-view geometric, multi-view photometric, and geometric regularization to preserve global geometric accuracy. We also propose a camera exposure compensation model to cope with scenes with large illumination variations. Experiments on indoor and outdoor scenes show that our method achieves fast training and rendering while maintaining high-fidelity rendering and geometric reconstruction, outperforming 3DGS-based and NeRF-based methods.",
    "authors": [
      "Danpeng Chen",
      "Hai Li",
      "Weicai Ye",
      "Yifan Wang",
      "Weijian Xie",
      "Shangjin Zhai",
      "Nan Wang",
      "Haomin Liu",
      "Hujun Bao",
      "Guofeng Zhang"
    ],
    "url": "http://arxiv.org/abs/2406.06521v1",
    "timestamp": 1718042341,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "0629f1e1-02a7-4e31-922f-6d10aa5da2d1": {
    "pk": "0629f1e1-02a7-4e31-922f-6d10aa5da2d1",
    "title": "Decentralized Personalized Federated Learning",
    "abstract": "This work tackles the challenges of data heterogeneity and communication limitations in decentralized federated learning. We focus on creating a collaboration graph that guides each client in selecting suitable collaborators for training personalized models that leverage their local data effectively. Our approach addresses these issues through a novel, communication-efficient strategy that enhances resource efficiency. Unlike traditional methods, our formulation identifies collaborators at a granular level by considering combinatorial relations of clients, enhancing personalization while minimizing communication overhead. We achieve this through a bi-level optimization framework that employs a constrained greedy algorithm, resulting in a resource-efficient collaboration graph for personalized learning. Extensive evaluation against various baselines across diverse datasets demonstrates the superiority of our method, named DPFL. DPFL consistently outperforms other approaches, showcasing its effectiveness in handling real-world data heterogeneity, minimizing communication overhead, enhancing resource efficiency, and building personalized models in decentralized federated learning scenarios.",
    "authors": [
      "Salma Kharrat",
      "Marco Canini",
      "Samuel Horvath"
    ],
    "url": "http://arxiv.org/abs/2406.06520v1",
    "timestamp": 1718042328,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "723bbf28-5f62-4761-aa0c-f1bee3ab02c0": {
    "pk": "723bbf28-5f62-4761-aa0c-f1bee3ab02c0",
    "title": "Data Augmentation for Multivariate Time Series Classification: An Experimental Study",
    "abstract": "Our study investigates the impact of data augmentation on the performance of multivariate time series models, focusing on datasets from the UCR archive. Despite the limited size of these datasets, we achieved classification accuracy improvements in 10 out of 13 datasets using the Rocket and InceptionTime models. This highlights the essential role of sufficient data in training effective models, paralleling the advancements seen in computer vision. Our work delves into adapting and applying existing methods in innovative ways to the domain of multivariate time series classification. Our comprehensive exploration of these techniques sets a new standard for addressing data scarcity in time series analysis, emphasizing that diverse augmentation strategies are crucial for unlocking the potential of both traditional and deep learning models. Moreover, by meticulously analyzing and applying a variety of augmentation techniques, we demonstrate that strategic data enrichment can enhance model accuracy. This not only establishes a benchmark for future research in time series analysis but also underscores the importance of adopting varied augmentation approaches to improve model performance in the face of limited data availability.",
    "authors": [
      "Romain Ilbert",
      "Thai V. Hoang",
      "Zonghua Zhang"
    ],
    "url": "http://arxiv.org/abs/2406.06518v1",
    "timestamp": 1718042282,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "24ed7ad2-19b7-4dc4-a782-d62f4860cc77": {
    "pk": "24ed7ad2-19b7-4dc4-a782-d62f4860cc77",
    "title": "Genomics-guided Representation Learning for Pathologic Pan-cancer Tumor Microenvironment Subtype Prediction",
    "abstract": "The characterization of Tumor MicroEnvironment (TME) is challenging due to its complexity and heterogeneity. Relatively consistent TME characteristics embedded within highly specific tissue features, render them difficult to predict. The capability to accurately classify TME subtypes is of critical significance for clinical tumor diagnosis and precision medicine. Based on the observation that tumors with different origins share similar microenvironment patterns, we propose PathoTME, a genomics-guided Siamese representation learning framework employing Whole Slide Image (WSI) for pan-cancer TME subtypes prediction. Specifically, we utilize Siamese network to leverage genomic information as a regularization factor to assist WSI embeddings learning during the training phase. Additionally, we employ Domain Adversarial Neural Network (DANN) to mitigate the impact of tissue type variations. To eliminate domain bias, a dynamic WSI prompt is designed to further unleash the model's capabilities. Our model achieves better performance than other state-of-the-art methods across 23 cancer types on TCGA dataset. Our code is available at https://github.com/Mengflz/PathoTME.",
    "authors": [
      "Fangliangzi Meng",
      "Hongrun Zhang",
      "Ruodan Yan",
      "Guohui Chuai",
      "Chao Li",
      "Qi Liu"
    ],
    "url": "http://arxiv.org/abs/2406.06517v1",
    "timestamp": 1718042181,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "675f5b7b-9d98-4a8a-8355-8ad7fb28d6b1": {
    "pk": "675f5b7b-9d98-4a8a-8355-8ad7fb28d6b1",
    "title": "Spin-photon entanglement of a single Er$^{3+}$ ion in the telecom band",
    "abstract": "Long-distance quantum communication using quantum repeaters is an enabling technology for secure communication, distributed quantum computing and quantum-enhanced sensing and metrology. As a building block of quantum repeaters, spin-photon entanglement has been demonstrated with both atomic and solid-state qubits. However, previously demonstrated qubits with long spin coherence do not directly emit photons into the low-loss telecom band that is needed for long-distance communication. Here, we demonstrate spin-photon entanglement using a single Er$^{3+}$ ion in a solid-state crystal, integrated into a silicon nanophotonic circuit. Direct emission into the telecom band enables an entanglement rate of 1.48 Hz over 15.6 km of optical fiber, with a fidelity of 73(3)$\\%$. This opens the door to large-scale quantum networks based on scalable nanophotonic devices and many spectrally multiplexed Er$^{3+}$ ions.",
    "authors": [
      "Mehmet T. Uysal",
      "\u0141ukasz Dusanowski",
      "Haitong Xu",
      "Sebastian P. Horvath",
      "Salim Ourari",
      "Robert J. Cava",
      "Nathalie P. de Leon",
      "Jeff D. Thompson"
    ],
    "url": "http://arxiv.org/abs/2406.06515v1",
    "timestamp": 1718042125,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "925a8af4-87fe-4d2e-b570-fccfa1b26066": {
    "pk": "925a8af4-87fe-4d2e-b570-fccfa1b26066",
    "title": "Random Features Approximation for Control-Affine Systems",
    "abstract": "Modern data-driven control applications call for flexible nonlinear models that are amenable to principled controller synthesis and realtime feedback. Many nonlinear dynamical systems of interest are control affine. We propose two novel classes of nonlinear feature representations which capture control affine structure while allowing for arbitrary complexity in the state dependence. Our methods make use of random features (RF) approximations, inheriting the expressiveness of kernel methods at a lower computational cost. We formalize the representational capabilities of our methods by showing their relationship to the Affine Dot Product (ADP) kernel proposed by Casta\\~neda et al. (2021) and a novel Affine Dense (AD) kernel that we introduce. We further illustrate the utility by presenting a case study of data-driven optimization-based control using control certificate functions (CCF). Simulation experiments on a double pendulum empirically demonstrate the advantages of our methods.",
    "authors": [
      "Kimia Kazemian",
      "Yahya Sattar",
      "Sarah Dean"
    ],
    "url": "http://arxiv.org/abs/2406.06514v1",
    "timestamp": 1718042097,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "72800758-1c16-4e86-85aa-b23dcaf568dc": {
    "pk": "72800758-1c16-4e86-85aa-b23dcaf568dc",
    "title": "Merlin: A Vision Language Foundation Model for 3D Computed Tomography",
    "abstract": "Over 85 million computed tomography (CT) scans are performed annually in the US, of which approximately one quarter focus on the abdomen. Given the current radiologist shortage, there is a large impetus to use artificial intelligence to alleviate the burden of interpreting these complex imaging studies. Prior state-of-the-art approaches for automated medical image interpretation leverage vision language models (VLMs). However, current medical VLMs are generally limited to 2D images and short reports, and do not leverage electronic health record (EHR) data for supervision. We introduce Merlin - a 3D VLM that we train using paired CT scans (6+ million images from 15,331 CTs), EHR diagnosis codes (1.8+ million codes), and radiology reports (6+ million tokens). We evaluate Merlin on 6 task types and 752 individual tasks. The non-adapted (off-the-shelf) tasks include zero-shot findings classification (31 findings), phenotype classification (692 phenotypes), and zero-shot cross-modal retrieval (image to findings and image to impressions), while model adapted tasks include 5-year disease prediction (6 diseases), radiology report generation, and 3D semantic segmentation (20 organs). We perform internal validation on a test set of 5,137 CTs, and external validation on 7,000 clinical CTs and on two public CT datasets (VerSe, TotalSegmentator). Beyond these clinically-relevant evaluations, we assess the efficacy of various network architectures and training strategies to depict that Merlin has favorable performance to existing task-specific baselines. We derive data scaling laws to empirically assess training data needs for requisite downstream task performance. Furthermore, unlike conventional VLMs that require hundreds of GPUs for training, we perform all training on a single GPU.",
    "authors": [
      "Louis Blankemeier",
      "Joseph Paul Cohen",
      "Ashwin Kumar",
      "Dave Van Veen",
      "Syed Jamal Safdar Gardezi",
      "Magdalini Paschali",
      "Zhihong Chen",
      "Jean-Benoit Delbrouck",
      "Eduardo Reis",
      "Cesar Truyts",
      "Christian Bluethgen",
      "Malte Engmann Kjeldskov Jensen",
      "Sophie Ostmeier",
      "Maya Varma",
      "Jeya Maria Jose Valanarasu",
      "Zhongnan Fang",
      "Zepeng Huo",
      "Zaid Nabulsi",
      "Diego Ardila",
      "Wei-Hung Weng",
      "Edson Amaro Junior",
      "Neera Ahuja",
      "Jason Fries",
      "Nigam H. Shah",
      "Andrew Johnston",
      "Robert D. Boutin",
      "Andrew Wentland",
      "Curtis P. Langlotz",
      "Jason Hom",
      "Sergios Gatidis",
      "Akshay S. Chaudhari"
    ],
    "url": "http://arxiv.org/abs/2406.06512v1",
    "timestamp": 1718041981,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "336a0eda-a76c-47b8-9fa1-a5f99456ee72": {
    "pk": "336a0eda-a76c-47b8-9fa1-a5f99456ee72",
    "title": "Quantifying fault tolerant simulation of strongly correlated systems using the Fermi-Hubbard model",
    "abstract": "Understanding the physics of strongly correlated materials is one of the grand challenge problems for physics today. A large class of scientifically interesting materials, from high-$T_c$ superconductors to spin liquids, involve medium to strong correlations, and building a holistic understanding of these materials is critical. Doing so is hindered by the competition between the kinetic energy and Coulomb repulsion, which renders both analytic and numerical methods unsatisfactory for describing interacting materials. Fault-tolerant quantum computers have been proposed as a path forward to overcome these difficulties, but this potential capability has not yet been fully assessed. Here, using the multi-orbital Fermi-Hubbard model as a representative model and a source of scalable problem specifications, we estimate the resource costs needed to use fault-tolerant quantum computers for obtaining experimentally relevant quantities such as correlation function estimation. We find that advances in quantum algorithms and hardware will be needed in order to reduce quantum resources and feasibly address utility-scale problem instances.",
    "authors": [
      "Anjali A. Agrawal",
      "Tyler L. Wilson",
      "S. N. Saadatmand",
      "Mark J. Hodson",
      "Josh Y. Mutus",
      "Athena Caesura",
      "Peter D. Johnson",
      "Alexander F. Kemper"
    ],
    "url": "http://arxiv.org/abs/2406.06511v1",
    "timestamp": 1718041856,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "26d69348-d9a3-4ab8-813b-59f56f77281f": {
    "pk": "26d69348-d9a3-4ab8-813b-59f56f77281f",
    "title": "Monkey See, Monkey Do: Harnessing Self-attention in Motion Diffusion for Zero-shot Motion Transfer",
    "abstract": "Given the remarkable results of motion synthesis with diffusion models, a natural question arises: how can we effectively leverage these models for motion editing? Existing diffusion-based motion editing methods overlook the profound potential of the prior embedded within the weights of pre-trained models, which enables manipulating the latent feature space; hence, they primarily center on handling the motion space. In this work, we explore the attention mechanism of pre-trained motion diffusion models. We uncover the roles and interactions of attention elements in capturing and representing intricate human motion patterns, and carefully integrate these elements to transfer a leader motion to a follower one while maintaining the nuanced characteristics of the follower, resulting in zero-shot motion transfer. Editing features associated with selected motions allows us to confront a challenge observed in prior motion diffusion approaches, which use general directives (e.g., text, music) for editing, ultimately failing to convey subtle nuances effectively. Our work is inspired by how a monkey closely imitates what it sees while maintaining its unique motion patterns; hence we call it Monkey See, Monkey Do, and dub it MoMo. Employing our technique enables accomplishing tasks such as synthesizing out-of-distribution motions, style transfer, and spatial editing. Furthermore, diffusion inversion is seldom employed for motions; as a result, editing efforts focus on generated motions, limiting the editability of real ones. MoMo harnesses motion inversion, extending its application to both real and generated motions. Experimental results show the advantage of our approach over the current art. In particular, unlike methods tailored for specific applications through training, our approach is applied at inference time, requiring no training. Our webpage is at https://monkeyseedocg.github.io.",
    "authors": [
      "Sigal Raab",
      "Inbar Gat",
      "Nathan Sala",
      "Guy Tevet",
      "Rotem Shalev-Arkushin",
      "Ohad Fried",
      "Amit H. Bermano",
      "Daniel Cohen-Or"
    ],
    "url": "http://arxiv.org/abs/2406.06508v1",
    "timestamp": 1718041634,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "1fad4e3c-8b87-4b31-86ab-5922c5db32ab": {
    "pk": "1fad4e3c-8b87-4b31-86ab-5922c5db32ab",
    "title": "Verification-Guided Shielding for Deep Reinforcement Learning",
    "abstract": "In recent years, Deep Reinforcement Learning (DRL) has emerged as an effective approach to solving real-world tasks. However, despite their successes, DRL-based policies suffer from poor reliability, which limits their deployment in safety-critical domains. As a result, various methods have been put forth to address this issue by providing formal safety guarantees. Two main approaches include shielding and verification. While shielding ensures the safe behavior of the policy by employing an external online component (i.e., a ``shield'') that overruns potentially dangerous actions, this approach has a significant computational cost as the shield must be invoked at runtime to validate every decision. On the other hand, verification is an offline process that can identify policies that are unsafe, prior to their deployment, yet, without providing alternative actions when such a policy is deemed unsafe. In this work, we present verification-guided shielding -- a novel approach that bridges the DRL reliability gap by integrating these two methods. Our approach combines both formal and probabilistic verification tools to partition the input domain into safe and unsafe regions. In addition, we employ clustering and symbolic representation procedures that compress the unsafe regions into a compact representation. This, in turn, allows to temporarily activate the shield solely in (potentially) unsafe regions, in an efficient manner. Our novel approach allows to significantly reduce runtime overhead while still preserving formal safety guarantees. We extensively evaluate our approach on two benchmarks from the robotic navigation domain, as well as provide an in-depth analysis of its scalability and completeness.",
    "authors": [
      "Davide Corsi",
      "Guy Amir",
      "Andoni Rodriguez",
      "Cesar Sanchez",
      "Guy Katz",
      "Roy Fox"
    ],
    "url": "http://arxiv.org/abs/2406.06507v1",
    "timestamp": 1718041499,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "49069fab-68e2-4ae0-a92c-d1a32ee81d75": {
    "pk": "49069fab-68e2-4ae0-a92c-d1a32ee81d75",
    "title": "Online Newton Method for Bandit Convex Optimisation",
    "abstract": "We introduce a computationally efficient algorithm for zeroth-order bandit convex optimisation and prove that in the adversarial setting its regret is at most $d^{3.5} \\sqrt{n} \\mathrm{polylog}(n, d)$ with high probability where $d$ is the dimension and $n$ is the time horizon. In the stochastic setting the bound improves to $M d^{2} \\sqrt{n} \\mathrm{polylog}(n, d)$ where $M \\in [d^{-1/2}, d^{-1 / 4}]$ is a constant that depends on the geometry of the constraint set and the desired computational properties.",
    "authors": [
      "Hidde Fokkema",
      "Dirk van der Hoeven",
      "Tor Lattimore",
      "Jack J. Mayo"
    ],
    "url": "http://arxiv.org/abs/2406.06506v1",
    "timestamp": 1718041451,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.OC",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "636c25f6-17cb-4396-bdea-5670d4ca859f": {
    "pk": "636c25f6-17cb-4396-bdea-5670d4ca859f",
    "title": "Adaptive Opponent Policy Detection in Multi-Agent MDPs: Real-Time Strategy Switch Identification Using Running Error Estimation",
    "abstract": "In Multi-agent Reinforcement Learning (MARL), accurately perceiving opponents' strategies is essential for both cooperative and adversarial contexts, particularly within dynamic environments. While Proximal Policy Optimization (PPO) and related algorithms such as Actor-Critic with Experience Replay (ACER), Trust Region Policy Optimization (TRPO), and Deep Deterministic Policy Gradient (DDPG) perform well in single-agent, stationary environments, they suffer from high variance in MARL due to non-stationary and hidden policies of opponents, leading to diminished reward performance. Additionally, existing methods in MARL face significant challenges, including the need for inter-agent communication, reliance on explicit reward information, high computational demands, and sampling inefficiencies. These issues render them less effective in continuous environments where opponents may abruptly change their policies without prior notice. Against this background, we present OPS-DeMo (Online Policy Switch-Detection Model), an online algorithm that employs dynamic error decay to detect changes in opponents' policies. OPS-DeMo continuously updates its beliefs using an Assumed Opponent Policy (AOP) Bank and selects corresponding responses from a pre-trained Response Policy Bank. Each response policy is trained against consistently strategizing opponents, reducing training uncertainty and enabling the effective use of algorithms like PPO in multi-agent environments. Comparative assessments show that our approach outperforms PPO-trained models in dynamic scenarios like the Predator-Prey setting, providing greater robustness to sudden policy shifts and enabling more informed decision-making through precise opponent policy insights.",
    "authors": [
      "Mohidul Haque Mridul",
      "Mohammad Foysal Khan",
      "Redwan Ahmed Rizvee",
      "Md Mosaddek Khan"
    ],
    "url": "http://arxiv.org/abs/2406.06500v1",
    "timestamp": 1718040884,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5fd7edd7-7f01-4811-8242-86ec4756d59e": {
    "pk": "5fd7edd7-7f01-4811-8242-86ec4756d59e",
    "title": "NarrativeBridge: Enhancing Video Captioning with Causal-Temporal Narrative",
    "abstract": "Existing video captioning benchmarks and models lack coherent representations of causal-temporal narrative, which is sequences of events linked through cause and effect, unfolding over time and driven by characters or agents. This lack of narrative restricts models' ability to generate text descriptions that capture the causal and temporal dynamics inherent in video content. To address this gap, we propose NarrativeBridge, an approach comprising of: (1) a novel Causal-Temporal Narrative (CTN) captions benchmark generated using a large language model and few-shot prompting, explicitly encoding cause-effect temporal relationships in video descriptions, evaluated automatically to ensure caption quality and relevance; and (2) a dedicated Cause-Effect Network (CEN) architecture with separate encoders for capturing cause and effect dynamics independently, enabling effective learning and generation of captions with causal-temporal narrative. Extensive experiments demonstrate that CEN is more accurate in articulating the causal and temporal aspects of video content than the second best model (GIT): 17.88 and 17.44 CIDEr on the MSVD and MSR-VTT datasets, respectively. The proposed framework understands and generates nuanced text descriptions with intricate causal-temporal narrative structures present in videos, addressing a critical limitation in video captioning. For project details, visit https://narrativebridge.github.io/.",
    "authors": [
      "Asmar Nadeem",
      "Faegheh Sardari",
      "Robert Dawes",
      "Syed Sameed Husain",
      "Adrian Hilton",
      "Armin Mustafa"
    ],
    "url": "http://arxiv.org/abs/2406.06499v1",
    "timestamp": 1718040864,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "8e4f1436-ea5b-4513-bbe0-7ab9c1375caf": {
    "pk": "8e4f1436-ea5b-4513-bbe0-7ab9c1375caf",
    "title": "Direct Preference Optimization for Suppressing Hallucinated Prior Exams in Radiology Report Generation",
    "abstract": "Recent advances in generative vision-language models (VLMs) have exciting potential implications for AI in radiology, yet VLMs are also known to produce hallucinations, nonsensical text, and other unwanted behaviors that can waste clinicians' time and cause patient harm. Drawing on recent work on direct preference optimization (DPO), we propose a simple method for modifying the behavior of pretrained VLMs performing radiology report generation by suppressing unwanted types of generations. We apply our method to the prevention of hallucinations of prior exams, addressing a long-established problem behavior in models performing chest X-ray report generation. Across our experiments, we find that DPO fine-tuning achieves a 3.2-4.8x reduction in lines hallucinating prior exams while maintaining model performance on clinical accuracy metrics. Our work is, to the best of our knowledge, the first work to apply DPO to medical VLMs, providing a data- and compute- efficient way to suppress problem behaviors while maintaining overall clinical accuracy.",
    "authors": [
      "Oishi Banerjee",
      "Hong-Yu Zhou",
      "Subathra Adithan",
      "Stephen Kwak",
      "Kay Wu",
      "Pranav Rajpurkar"
    ],
    "url": "http://arxiv.org/abs/2406.06496v1",
    "timestamp": 1718040696,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b51e9b2b-b906-439a-ae7b-703547313f0c": {
    "pk": "b51e9b2b-b906-439a-ae7b-703547313f0c",
    "title": "Scaling Continuous Latent Variable Models as Probabilistic Integral Circuits",
    "abstract": "Probabilistic integral circuits (PICs) have been recently introduced as probabilistic models enjoying the key ingredient behind expressive generative models: continuous latent variables (LVs). PICs are symbolic computational graphs defining continuous LV models as hierarchies of functions that are summed and multiplied together, or integrated over some LVs. They are tractable if LVs can be analytically integrated out, otherwise they can be approximated by tractable probabilistic circuits (PC) encoding a hierarchical numerical quadrature process, called QPCs.   So far, only tree-shaped PICs have been explored, and training them via numerical quadrature requires memory-intensive processing at scale. In this paper, we address these issues, and present: (i) a pipeline for building DAG-shaped PICs out of arbitrary variable decompositions, (ii) a procedure for training PICs using tensorized circuit architectures, and (iii) neural functional sharing techniques to allow scalable training. In extensive experiments, we showcase the effectiveness of functional sharing and the superiority of QPCs over traditional PCs.",
    "authors": [
      "Gennaro Gala",
      "Cassio de Campos",
      "Antonio Vergari",
      "Erik Quaeghebeur"
    ],
    "url": "http://arxiv.org/abs/2406.06494v1",
    "timestamp": 1718040617,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "4626d024-54a2-4012-af42-be50b429b0b7": {
    "pk": "4626d024-54a2-4012-af42-be50b429b0b7",
    "title": "Input Driven Synchronization of Chaotic Neural Networks with Analyticaly Determined Conditional Lyapunov Exponents",
    "abstract": "Recurrent neural networks (RNNs) with random, but sufficiently strong and balanced coupling display a well known high-dimensional chaotic dynamics. Here, we investigate if externally applied inputs to these RNNs can stabilize globally synchronous, input-dependent solutions, in spite of the strong chaos-inducing coupling. We find that when the balance between excitation and inhibition is exact, that is when the row-sum of the weights is constant and 0, a globally applied input can readily synchronize all neurons onto a synchronous solution. The stability of the synchronous solution is analytically explored in this work with a master stability function. For any synchronous solution to the network dynamics, the conditional Lyapunov spectrum can be readily determined, with the stability of the synchronous solution critically dependent on the largest real eigenvalue component of the RNN weight matrix. We find that the smaller the maximum real component of the weight matrix eigenvalues, the more readily the network synchronizes. Further, the conditional Lyapunov exponents are easily computed numerically for any synchronization signal without simulating the RNN. Finally, for certain oscillatory synchronization signals, the conditional Lyapunov exponents can be determined analytically.",
    "authors": [
      "Jordan Culp",
      "Wilten Nicola"
    ],
    "url": "http://arxiv.org/abs/2406.06491v1",
    "timestamp": 1718040543,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "nlin.CD",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "a3373c87-37ce-48bf-9c61-ffec2f363451": {
    "pk": "a3373c87-37ce-48bf-9c61-ffec2f363451",
    "title": "Computationally efficient permutation tests for the multivariate two-sample problem based on energy distance or maximum mean discrepancy statistics",
    "abstract": "Non-parametric two-sample tests based on energy distance or maximum mean discrepancy are widely used statistical tests for comparing multivariate data from two populations. While these tests enjoy desirable statistical properties, their test statistics can be expensive to compute as they require the computation of 3 distinct Euclidean distance (or kernel) matrices between samples, where the time complexity of each of these computations (namely, $O(n_{x}^2 p)$, $O(n_{y}^2 p)$, and $O(n_{x} n_{y} p)$) scales quadratically with the number of samples ($n_x$, $n_y$) and linearly with the number of variables ($p$). Since the standard permutation test requires repeated re-computations of these expensive statistics it's application to large datasets can become unfeasible. While several statistical approaches have been proposed to mitigate this issue, they all sacrifice desirable statistical properties to decrease the computational cost (e.g., trade computation speed by a decrease in statistical power). A better computational strategy is to first pre-compute the Euclidean distance (kernel) matrix of the concatenated data, and then permute indexes and retrieve the corresponding elements to compute the re-sampled statistics. While this strategy can reduce the computation cost relative to the standard permutation test, it relies on the computation of a larger Euclidean distance (kernel) matrix with complexity $O((n_x + n_y)^2 p)$. In this paper, we present a novel computationally efficient permutation algorithm which only requires the pre-computation of the 3 smaller matrices and achieves large computational speedups without sacrificing finite-sample validity or statistical power. We illustrate its computational gains in a series of experiments and compare its statistical power to the current state-of-the-art approach for balancing computational cost and statistical performance.",
    "authors": [
      "Elias Chaibub Neto"
    ],
    "url": "http://arxiv.org/abs/2406.06488v1",
    "timestamp": 1718040427,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "stat.CO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "2199c616-498e-4a5d-914b-505bf9ab5130": {
    "pk": "2199c616-498e-4a5d-914b-505bf9ab5130",
    "title": "Continuum Attention for Neural Operators",
    "abstract": "Transformers, and the attention mechanism in particular, have become ubiquitous in machine learning. Their success in modeling nonlocal, long-range correlations has led to their widespread adoption in natural language processing, computer vision, and time-series problems. Neural operators, which map spaces of functions into spaces of functions, are necessarily both nonlinear and nonlocal if they are universal; it is thus natural to ask whether the attention mechanism can be used in the design of neural operators. Motivated by this, we study transformers in the function space setting. We formulate attention as a map between infinite dimensional function spaces and prove that the attention mechanism as implemented in practice is a Monte Carlo or finite difference approximation of this operator. The function space formulation allows for the design of transformer neural operators, a class of architectures designed to learn mappings between function spaces, for which we prove a universal approximation result. The prohibitive cost of applying the attention operator to functions defined on multi-dimensional domains leads to the need for more efficient attention-based architectures. For this reason we also introduce a function space generalization of the patching strategy from computer vision, and introduce a class of associated neural operators. Numerical results, on an array of operator learning problems, demonstrate the promise of our approaches to function space formulations of attention and their use in neural operators.",
    "authors": [
      "Edoardo Calvello",
      "Nikola B. Kovachki",
      "Matthew E. Levine",
      "Andrew M. Stuart"
    ],
    "url": "http://arxiv.org/abs/2406.06486v1",
    "timestamp": 1718040346,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "cf1e2c0a-21f3-4983-903f-e8dc31d9bfdb": {
    "pk": "cf1e2c0a-21f3-4983-903f-e8dc31d9bfdb",
    "title": "Can Language Models Serve as Text-Based World Simulators?",
    "abstract": "Virtual environments play a key role in benchmarking advances in complex planning and decision-making tasks but are expensive and complicated to build by hand. Can current language models themselves serve as world simulators, correctly predicting how actions change different world states, thus bypassing the need for extensive manual coding? Our goal is to answer this question in the context of text-based simulators. Our approach is to build and use a new benchmark, called ByteSized32-State-Prediction, containing a dataset of text game state transitions and accompanying game tasks. We use this to directly quantify, for the first time, how well LLMs can serve as text-based world simulators. We test GPT-4 on this dataset and find that, despite its impressive performance, it is still an unreliable world simulator without further innovations. This work thus contributes both new insights into current LLM's capabilities and weaknesses, as well as a novel benchmark to track future progress as new models appear.",
    "authors": [
      "Ruoyao Wang",
      "Graham Todd",
      "Ziang Xiao",
      "Xingdi Yuan",
      "Marc-Alexandre C\u00f4t\u00e9",
      "Peter Clark",
      "Peter Jansen"
    ],
    "url": "http://arxiv.org/abs/2406.06485v1",
    "timestamp": 1718040284,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "95b88e13-c985-48cc-92cf-7a36314df5f0": {
    "pk": "95b88e13-c985-48cc-92cf-7a36314df5f0",
    "title": "Parallelizing Linear Transformers with the Delta Rule over Sequence Length",
    "abstract": "Transformers with linear attention (i.e., linear transformers) and state-space models have recently been suggested as a viable linear-time alternative to transformers with softmax attention. However, these models still underperform transformers especially on tasks that require in-context retrieval. While more expressive variants of linear transformers which replace the additive outer-product update in linear transformers with the delta rule have been found to be more effective at associative recall, existing algorithms for training such models do not parallelize over sequence length and are thus inefficient to train on modern hardware. This work describes a hardware-efficient algorithm for training linear transformers with the delta rule, which exploits a memory-efficient representation for computing products of Householder matrices. This algorithm allows us to scale up DeltaNet to standard language modeling settings. We train a 1.3B model for 100B tokens and find that it outperforms recent linear-time baselines such as Mamba and GLA in terms of perplexity and zero-shot performance on downstream tasks (including on tasks that focus on recall). We also experiment with two hybrid models which combine DeltaNet layers with (1) sliding-window attention layers every other layer or (2) two global attention layers, and find that these hybrid models outperform strong transformer baselines.",
    "authors": [
      "Songlin Yang",
      "Bailin Wang",
      "Yu Zhang",
      "Yikang Shen",
      "Yoon Kim"
    ],
    "url": "http://arxiv.org/abs/2406.06484v1",
    "timestamp": 1718040282,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "8f4bbba7-872e-4a6b-a703-fd7f579574e1": {
    "pk": "8f4bbba7-872e-4a6b-a703-fd7f579574e1",
    "title": "Graph-Based Bidirectional Transformer Decision Threshold Adjustment Algorithm for Class-Imbalanced Molecular Data",
    "abstract": "Data sets with imbalanced class sizes, often where one class size is much smaller than that of others, occur extremely often in various applications, including those with biological foundations, such as drug discovery and disease diagnosis. Thus, it is extremely important to be able to identify data elements of classes of various sizes, as a failure to detect can result in heavy costs. However, many data classification algorithms do not perform well on imbalanced data sets as they often fail to detect elements belonging to underrepresented classes. In this paper, we propose the BTDT-MBO algorithm, incorporating Merriman-Bence-Osher (MBO) techniques and a bidirectional transformer, as well as distance correlation and decision threshold adjustments, for data classification problems on highly imbalanced molecular data sets, where the sizes of the classes vary greatly. The proposed method not only integrates adjustments in the classification threshold for the MBO algorithm in order to help deal with the class imbalance, but also uses a bidirectional transformer model based on an attention mechanism for self-supervised learning. Additionally, the method implements distance correlation as a weight function for the similarity graph-based framework on which the adjusted MBO algorithm operates. The proposed model is validated using six molecular data sets, and we also provide a thorough comparison to other competing algorithms. The computational experiments show that the proposed method performs better than competing techniques even when the class imbalance ratio is very high.",
    "authors": [
      "Nicole Hayes",
      "Ekaterina Merkurjev",
      "Guo-Wei Wei"
    ],
    "url": "http://arxiv.org/abs/2406.06479v1",
    "timestamp": 1718040013,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "cfe503e1-2484-4c6a-9dd5-1a8c21fbb3b6": {
    "pk": "cfe503e1-2484-4c6a-9dd5-1a8c21fbb3b6",
    "title": "Towards a Personal Health Large Language Model",
    "abstract": "In health, most large language model (LLM) research has focused on clinical tasks. However, mobile and wearable devices, which are rarely integrated into such tasks, provide rich, longitudinal data for personal health monitoring. Here we present Personal Health Large Language Model (PH-LLM), fine-tuned from Gemini for understanding and reasoning over numerical time-series personal health data. We created and curated three datasets that test 1) production of personalized insights and recommendations from sleep patterns, physical activity, and physiological responses, 2) expert domain knowledge, and 3) prediction of self-reported sleep outcomes. For the first task we designed 857 case studies in collaboration with domain experts to assess real-world scenarios in sleep and fitness. Through comprehensive evaluation of domain-specific rubrics, we observed that Gemini Ultra 1.0 and PH-LLM are not statistically different from expert performance in fitness and, while experts remain superior for sleep, fine-tuning PH-LLM provided significant improvements in using relevant domain knowledge and personalizing information for sleep insights. We evaluated PH-LLM domain knowledge using multiple choice sleep medicine and fitness examinations. PH-LLM achieved 79% on sleep and 88% on fitness, exceeding average scores from a sample of human experts. Finally, we trained PH-LLM to predict self-reported sleep quality outcomes from textual and multimodal encoding representations of wearable data, and demonstrate that multimodal encoding is required to match performance of specialized discriminative models. Although further development and evaluation are necessary in the safety-critical personal health domain, these results demonstrate both the broad knowledge and capabilities of Gemini models and the benefit of contextualizing physiological data for personal health applications as done with PH-LLM.",
    "authors": [
      "Justin Cosentino",
      "Anastasiya Belyaeva",
      "Xin Liu",
      "Nicholas A. Furlotte",
      "Zhun Yang",
      "Chace Lee",
      "Erik Schenck",
      "Yojan Patel",
      "Jian Cui",
      "Logan Douglas Schneider",
      "Robby Bryant",
      "Ryan G. Gomes",
      "Allen Jiang",
      "Roy Lee",
      "Yun Liu",
      "Javier Perez",
      "Jameson K. Rogers",
      "Cathy Speed",
      "Shyam Tailor",
      "Megan Walker",
      "Jeffrey Yu",
      "Tim Althoff",
      "Conor Heneghan",
      "John Hernandez",
      "Mark Malhotra",
      "Leor Stern",
      "Yossi Matias",
      "Greg S. Corrado",
      "Shwetak Patel",
      "Shravya Shetty",
      "Jiening Zhan",
      "Shruthi Prabhakara",
      "Daniel McDuff",
      "Cory Y. McLean"
    ],
    "url": "http://arxiv.org/abs/2406.06474v1",
    "timestamp": 1718039809,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "3d57202b-2fb2-4e7b-803d-716a91f8a9db": {
    "pk": "3d57202b-2fb2-4e7b-803d-716a91f8a9db",
    "title": "Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning",
    "abstract": "Language agents perform complex tasks by using tools to execute each step precisely. However, most existing agents are based on proprietary models or designed to target specific tasks, such as mathematics or multi-hop question answering. We introduce Husky, a holistic, open-source language agent that learns to reason over a unified action space to address a diverse set of complex tasks involving numerical, tabular, and knowledge-based reasoning. Husky iterates between two stages: 1) generating the next action to take towards solving a given task and 2) executing the action using expert models and updating the current solution state. We identify a thorough ontology of actions for addressing complex tasks and curate high-quality data to train expert models for executing these actions. Our experiments show that Husky outperforms prior language agents across 14 evaluation datasets. Moreover, we introduce HuskyQA, a new evaluation set which stress tests language agents for mixed-tool reasoning, with a focus on retrieving missing knowledge and performing numerical reasoning. Despite using 7B models, Husky matches or even exceeds frontier LMs such as GPT-4 on these tasks, showcasing the efficacy of our holistic approach in addressing complex reasoning problems. Our code and models are available at https://github.com/agent-husky/Husky-v1.",
    "authors": [
      "Joongwon Kim",
      "Bhargavi Paranjape",
      "Tushar Khot",
      "Hannaneh Hajishirzi"
    ],
    "url": "http://arxiv.org/abs/2406.06469v1",
    "timestamp": 1718039245,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "cc530380-b18b-4ef0-a5f0-8c9c5984fa18": {
    "pk": "cc530380-b18b-4ef0-a5f0-8c9c5984fa18",
    "title": "Randomized Binary and Tree Search under Pressure",
    "abstract": "We study a generalized binary search problem on the line and general trees. On the line (e.g., a sorted array), binary search finds a target node in $O(\\log n)$ queries in the worst case, where $n$ is the number of nodes. In situations with limited budget or time, we might only be able to perform a few queries, possibly sub-logarithmic many. In this case, it is impossible to guarantee that the target will be found regardless of its position. Our main result is the construction of a randomized strategy that maximizes the minimum (over the target position) probability of finding the target. Such a strategy provides a natural solution where there is no apriori (stochastic) information of the target's position. As with regular binary search, we can find and run the strategy in $O(\\log n)$ time (and using only $O(\\log n)$ random bits). Our construction is obtained by reinterpreting the problem as a two-player (\\textit{seeker} and \\textit{hider}) zero-sum game and exploiting an underlying number theoretical structure.   Furthermore, we generalize the setting to study a search game on trees. In this case, a query returns the edge's endpoint closest to the target. Again, when the number of queries is bounded by some given $k$, we quantify a \\emph{the-less-queries-the-better} approach by defining a seeker's profit $p$ depending on the number of queries needed to locate the hider. For the linear programming formulation of the corresponding zero-sum game, we show that computing the best response for the hider (i.e., the separation problem of the underlying dual LP) can be done in time $O(n^2 2^{2k})$, where $n$ is the size of the tree. This result allows to compute a Nash equilibrium in polynomial time whenever $k=O(\\log n)$. In contrast, computing the best response for the hider is NP-hard.",
    "authors": [
      "Agust\u00edn Caracci",
      "Christoph D\u00fcrr",
      "Jos\u00e9 Verschae"
    ],
    "url": "http://arxiv.org/abs/2406.06468v1",
    "timestamp": 1718039195,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.DS",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f662272b-9399-4d09-a606-fb32e8ba7ab8": {
    "pk": "f662272b-9399-4d09-a606-fb32e8ba7ab8",
    "title": "AID: Adapting Image2Video Diffusion Models for Instruction-guided Video Prediction",
    "abstract": "Text-guided video prediction (TVP) involves predicting the motion of future frames from the initial frame according to an instruction, which has wide applications in virtual reality, robotics, and content creation. Previous TVP methods make significant breakthroughs by adapting Stable Diffusion for this task. However, they struggle with frame consistency and temporal stability primarily due to the limited scale of video datasets. We observe that pretrained Image2Video diffusion models possess good priors for video dynamics but they lack textual control. Hence, transferring Image2Video models to leverage their video dynamic priors while injecting instruction control to generate controllable videos is both a meaningful and challenging task. To achieve this, we introduce the Multi-Modal Large Language Model (MLLM) to predict future video states based on initial frames and text instructions. More specifically, we design a dual query transformer (DQFormer) architecture, which integrates the instructions and frames into the conditional embeddings for future frame prediction. Additionally, we develop Long-Short Term Temporal Adapters and Spatial Adapters that can quickly transfer general video diffusion models to specific scenarios with minimal training costs. Experimental results show that our method significantly outperforms state-of-the-art techniques on four datasets: Something Something V2, Epic Kitchen-100, Bridge Data, and UCF-101. Notably, AID achieves 91.2% and 55.5% FVD improvements on Bridge and SSv2 respectively, demonstrating its effectiveness in various domains. More examples can be found at our website https://chenhsing.github.io/AID.",
    "authors": [
      "Zhen Xing",
      "Qi Dai",
      "Zejia Weng",
      "Zuxuan Wu",
      "Yu-Gang Jiang"
    ],
    "url": "http://arxiv.org/abs/2406.06465v1",
    "timestamp": 1718038928,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "843e85c1-1e73-40e8-a25f-302a470ea736": {
    "pk": "843e85c1-1e73-40e8-a25f-302a470ea736",
    "title": "Transforming Wearable Data into Health Insights using Large Language Model Agents",
    "abstract": "Despite the proliferation of wearable health trackers and the importance of sleep and exercise to health, deriving actionable personalized insights from wearable data remains a challenge because doing so requires non-trivial open-ended analysis of these data. The recent rise of large language model (LLM) agents, which can use tools to reason about and interact with the world, presents a promising opportunity to enable such personalized analysis at scale. Yet, the application of LLM agents in analyzing personal health is still largely untapped. In this paper, we introduce the Personal Health Insights Agent (PHIA), an agent system that leverages state-of-the-art code generation and information retrieval tools to analyze and interpret behavioral health data from wearables. We curate two benchmark question-answering datasets of over 4000 health insights questions. Based on 650 hours of human and expert evaluation we find that PHIA can accurately address over 84% of factual numerical questions and more than 83% of crowd-sourced open-ended questions. This work has implications for advancing behavioral health across the population, potentially enabling individuals to interpret their own wearable data, and paving the way for a new era of accessible, personalized wellness regimens that are informed by data-driven insights.",
    "authors": [
      "Mike A. Merrill",
      "Akshay Paruchuri",
      "Naghmeh Rezaei",
      "Geza Kovacs",
      "Javier Perez",
      "Yun Liu",
      "Erik Schenck",
      "Nova Hammerquist",
      "Jake Sunshine",
      "Shyam Tailor",
      "Kumar Ayush",
      "Hao-Wei Su",
      "Qian He",
      "Cory McLean",
      "Mark Malhotra",
      "Shwetak Patel",
      "Jiening Zhan",
      "Tim Althoff",
      "Daniel McDuff",
      "Xin Liu"
    ],
    "url": "http://arxiv.org/abs/2406.06464v1",
    "timestamp": 1718038854,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "da9327fd-23bb-4355-9cba-52f407d34dff": {
    "pk": "da9327fd-23bb-4355-9cba-52f407d34dff",
    "title": "VCR: Visual Caption Restoration",
    "abstract": "We introduce Visual Caption Restoration (VCR), a novel vision-language task that challenges models to accurately restore partially obscured texts using pixel-level hints within images. This task stems from the observation that text embedded in images is intrinsically different from common visual elements and natural language due to the need to align the modalities of vision, text, and text embedded in images. While numerous works have integrated text embedded in images into visual question-answering tasks, approaches to these tasks generally rely on optical character recognition or masked language modeling, thus reducing the task to mainly text-based processing. However, text-based processing becomes ineffective in VCR as accurate text restoration depends on the combined information from provided images, context, and subtle cues from the tiny exposed areas of masked texts. We develop a pipeline to generate synthetic images for the VCR task using image-caption pairs, with adjustable caption visibility to control the task difficulty. With this pipeline, we construct a dataset for VCR called VCR-Wiki using images with captions from Wikipedia, comprising 2.11M English and 346K Chinese entities in both easy and hard split variants. Our results reveal that current vision language models significantly lag behind human performance in the VCR task, and merely fine-tuning the models on our dataset does not lead to notable improvements. We release VCR-Wiki and the data construction code to facilitate future research.",
    "authors": [
      "Tianyu Zhang",
      "Suyuchen Wang",
      "Lu Li",
      "Ge Zhang",
      "Perouz Taslakian",
      "Sai Rajeswar",
      "Jie Fu",
      "Bang Liu",
      "Yoshua Bengio"
    ],
    "url": "http://arxiv.org/abs/2406.06462v1",
    "timestamp": 1718038728,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "9f99714d-8b11-4d6a-b3a9-9972c1729b6b": {
    "pk": "9f99714d-8b11-4d6a-b3a9-9972c1729b6b",
    "title": "Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies",
    "abstract": "A diverse array of reasoning strategies has been proposed to elicit the capabilities of large language models. However, in this paper, we point out that traditional evaluations which focus solely on performance metrics miss a key factor: the increased effectiveness due to additional compute. By overlooking this aspect, a skewed view of strategy efficiency is often presented. This paper introduces a framework that incorporates the compute budget into the evaluation, providing a more informative comparison that takes into account both performance metrics and computational cost. In this budget-aware perspective, we find that complex reasoning strategies often don't surpass simpler baselines purely due to algorithmic ingenuity, but rather due to the larger computational resources allocated. When we provide a simple baseline like chain-of-thought self-consistency with comparable compute resources, it frequently outperforms reasoning strategies proposed in the literature. In this scale-aware perspective, we find that unlike self-consistency, certain strategies such as multi-agent debate or Reflexion can become worse if more compute budget is utilized.",
    "authors": [
      "Junlin Wang",
      "Siddhartha Jain",
      "Dejiao Zhang",
      "Baishakhi Ray",
      "Varun Kumar",
      "Ben Athiwaratkun"
    ],
    "url": "http://arxiv.org/abs/2406.06461v1",
    "timestamp": 1718038508,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "ee5c8011-53fb-408a-960b-f298ff4c84fe": {
    "pk": "ee5c8011-53fb-408a-960b-f298ff4c84fe",
    "title": "How Useful is Intermittent, Asynchronous Expert Feedback for Bayesian Optimization?",
    "abstract": "Bayesian optimization (BO) is an integral part of automated scientific discovery -- the so-called self-driving lab -- where human inputs are ideally minimal or at least non-blocking. However, scientists often have strong intuition, and thus human feedback is still useful. Nevertheless, prior works in enhancing BO with expert feedback, such as by incorporating it in an offline or online but blocking (arrives at each BO iteration) manner, are incompatible with the spirit of self-driving labs. In this work, we study whether a small amount of randomly arriving expert feedback that is being incorporated in a non-blocking manner can improve a BO campaign. To this end, we run an additional, independent computing thread on top of the BO loop to handle the feedback-gathering process. The gathered feedback is used to learn a Bayesian preference model that can readily be incorporated into the BO thread, to steer its exploration-exploitation process. Experiments on toy and chemistry datasets suggest that even just a few intermittent, asynchronous expert feedback can be useful for improving or constraining BO. This can especially be useful for its implication in improving self-driving labs, e.g. making them more data-efficient and less costly.",
    "authors": [
      "Agustinus Kristiadi",
      "Felix Strieth-Kalthoff",
      "Sriram Ganapathi Subramanian",
      "Vincent Fortuin",
      "Pascal Poupart",
      "Geoff Pleiss"
    ],
    "url": "http://arxiv.org/abs/2406.06459v1",
    "timestamp": 1718038438,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "08ffe6fb-b041-4682-9328-619b0a0005bb": {
    "pk": "08ffe6fb-b041-4682-9328-619b0a0005bb",
    "title": "Evaluating the Retrieval Component in LLM-Based Question Answering Systems",
    "abstract": "Question answering systems (QA) utilizing Large Language Models (LLMs) heavily depend on the retrieval component to provide them with domain-specific information and reduce the risk of generating inaccurate responses or hallucinations. Although the evaluation of retrievers dates back to the early research in Information Retrieval, assessing their performance within LLM-based chatbots remains a challenge.   This study proposes a straightforward baseline for evaluating retrievers in Retrieval-Augmented Generation (RAG)-based chatbots. Our findings demonstrate that this evaluation framework provides a better image of how the retriever performs and is more aligned with the overall performance of the QA system. Although conventional metrics such as precision, recall, and F1 score may not fully capture LLMs' capabilities - as they can yield accurate responses despite imperfect retrievers - our method considers LLMs' strengths to ignore irrelevant contexts, as well as potential errors and hallucinations in their responses.",
    "authors": [
      "Ashkan Alinejad",
      "Krtin Kumar",
      "Ali Vahdat"
    ],
    "url": "http://arxiv.org/abs/2406.06458v1",
    "timestamp": 1718037982,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "73deb09a-9e27-4046-bc86-165a65962bf8": {
    "pk": "73deb09a-9e27-4046-bc86-165a65962bf8",
    "title": "A Large Language Model Pipeline for Breast Cancer Oncology",
    "abstract": "Large language models (LLMs) have demonstrated potential in the innovation of many disciplines. However, how they can best be developed for oncology remains underdeveloped. State-of-the-art OpenAI models were fine-tuned on a clinical dataset and clinical guidelines text corpus for two important cancer treatment factors, adjuvant radiation therapy and chemotherapy, using a novel Langchain prompt engineering pipeline. A high accuracy (0.85+) was achieved in the classification of adjuvant radiation therapy and chemotherapy for breast cancer patients. Furthermore, a confidence interval was formed from observational data on the quality of treatment from human oncologists to estimate the proportion of scenarios in which the model must outperform the original oncologist in its treatment prediction to be a better solution overall as 8.2% to 13.3%. Due to indeterminacy in the outcomes of cancer treatment decisions, future investigation, potentially a clinical trial, would be required to determine if this threshold was met by the models. Nevertheless, with 85% of U.S. cancer patients receiving treatment at local community facilities, these kinds of models could play an important part in expanding access to quality care with outcomes that lie, at minimum, close to a human oncologist.",
    "authors": [
      "Tristen Pool",
      "Dennis Trujillo"
    ],
    "url": "http://arxiv.org/abs/2406.06455v1",
    "timestamp": 1718037888,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "ef6f97ce-aedc-45c9-af95-a4092fc634aa": {
    "pk": "ef6f97ce-aedc-45c9-af95-a4092fc634aa",
    "title": "Time Series Analysis: yesterday, today, tomorrow",
    "abstract": "Forecasts of various processes have always been a sophisticated problem for statistics and data science. Over the past decades the solution procedures were updated by deep learning and kernel methods. According to many specialists, these approaches are much more precise, stable, and suitable compared to the classical statistical linear time series methods. Here we investigate how true this point of view is.",
    "authors": [
      "Igor Mackarov"
    ],
    "url": "http://arxiv.org/abs/2406.06453v1",
    "timestamp": 1718037764,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CY",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "19a5c4f0-7a33-4c65-9372-3e7d12881737": {
    "pk": "19a5c4f0-7a33-4c65-9372-3e7d12881737",
    "title": "Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course",
    "abstract": "The capability of large language models (LLMs) to generate, debug, and explain code has sparked the interest of researchers and educators in undergraduate programming, with many anticipating their transformative potential in programming education. However, decisions about why and how to use LLMs in programming education may involve more than just the assessment of an LLM's technical capabilities. Using the social shaping of technology theory as a guiding framework, our study explores how students' social perceptions influence their own LLM usage. We then examine the correlation of self-reported LLM usage with students' self-efficacy and midterm performances in an undergraduate programming course. Triangulating data from an anonymous end-of-course student survey (n = 158), a mid-course self-efficacy survey (n=158), student interviews (n = 10), self-reported LLM usage on homework, and midterm performances, we discovered that students' use of LLMs was associated with their expectations for their future careers and their perceptions of peer usage. Additionally, early self-reported LLM usage in our context correlated with lower self-efficacy and lower midterm scores, while students' perceived over-reliance on LLMs, rather than their usage itself, correlated with decreased self-efficacy later in the course.",
    "authors": [
      "Aadarsh Padiyath",
      "Xinying Hou",
      "Amy Pang",
      "Diego Viramontes Vargas",
      "Xingjian Gu",
      "Tamara Nelson-Fromm",
      "Zihan Wu",
      "Mark Guzdial",
      "Barbara Ericson"
    ],
    "url": "http://arxiv.org/abs/2406.06451v1",
    "timestamp": 1718037614,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.HC",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "9d7ea7a6-9932-475f-ab9e-3cd9ff1072e9": {
    "pk": "9d7ea7a6-9932-475f-ab9e-3cd9ff1072e9",
    "title": "Flat space spinning massive amplitudes from momentum space CFT",
    "abstract": "We discuss the flat space limit of AdS using the momentum space representation of CFT correlators. The flat space limit involves sending the AdS radius and the dimensions of operators dual to massive fields to infinity while also scaling appropriately the sources of the dual operators. In this limit, d-dimensional CFT correlators become (d+1)-dimensional scattering amplitudes. We exemplify our discussion with the computation of the flat-space limit of the CFT 3-point function of a conserved current, a non-conserved charged vector operator and its conjugate. The flat-space limit should yield the scattering amplitude of an Abelian gauge field with two massive vector fields. This scattering amplitude computes the electromagnetic form factors of the electromagnetic current in a spin-1 state, and these form factors encode the electromagnetic properties of the massive vector field (charge, magnetic moment and quadruple moment). In terms of the CFT, the flat-space limit amounts to zooming in the infrared region of the triple-K integrals that determine the 3-point function, while also scaling to infinity the order of (some of) the Bessel functions that feature in the triple-K integrals. In this limit the triple-K integral becomes proportional to the energy-preserving delta function, and the flat space limit correctly yields the corresponding flat space scattering amplitude in complete detail.",
    "authors": [
      "Raffaele Marotta",
      "Kostas Skenderis",
      "Mritunjay Verma"
    ],
    "url": "http://arxiv.org/abs/2406.06447v1",
    "timestamp": 1718037372,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "hep-th",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5874bb09-c452-414c-b1f6-f41a3911b3ed": {
    "pk": "5874bb09-c452-414c-b1f6-f41a3911b3ed",
    "title": "Parallel Quantum Local Search via Evolutionary Mechanism",
    "abstract": "We propose an innovative Parallel Quantum Local Search (PQLS) methodology that leverages the capabilities of small-scale quantum computers to efficiently address complex combinatorial optimization problems. Traditional Quantum Local Search (QLS) methods face limitations due to the sequential nature of solving sub-problems, which arises from dependencies between their solutions. Our approach transcends this constraint by simultaneously executing multiple QLS pathways and aggregating their most effective outcomes at certain intervals to establish a ``generation''. Each subsequent generation commences with the optimal solution from its predecessor, thereby significantly accelerating the convergence towards an optimal solution. Our findings demonstrate the profound impact of parallel quantum computing in enhancing the resolution of Ising problems, which are synonymous with combinatorial optimization challenges.",
    "authors": [
      "Chen-Yu Liu",
      "Kuan-Cheng Chen"
    ],
    "url": "http://arxiv.org/abs/2406.06445v1",
    "timestamp": 1718037352,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "63471970-8000-4306-9ec6-e92bbfaeba68": {
    "pk": "63471970-8000-4306-9ec6-e92bbfaeba68",
    "title": "LLM Dataset Inference: Did you train on my dataset?",
    "abstract": "The proliferation of large language models (LLMs) in the real world has come with a rise in copyright cases against companies for training their models on unlicensed data from the internet. Recent works have presented methods to identify if individual text sequences were members of the model's training data, known as membership inference attacks (MIAs). We demonstrate that the apparent success of these MIAs is confounded by selecting non-members (text sequences not used for training) belonging to a different distribution from the members (e.g., temporally shifted recent Wikipedia articles compared with ones used to train the model). This distribution shift makes membership inference appear successful. However, most MIA methods perform no better than random guessing when discriminating between members and non-members from the same distribution (e.g., in this case, the same period of time). Even when MIAs work, we find that different MIAs succeed at inferring membership of samples from different distributions. Instead, we propose a new dataset inference method to accurately identify the datasets used to train large language models. This paradigm sits realistically in the modern-day copyright landscape, where authors claim that an LLM is trained over multiple documents (such as a book) written by them, rather than one particular paragraph. While dataset inference shares many of the challenges of membership inference, we solve it by selectively combining the MIAs that provide positive signal for a given distribution, and aggregating them to perform a statistical test on a given dataset. Our approach successfully distinguishes the train and test sets of different subsets of the Pile with statistically significant p-values < 0.1, without any false positives.",
    "authors": [
      "Pratyush Maini",
      "Hengrui Jia",
      "Nicolas Papernot",
      "Adam Dziedzic"
    ],
    "url": "http://arxiv.org/abs/2406.06443v1",
    "timestamp": 1718037283,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "d492a3cd-a321-4982-a8e2-6190ef0a7aac": {
    "pk": "d492a3cd-a321-4982-a8e2-6190ef0a7aac",
    "title": "Interpretability of Language Models via Task Spaces",
    "abstract": "The usual way to interpret language models (LMs) is to test their performance on different benchmarks and subsequently infer their internal processes. In this paper, we present an alternative approach, concentrating on the quality of LM processing, with a focus on their language abilities. To this end, we construct 'linguistic task spaces' -- representations of an LM's language conceptualisation -- that shed light on the connections LMs draw between language phenomena. Task spaces are based on the interactions of the learning signals from different linguistic phenomena, which we assess via a method we call 'similarity probing'. To disentangle the learning signals of linguistic phenomena, we further introduce a method called 'fine-tuning via gradient differentials' (FTGD). We apply our methods to language models of three different scales and find that larger models generalise better to overarching general concepts for linguistic tasks, making better use of their shared structure. Further, the distributedness of linguistic processing increases with pre-training through increased parameter sharing between related linguistic tasks. The overall generalisation patterns are mostly stable throughout training and not marked by incisive stages, potentially explaining the lack of successful curriculum strategies for LMs.",
    "authors": [
      "Lucas Weber",
      "Jaap Jumelet",
      "Elia Bruni",
      "Dieuwke Hupkes"
    ],
    "url": "http://arxiv.org/abs/2406.06441v1",
    "timestamp": 1718037270,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f8ff778d-e871-429a-a0ec-fc4fff24dd92": {
    "pk": "f8ff778d-e871-429a-a0ec-fc4fff24dd92",
    "title": "Messengers: Breaking Echo Chambers in Collective Opinion Dynamics with Homophily",
    "abstract": "Collective estimation manifests computational intelligence emerging from inter-individual local interactions, e.g., by aggregating opinions from neighbors to estimate a quantity. Use cases of collective estimation may include directed motion in physical space, such that agents, for example, have to collectively explore a distributed feature, and collectively agree on a numerical value. In doing so, collectives face several challenges in achieving precise estimations. These challenges exhibit complex behaviors, particularly when the interaction network and opinion of agents evolve simultaneously. We take homophilic networks as an example, where disproportionate interaction with like-minded neighbors leads to the emergence of echo chambers, preventing collective consensus. Our simulation results confirm that, besides a lack of exposure to attitude-challenging opinions, seeking reaffirming information entraps agents in echo chambers. We propose a generic novel approach based on a Dichotomous Markov Process (DMP) where stubborn agents (called Messengers) connect the disconnected clusters by physically transporting their opinions to other clusters to inform and direct the other agents. We show that diverse collective behaviors arise from the DMP and study a continuum between task specialization with no switching (full-time Messengers), generalization with slow task switching (part-time Messengers), and rapid task switching (short-time Messengers) and its impact on system performance. Our results show that stubborn agents can, in various ways, break the echo chambers and promote consensus in collective opinion.",
    "authors": [
      "Mohsen Raoufi",
      "Heiko Hamann",
      "Pawel Romanczuk"
    ],
    "url": "http://arxiv.org/abs/2406.06440v1",
    "timestamp": 1718037203,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.SI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "7df720cc-97e0-4fcb-9866-37e0cdc663cf": {
    "pk": "7df720cc-97e0-4fcb-9866-37e0cdc663cf",
    "title": "Multimodal Contextualized Semantic Parsing from Speech",
    "abstract": "We introduce Semantic Parsing in Contextual Environments (SPICE), a task designed to enhance artificial agents' contextual awareness by integrating multimodal inputs with prior contexts. SPICE goes beyond traditional semantic parsing by offering a structured, interpretable framework for dynamically updating an agent's knowledge with new information, mirroring the complexity of human communication. We develop the VG-SPICE dataset, crafted to challenge agents with visual scene graph construction from spoken conversational exchanges, highlighting speech and visual data integration. We also present the Audio-Vision Dialogue Scene Parser (AViD-SP) developed for use on VG-SPICE. These innovations aim to improve multimodal information processing and integration. Both the VG-SPICE dataset and the AViD-SP model are publicly available.",
    "authors": [
      "Jordan Voas",
      "Raymond Mooney",
      "David Harwath"
    ],
    "url": "http://arxiv.org/abs/2406.06438v1",
    "timestamp": 1718037094,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "ffbe3b40-c6b5-45e6-9604-03e081185a06": {
    "pk": "ffbe3b40-c6b5-45e6-9604-03e081185a06",
    "title": "Solitary waves and kinks in FPU lattices with soft-hard-soft trilinear interactions",
    "abstract": "We consider a version of the classical Hamiltonian Fermi-Pasta-Ulam (FPU) problem with a trilinear force-strain relation of soft-hard-soft type that is in general non-symmetric. In addition to the classical spatially localized solitary waves, such hardening-softening model also exhibits supersonic kinks and finite-amplitude, spatially delocalized flat-top solitary waves that acquire the structure of a kink-antikink bundle when their velocity approaches the kink limit. Exploiting the fact that traveling waves are periodic modulo shift by a lattice spacing, we compute these solutions as fixed points of the corresponding nonlinear map and investigate how their properties depend on the parameter measuring the asymmetry of the problem. In a particularly interesting case when one of the soft regimes has zero elastic modulus, we obtain explicit solutions for sufficiently slow solitary waves. In contrast to conventional delocalization in the sonic limit, these compact structures mounted on a constant background become localized at the lattice scale as their velocity tends to zero. Numerical simulations of Riemann-type initial value problem in this degenerate model show the emergence of Whitham shocks that involve periodic trains of solitary waves. We investigate stability of the obtained solutions using direct numerical simulations and Floquet analysis. We also obtain explicit solutions for a quasicontinuum model that captures some important features of the discrete problem.",
    "authors": [
      "Anna Vainchtein",
      "Lev Truskinovsky"
    ],
    "url": "http://arxiv.org/abs/2406.06437v1",
    "timestamp": 1718036978,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "nlin.PS",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "be0947fc-7492-490b-b85a-93586efcd68c": {
    "pk": "be0947fc-7492-490b-b85a-93586efcd68c",
    "title": "Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain",
    "abstract": "In difficult decision-making scenarios, it is common to have conflicting opinions among expert human decision-makers as there may not be a single right answer. Such decisions may be guided by different attributes that can be used to characterize an individual's decision. We introduce a novel dataset for medical triage decision-making, labeled with a set of decision-maker attributes (DMAs). This dataset consists of 62 scenarios, covering six different DMAs, including ethical principles such as fairness and moral desert. We present a novel software framework for human-aligned decision-making by utilizing these DMAs, paving the way for trustworthy AI with better guardrails. Specifically, we demonstrate how large language models (LLMs) can serve as ethical decision-makers, and how their decisions can be aligned to different DMAs using zero-shot prompting. Our experiments focus on different open-source models with varying sizes and training techniques, such as Falcon, Mistral, and Llama 2. Finally, we also introduce a new form of weighted self-consistency that improves the overall quantified performance. Our results provide new research directions in the use of LLMs as alignable decision-makers. The dataset and open-source software are publicly available at: https://github.com/ITM-Kitware/llm-alignable-dm.",
    "authors": [
      "Brian Hu",
      "Bill Ray",
      "Alice Leung",
      "Amy Summerville",
      "David Joy",
      "Christopher Funk",
      "Arslan Basharat"
    ],
    "url": "http://arxiv.org/abs/2406.06435v1",
    "timestamp": 1718036723,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "eb7687df-38ee-4f72-90ab-66a91c695717": {
    "pk": "eb7687df-38ee-4f72-90ab-66a91c695717",
    "title": "Spatiotemporal Graph Neural Network Modelling Perfusion MRI",
    "abstract": "Perfusion MRI (pMRI) offers valuable insights into tumor vascularity and promises to predict tumor genotypes, thus benefiting prognosis for glioma patients, yet effective models tailored to 4D pMRI are still lacking. This study presents the first attempt to model 4D pMRI using a GNN-based spatiotemporal model PerfGAT, integrating spatial information and temporal kinetics to predict Isocitrate DeHydrogenase (IDH) mutation status in glioma patients. Specifically, we propose a graph structure learning approach based on edge attention and negative graphs to optimize temporal correlations modeling. Moreover, we design a dual-attention feature fusion module to integrate spatiotemporal features while addressing tumor-related brain regions. Further, we develop a class-balanced augmentation methods tailored to spatiotemporal data, which could mitigate the common label imbalance issue in clinical datasets. Our experimental results demonstrate that the proposed method outperforms other state-of-the-art approaches, promising to model pMRI effectively for patient characterization.",
    "authors": [
      "Ruodan Yan",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Chao Li"
    ],
    "url": "http://arxiv.org/abs/2406.06434v1",
    "timestamp": 1718036686,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.IV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "6a3e4706-a7f5-4214-a82f-d8ce3e97a8e0": {
    "pk": "6a3e4706-a7f5-4214-a82f-d8ce3e97a8e0",
    "title": "SYM3D: Learning Symmetric Triplanes for Better 3D-Awareness of GANs",
    "abstract": "Despite the growing success of 3D-aware GANs, which can be trained on 2D images to generate high-quality 3D assets, they still rely on multi-view images with camera annotations to synthesize sufficient details from all viewing directions. However, the scarce availability of calibrated multi-view image datasets, especially in comparison to single-view images, has limited the potential of 3D GANs. Moreover, while bypassing camera pose annotations with a camera distribution constraint reduces dependence on exact camera parameters, it still struggles to generate a consistent orientation of 3D assets. To this end, we propose SYM3D, a novel 3D-aware GAN designed to leverage the prevalent reflectional symmetry structure found in natural and man-made objects, alongside a proposed view-aware spatial attention mechanism in learning the 3D representation. We evaluate SYM3D on both synthetic (ShapeNet Chairs, Cars, and Airplanes) and real-world datasets (ABO-Chair), demonstrating its superior performance in capturing detailed geometry and texture, even when trained on only single-view images. Finally, we demonstrate the effectiveness of incorporating symmetry regularization in helping reduce artifacts in the modeling of 3D assets in the text-to-3D task.",
    "authors": [
      "Jing Yang",
      "Kyle Fogarty",
      "Fangcheng Zhong",
      "Cengiz Oztireli"
    ],
    "url": "http://arxiv.org/abs/2406.06432v1",
    "timestamp": 1718036647,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "024e54bb-5760-417b-83ef-5ae60c97d87f": {
    "pk": "024e54bb-5760-417b-83ef-5ae60c97d87f",
    "title": "Margin-aware Preference Optimization for Aligning Diffusion Models without Reference",
    "abstract": "Modern alignment techniques based on human preferences, such as RLHF and DPO, typically employ divergence regularization relative to the reference model to ensure training stability. However, this often limits the flexibility of models during alignment, especially when there is a clear distributional discrepancy between the preference data and the reference model. In this paper, we focus on the alignment of recent text-to-image diffusion models, such as Stable Diffusion XL (SDXL), and find that this \"reference mismatch\" is indeed a significant problem in aligning these models due to the unstructured nature of visual modalities: e.g., a preference for a particular stylistic aspect can easily induce such a discrepancy. Motivated by this observation, we propose a novel and memory-friendly preference alignment method for diffusion models that does not depend on any reference model, coined margin-aware preference optimization (MaPO). MaPO jointly maximizes the likelihood margin between the preferred and dispreferred image sets and the likelihood of the preferred sets, simultaneously learning general stylistic features and preferences. For evaluation, we introduce two new pairwise preference datasets, which comprise self-generated image pairs from SDXL, Pick-Style and Pick-Safety, simulating diverse scenarios of reference mismatch. Our experiments validate that MaPO can significantly improve alignment on Pick-Style and Pick-Safety and general preference alignment when used with Pick-a-Pic v2, surpassing the base SDXL and other existing methods. Our code, models, and datasets are publicly available via https://mapo-t2i.github.io",
    "authors": [
      "Jiwoo Hong",
      "Sayak Paul",
      "Noah Lee",
      "Kashif Rasul",
      "James Thorne",
      "Jongheon Jeong"
    ],
    "url": "http://arxiv.org/abs/2406.06424v1",
    "timestamp": 1718036085,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "9ea04b66-cfba-4bc0-84a1-0172b2d9b8dd": {
    "pk": "9ea04b66-cfba-4bc0-84a1-0172b2d9b8dd",
    "title": "Hybrid Video Anomaly Detection for Anomalous Scenarios in Autonomous Driving",
    "abstract": "In autonomous driving, the most challenging scenarios are the ones that can only be detected within their temporal context. Most video anomaly detection approaches focus either on surveillance or traffic accidents, which are only a subfield of autonomous driving. In this work, we present HF$^2$-VAD$_{AD}$, a variation of the HF$^2$-VAD surveillance video anomaly detection method for autonomous driving. We learn a representation of normality from a vehicle's ego perspective and evaluate pixel-wise anomaly detections in rare and critical scenarios.",
    "authors": [
      "Daniel Bogdoll",
      "Jan Imhof",
      "Tim Joseph",
      "J. Marius Z\u00f6llner"
    ],
    "url": "http://arxiv.org/abs/2406.06423v1",
    "timestamp": 1718036073,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b1df4da2-0328-4767-bf64-2e29627bc98b": {
    "pk": "b1df4da2-0328-4767-bf64-2e29627bc98b",
    "title": "Notes on Various Errors and Jacobian Derivations for SLAM",
    "abstract": "This paper delves into critical concepts and meticulous calculations pertinent to Simultaneous Localization and Mapping (SLAM), with a focus on error analysis and Jacobian matrices. We introduce various types of errors commonly encountered in SLAM, including reprojection error, photometric error, relative pose error, and line reprojection error, alongside their mathematical formulations. The fundamental role of error as the discrepancy between observed and predicted values in SLAM optimization is examined, emphasizing non-linear least squares methods for optimization.   We provide a detailed analysis of: - Reprojection Error: Including Jacobian calculations for camera poses and map points, highlighting both theoretical underpinnings and practical consequences. - Photometric Error: Addressing errors from image intensity variations, essential for direct method-based SLAM. - Relative Pose Error: Discussing its significance in pose graph optimization, especially in loop closure scenarios. The paper also presents extensive derivations of Jacobian matrices for various SLAM components such as camera poses, map points, and motion parameters. We explore the application of Lie theory to optimize rotation representations and transformations, improving computational efficiency. Specific software implementations are referenced, offering practical insights into the real-world application of these theories in SLAM systems.   Additionally, advanced topics such as line reprojection errors and IMU measurement errors are explored, discussing their impact on SLAM accuracy and performance. This comprehensive examination aims to enhance understanding and implementation of error analysis and Jacobian derivation in SLAM, contributing to more accurate and efficient state estimation in complex environments.",
    "authors": [
      "Gyubeom Im"
    ],
    "url": "http://arxiv.org/abs/2406.06422v1",
    "timestamp": 1718035991,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "6911b2ae-518d-4a77-bcb8-6983186c9fec": {
    "pk": "6911b2ae-518d-4a77-bcb8-6983186c9fec",
    "title": "Explainable Graph Neural Networks Under Fire",
    "abstract": "Predictions made by graph neural networks (GNNs) usually lack interpretability due to their complex computational behavior and the abstract nature of graphs. In an attempt to tackle this, many GNN explanation methods have emerged. Their goal is to explain a model's predictions and thereby obtain trust when GNN models are deployed in decision critical applications. Most GNN explanation methods work in a post-hoc manner and provide explanations in the form of a small subset of important edges and/or nodes. In this paper we demonstrate that these explanations can unfortunately not be trusted, as common GNN explanation methods turn out to be highly susceptible to adversarial perturbations. That is, even small perturbations of the original graph structure that preserve the model's predictions may yield drastically different explanations. This calls into question the trustworthiness and practical utility of post-hoc explanation methods for GNNs. To be able to attack GNN explanation models, we devise a novel attack method dubbed \\textit{GXAttack}, the first \\textit{optimization-based} adversarial attack method for post-hoc GNN explanations under such settings. Due to the devastating effectiveness of our attack, we call for an adversarial evaluation of future GNN explainers to demonstrate their robustness.",
    "authors": [
      "Zhong Li",
      "Simon Geisler",
      "Yuhang Wang",
      "Stephan G\u00fcnnemann",
      "Matthijs van Leeuwen"
    ],
    "url": "http://arxiv.org/abs/2406.06417v1",
    "timestamp": 1718035756,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "35ea9410-a583-4c01-9720-b2a9e2ff7914": {
    "pk": "35ea9410-a583-4c01-9720-b2a9e2ff7914",
    "title": "A Taxonomy of Challenges to Curating Fair Datasets",
    "abstract": "Despite extensive efforts to create fairer machine learning (ML) datasets, there remains a limited understanding of the practical aspects of dataset curation. Drawing from interviews with 30 ML dataset curators, we present a comprehensive taxonomy of the challenges and trade-offs encountered throughout the dataset curation lifecycle. Our findings underscore overarching issues within the broader fairness landscape that impact data curation. We conclude with recommendations aimed at fostering systemic changes to better facilitate fair dataset curation practices.",
    "authors": [
      "Dora Zhao",
      "Morgan Klaus Scheuerman",
      "Pooja Chitre",
      "Jerone T. A. Andrews",
      "Georgia Panagiotidou",
      "Shawn Walker",
      "Kathleen H. Pine",
      "Alice Xiang"
    ],
    "url": "http://arxiv.org/abs/2406.06407v1",
    "timestamp": 1718035148,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "79193b0b-c967-42dd-bc6c-a8e72d920f0d": {
    "pk": "79193b0b-c967-42dd-bc6c-a8e72d920f0d",
    "title": "Controlling Emotion in Text-to-Speech with Natural Language Prompts",
    "abstract": "In recent years, prompting has quickly become one of the standard ways of steering the outputs of generative machine learning models, due to its intuitive use of natural language. In this work, we propose a system conditioned on embeddings derived from an emotionally rich text that serves as prompt. Thereby, a joint representation of speaker and prompt embeddings is integrated at several points within a transformer-based architecture. Our approach is trained on merged emotional speech and text datasets and varies prompts in each training iteration to increase the generalization capabilities of the model. Objective and subjective evaluation results demonstrate the ability of the conditioned synthesis system to accurately transfer the emotions present in a prompt to speech. At the same time, precise tractability of speaker identities as well as overall high speech quality and intelligibility are maintained.",
    "authors": [
      "Thomas Bott",
      "Florian Lux",
      "Ngoc Thang Vu"
    ],
    "url": "http://arxiv.org/abs/2406.06406v1",
    "timestamp": 1718035122,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f4bb144a-036c-4de0-9cf9-41f5347c47d2": {
    "pk": "f4bb144a-036c-4de0-9cf9-41f5347c47d2",
    "title": "Meta Learning Text-to-Speech Synthesis in over 7000 Languages",
    "abstract": "In this work, we take on the challenging task of building a single text-to-speech synthesis system that is capable of generating speech in over 7000 languages, many of which lack sufficient data for traditional TTS development. By leveraging a novel integration of massively multilingual pretraining and meta learning to approximate language representations, our approach enables zero-shot speech synthesis in languages without any available data. We validate our system's performance through objective measures and human evaluation across a diverse linguistic landscape. By releasing our code and models publicly, we aim to empower communities with limited linguistic resources and foster further innovation in the field of speech technology.",
    "authors": [
      "Florian Lux",
      "Sarina Meyer",
      "Lyonel Behringer",
      "Frank Zalkow",
      "Phat Do",
      "Matt Coler",
      "Emanu\u00ebl A. P. Habets",
      "Ngoc Thang Vu"
    ],
    "url": "http://arxiv.org/abs/2406.06403v1",
    "timestamp": 1718035012,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b0078387-b998-4a62-9f4d-11648850790a": {
    "pk": "b0078387-b998-4a62-9f4d-11648850790a",
    "title": "Early Acceptance Matching Game for User-Centric Clustering in Scalable Cell-free MIMO Networks",
    "abstract": "The canonical setup is the primary approach adopted in cell-free multiple-input multiple-output (MIMO) networks, in which all access points (APs) jointly serve every user equipment (UE). This approach is not scalable in terms of computational complexity and fronthaul signaling becoming impractical in large networks. This work adopts a user-centric approach, a scalable alternative in which only a set of preferred APs jointly serve a UE. Forming the optimal cluster of APs for each UE is a challenging task, especially, when it needs to be dynamically adjusted to meet the quality of service (QoS) requirements of the UE. This complexity is even exacerbated when considering the constrained fronthaul capacity of the UE and the AP. We solve this problem with a novel many-to-many matching game. More specifically, we devise an early acceptance matching algorithm, which immediately admits or rejects UEs based on their requests and available radio resources. The proposed solution significantly reduces the fronthaul signaling while satisfying the maximum of UEs in terms of requested QoS compared to state-of-the-art approaches.",
    "authors": [
      "Ala Eddine Nouali",
      "Mohamed Sana",
      "Jean-Paul Jamont"
    ],
    "url": "http://arxiv.org/abs/2406.06402v1",
    "timestamp": 1718034974,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.SP",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "7a3058e2-657b-4b7b-9b50-d3383ded79e8": {
    "pk": "7a3058e2-657b-4b7b-9b50-d3383ded79e8",
    "title": "INTERSPEECH 2009 Emotion Challenge Revisited: Benchmarking 15 Years of Progress in Speech Emotion Recognition",
    "abstract": "We revisit the INTERSPEECH 2009 Emotion Challenge -- the first ever speech emotion recognition (SER) challenge -- and evaluate a series of deep learning models that are representative of the major advances in SER research in the time since then. We start by training each model using a fixed set of hyperparameters, and further fine-tune the best-performing models of that initial setup with a grid search. Results are always reported on the official test set with a separate validation set only used for early stopping. Most models score below or close to the official baseline, while they marginally outperform the original challenge winners after hyperparameter tuning. Our work illustrates that, despite recent progress, FAU-AIBO remains a very challenging benchmark. An interesting corollary is that newer methods do not consistently outperform older ones, showing that progress towards `solving' SER is not necessarily monotonic.",
    "authors": [
      "Andreas Triantafyllopoulos",
      "Anton Batliner",
      "Simon Rampp",
      "Manuel Milling",
      "Bj\u00f6rn Schuller"
    ],
    "url": "http://arxiv.org/abs/2406.06401v1",
    "timestamp": 1718034906,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c94b9b61-8d17-455c-9629-2e9cafe85f0b": {
    "pk": "c94b9b61-8d17-455c-9629-2e9cafe85f0b",
    "title": "Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue",
    "abstract": "We study the limitations of Large Language Models (LLMs) for the task of response generation in human-machine dialogue. Several techniques have been proposed in the literature for different dialogue types (e.g., Open-Domain). However, the evaluations of these techniques have been limited in terms of base LLMs, dialogue types and evaluation metrics. In this work, we extensively analyze different LLM adaptation techniques when applied to different dialogue types. We have selected two base LLMs, Llama-2 and Mistral, and four dialogue types Open-Domain, Knowledge-Grounded, Task-Oriented, and Question Answering. We evaluate the performance of in-context learning and fine-tuning techniques across datasets selected for each dialogue type. We assess the impact of incorporating external knowledge to ground the generation in both scenarios of Retrieval-Augmented Generation (RAG) and gold knowledge. We adopt consistent evaluation and explainability criteria for automatic metrics and human evaluation protocols. Our analysis shows that there is no universal best-technique for adapting large language models as the efficacy of each technique depends on both the base LLM and the specific type of dialogue. Last but not least, the assessment of the best adaptation technique should include human evaluation to avoid false expectations and outcomes derived from automatic metrics.",
    "authors": [
      "Simone Alghisi",
      "Massimo Rizzoli",
      "Gabriel Roccabruna",
      "Seyed Mahed Mousavi",
      "Giuseppe Riccardi"
    ],
    "url": "http://arxiv.org/abs/2406.06399v1",
    "timestamp": 1718034769,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "472c3235-2111-4718-a5ca-f02c6833c8e2": {
    "pk": "472c3235-2111-4718-a5ca-f02c6833c8e2",
    "title": "Universality of AdaGrad Stepsizes for Stochastic Optimization: Inexact Oracle, Acceleration and Variance Reduction",
    "abstract": "We present adaptive gradient methods (both basic and accelerated) for solving convex composite optimization problems in which the main part is approximately smooth (a.k.a. $(\\delta, L)$-smooth) and can be accessed only via a (potentially biased) stochastic gradient oracle. This setting covers many interesting examples including H\\\"older smooth problems and various inexact computations of the stochastic gradient. Our methods use AdaGrad stepsizes and are adaptive in the sense that they do not require knowing any problem-dependent constants except an estimate of the diameter of the feasible set but nevertheless achieve the best possible convergence rates as if they knew the corresponding constants. We demonstrate that AdaGrad stepsizes work in a variety of situations by proving, in a unified manner, three types of new results. First, we establish efficiency guarantees for our methods in the classical setting where the oracle's variance is uniformly bounded. We then show that, under more refined assumptions on the variance, the same methods without any modifications enjoy implicit variance reduction properties allowing us to express their complexity estimates in terms of the variance only at the minimizer. Finally, we show how to incorporate explicit SVRG-type variance reduction into our methods and obtain even faster algorithms. In all three cases, we present both basic and accelerated algorithms achieving state-of-the-art complexity bounds. As a direct corollary of our results, we obtain universal stochastic gradient methods for H\\\"older smooth problems which can be used in all situations.",
    "authors": [
      "Anton Rodomanov",
      "Xiaowen Jiang",
      "Sebastian Stich"
    ],
    "url": "http://arxiv.org/abs/2406.06398v1",
    "timestamp": 1718034747,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.OC",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "e037ae33-5eb3-4cf7-9444-5ea806d2d44c": {
    "pk": "e037ae33-5eb3-4cf7-9444-5ea806d2d44c",
    "title": "Contrastive learning of T cell receptor representations",
    "abstract": "Computational prediction of the interaction of T cell receptors (TCRs) and their ligands is a grand challenge in immunology. Despite advances in high-throughput assays, specificity-labelled TCR data remains sparse. In other domains, the pre-training of language models on unlabelled data has been successfully used to address data bottlenecks. However, it is unclear how to best pre-train protein language models for TCR specificity prediction. Here we introduce a TCR language model called SCEPTR (Simple Contrastive Embedding of the Primary sequence of T cell Receptors), capable of data-efficient transfer learning. Through our model, we introduce a novel pre-training strategy combining autocontrastive learning and masked-language modelling, which enables SCEPTR to achieve its state-of-the-art performance. In contrast, existing protein language models and a variant of SCEPTR pre-trained without autocontrastive learning are outperformed by sequence alignment-based methods. We anticipate that contrastive learning will be a useful paradigm to decode the rules of TCR specificity.",
    "authors": [
      "Yuta Nagano",
      "Andrew Pyo",
      "Martina Milighetti",
      "James Henderson",
      "John Shawe-Taylor",
      "Benny Chain",
      "Andreas Tiffeau-Mayer"
    ],
    "url": "http://arxiv.org/abs/2406.06397v1",
    "timestamp": 1718034645,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "q-bio.BM",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c0ca86c8-6772-4e77-90b1-f678e4fa9312": {
    "pk": "c0ca86c8-6772-4e77-90b1-f678e4fa9312",
    "title": "A Gigabit, DMA-enhanced Open-Source Ethernet Controller for Mixed-Criticality Systems",
    "abstract": "The ongoing revolution in application domains targeting autonomous navigation, first and foremost automotive \"zonalization\", has increased the importance of certain off-chip communication interfaces, particularly Ethernet. The latter will play an essential role in next-generation vehicle architectures as the backbone connecting simultaneously and instantaneously the zonal/domain controllers. There is thereby an incumbent need to introduce a performant Ethernet controller in the open-source HW community, to be used as a proxy for architectural explorations and prototyping of mixed-criticality systems (MCSs). Driven by this trend, in this work, we propose a fully open-source, DMA-enhanced, technology-agnostic Gigabit Ethernet architecture that overcomes the limitations of existing open-source architectures, such as Lowrisc's Ethernet, often tied to FPGA implementation, performance-bound by sub-optimal design choices such as large memory buffers, and in general not mature enough to bridge the gap between academia and industry. Besides the area advantage, the proposed design increases packet transmission speed up to almost 3x compared to Lowrisc's and is validated through implementation and FPGA prototyping into two open-source, heterogeneous MCSs.",
    "authors": [
      "Chaoqun Liang",
      "Alessandro Ottaviano",
      "Thomas Benz",
      "Mattia Sinigaglia",
      "Luca Benini",
      "Angelo Garofalo",
      "Davide Rossi"
    ],
    "url": "http://arxiv.org/abs/2406.06394v1",
    "timestamp": 1718034488,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AR",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "d96470ed-24a9-4be6-a597-d111359d33ee": {
    "pk": "d96470ed-24a9-4be6-a597-d111359d33ee",
    "title": "STimage-1K4M: A histopathology image-gene expression dataset for spatial transcriptomics",
    "abstract": "Recent advances in multi-modal algorithms have driven and been driven by the increasing availability of large image-text datasets, leading to significant strides in various fields, including computational pathology. However, in most existing medical image-text datasets, the text typically provides high-level summaries that may not sufficiently describe sub-tile regions within a large pathology image. For example, an image might cover an extensive tissue area containing cancerous and healthy regions, but the accompanying text might only specify that this image is a cancer slide, lacking the nuanced details needed for in-depth analysis. In this study, we introduce STimage-1K4M, a novel dataset designed to bridge this gap by providing genomic features for sub-tile images. STimage-1K4M contains 1,149 images derived from spatial transcriptomics data, which captures gene expression information at the level of individual spatial spots within a pathology image. Specifically, each image in the dataset is broken down into smaller sub-image tiles, with each tile paired with 15,000-30,000 dimensional gene expressions. With 4,293,195 pairs of sub-tile images and gene expressions, STimage-1K4M offers unprecedented granularity, paving the way for a wide range of advanced research in multi-modal data analysis an innovative applications in computational pathology, and beyond.",
    "authors": [
      "Jiawen Chen",
      "Muqing Zhou",
      "Wenrong Wu",
      "Jinwei Zhang",
      "Yun Li",
      "Didong Li"
    ],
    "url": "http://arxiv.org/abs/2406.06393v1",
    "timestamp": 1718034487,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5f86b131-96ea-4669-aa6a-acf68365ef08": {
    "pk": "5f86b131-96ea-4669-aa6a-acf68365ef08",
    "title": "Towards Lifelong Learning of Large Language Models: A Survey",
    "abstract": "As the applications of large language models (LLMs) expand across diverse fields, the ability of these models to adapt to ongoing changes in data, tasks, and user preferences becomes crucial. Traditional training methods, relying on static datasets, are increasingly inadequate for coping with the dynamic nature of real-world information. Lifelong learning, also known as continual or incremental learning, addresses this challenge by enabling LLMs to learn continuously and adaptively over their operational lifetime, integrating new knowledge while retaining previously learned information and preventing catastrophic forgetting. This survey delves into the sophisticated landscape of lifelong learning, categorizing strategies into two primary groups: Internal Knowledge and External Knowledge. Internal Knowledge includes continual pretraining and continual finetuning, each enhancing the adaptability of LLMs in various scenarios. External Knowledge encompasses retrieval-based and tool-based lifelong learning, leveraging external data sources and computational tools to extend the model's capabilities without modifying core parameters. The key contributions of our survey are: (1) Introducing a novel taxonomy categorizing the extensive literature of lifelong learning into 12 scenarios; (2) Identifying common techniques across all lifelong learning scenarios and classifying existing literature into various technique groups within each scenario; (3) Highlighting emerging techniques such as model expansion and data selection, which were less explored in the pre-LLM era. Through a detailed examination of these groups and their respective categories, this survey aims to enhance the adaptability, reliability, and overall performance of LLMs in real-world applications.",
    "authors": [
      "Junhao Zheng",
      "Shengjie Qiu",
      "Chengming Shi",
      "Qianli Ma"
    ],
    "url": "http://arxiv.org/abs/2406.06391v1",
    "timestamp": 1718034385,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "60313475-8cd5-4fb6-b506-99822f6e7ad8": {
    "pk": "60313475-8cd5-4fb6-b506-99822f6e7ad8",
    "title": "Reconstructing the genealogy of LIGO-Virgo black holes",
    "abstract": "We propose a Bayesian inference framework to predict the merger history of LIGO-Virgo binary black holes, whose binary components may have undergone hierarchical mergers in the past. The framework relies on numerical relativity predictions for the mass, spin, and kick velocity of the remnant black holes. This proposed framework computes the masses, spins, and kicks imparted to the remnant of the parent binaries, given the initial masses and spin magnitudes of the binary constituents. We validate our approach by performing an \"injection study\" based on a constructed sequence of hierarchically-formed binaries. Noise is added to the final binary in the sequence, and the parameters of the 'parent' and 'grandparent' binaries in the merger chain are then reconstructed. This method is then applied to three GWTC-3 events: GW190521, GW200220_061928, GW190426_190642. These events were selected because at least one of the binary companions lies in the putative pair-instability supernova mass gap, in which stellar processes alone cannot produce black holes. Hierarchical mergers offer a natural explanation for the formation of black holes in the pair-instability mass-gap. We use the backward evolution framework to predict the parameters of the parents of the primary companion of these three binaries. Our results indicate that at least one component of these three observed binaries was formed through a prior binary black hole merger. This approach can be readily applied to future high-mass gravitational wave events to predict their formation history under the hierarchical merger assumption.",
    "authors": [
      "Parthapratim Mahapatra",
      "Debatri Chattopadhyay",
      "Anuradha Gupta",
      "Fabio Antonini",
      "Marc Favata",
      "B. S. Sathyaprakash",
      "K. G. Arun"
    ],
    "url": "http://arxiv.org/abs/2406.06390v1",
    "timestamp": 1718034338,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.HE",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "98f4e7b6-d02f-49b1-b678-c255b024fbda": {
    "pk": "98f4e7b6-d02f-49b1-b678-c255b024fbda",
    "title": "Time-tronics: from temporal printed circuit board to quantum computer",
    "abstract": "Time crystalline structures can be created in periodically driven systems. They are temporal lattices which can reveal different condensed matter behaviours ranging from Anderson localization in time to temporal analogues of many-body localization or topological insulators. However, the potential practical applications of time crystalline structures have yet to be explored. Here, we pave the way for time-tronics where temporal lattices are like printed circuit boards for realization of a broad range of quantum devices. The elements of these devices can correspond to structures of dimensions higher than three and can be arbitrarily connected and reconfigured at any moment. Moreover, our approach allows for the construction of a quantum computer, enabling quantum gate operations for all possible pairs of qubits. Our findings indicate that the limitations faced in building devices using conventional spatial crystals can be overcome by adopting crystalline structures in time.",
    "authors": [
      "Krzysztof Giergiel",
      "Peter Hannaford",
      "Krzysztof Sacha"
    ],
    "url": "http://arxiv.org/abs/2406.06387v1",
    "timestamp": 1718034289,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cond-mat.quant-gas",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "1f8ea75c-7379-4e5c-b2bc-ce0019935302": {
    "pk": "1f8ea75c-7379-4e5c-b2bc-ce0019935302",
    "title": "FPN-IAIA-BL: A Multi-Scale Interpretable Deep Learning Model for Classification of Mass Margins in Digital Mammography",
    "abstract": "Digital mammography is essential to breast cancer detection, and deep learning offers promising tools for faster and more accurate mammogram analysis. In radiology and other high-stakes environments, uninterpretable (\"black box\") deep learning models are unsuitable and there is a call in these fields to make interpretable models. Recent work in interpretable computer vision provides transparency to these formerly black boxes by utilizing prototypes for case-based explanations, achieving high accuracy in applications including mammography. However, these models struggle with precise feature localization, reasoning on large portions of an image when only a small part is relevant. This paper addresses this gap by proposing a novel multi-scale interpretable deep learning model for mammographic mass margin classification. Our contribution not only offers an interpretable model with reasoning aligned with radiologist practices, but also provides a general architecture for computer vision with user-configurable prototypes from coarse- to fine-grained prototypes.",
    "authors": [
      "Julia Yang",
      "Alina Jade Barnett",
      "Jon Donnelly",
      "Satvik Kishore",
      "Jerry Fang",
      "Fides Regina Schwartz",
      "Chaofan Chen",
      "Joseph Y. Lo",
      "Cynthia Rudin"
    ],
    "url": "http://arxiv.org/abs/2406.06386v1",
    "timestamp": 1718034281,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "50b4f3a9-d688-4636-908b-6f055ac90234": {
    "pk": "50b4f3a9-d688-4636-908b-6f055ac90234",
    "title": "Low-Rank Quantization-Aware Training for LLMs",
    "abstract": "Large language models (LLMs) are omnipresent, however their practical deployment is challenging due to their ever increasing computational and memory demands. Quantization is one of the most effective ways to make them more compute and memory efficient. Quantization-aware training (QAT) methods, generally produce the best quantized performance, however it comes at the cost of potentially long training time and excessive memory usage, making it impractical when applying for LLMs. Inspired by parameter-efficient fine-tuning (PEFT) and low-rank adaptation (LoRA) literature, we propose LR-QAT -- a lightweight and memory-efficient QAT algorithm for LLMs. LR-QAT employs several components to save memory without sacrificing predictive performance: (a) low-rank auxiliary weights that are aware of the quantization grid; (b) a downcasting operator using fixed-point or double-packed integers and (c) checkpointing. Unlike most related work, our method (i) is inference-efficient, leading to no additional overhead compared to traditional PTQ; (ii) can be seen as a general extended pretraining framework, meaning that the resulting model can still be utilized for any downstream task afterwards; (iii) can be applied across a wide range of quantization settings, such as different choices quantization granularity, activation quantization, and seamlessly combined with many PTQ techniques. We apply LR-QAT to the LLaMA-2/3 and Mistral model families and validate its effectiveness on several downstream tasks. Our method outperforms common post-training quantization (PTQ) approaches and reaches the same model performance as full-model QAT at the fraction of its memory usage. Specifically, we can train a 7B LLM on a single consumer grade GPU with 24GB of memory.",
    "authors": [
      "Yelysei Bondarenko",
      "Riccardo Del Chiaro",
      "Markus Nagel"
    ],
    "url": "http://arxiv.org/abs/2406.06385v1",
    "timestamp": 1718034262,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "e9062e7c-eb7e-46eb-bd24-1b574cbf4e61": {
    "pk": "e9062e7c-eb7e-46eb-bd24-1b574cbf4e61",
    "title": "Generalizing to Unseen Domains in Diabetic Retinopathy with Disentangled Representations",
    "abstract": "Diabetic Retinopathy (DR), induced by diabetes, poses a significant risk of visual impairment. Accurate and effective grading of DR aids in the treatment of this condition. Yet existing models experience notable performance degradation on unseen domains due to domain shifts. Previous methods address this issue by simulating domain style through simple visual transformation and mitigating domain noise via learning robust representations. However, domain shifts encompass more than image styles. They overlook biases caused by implicit factors such as ethnicity, age, and diagnostic criteria. In our work, we propose a novel framework where representations of paired data from different domains are decoupled into semantic features and domain noise. The resulting augmented representation comprises original retinal semantics and domain noise from other domains, aiming to generate enhanced representations aligned with real-world clinical needs, incorporating rich information from diverse domains. Subsequently, to improve the robustness of the decoupled representations, class and domain prototypes are employed to interpolate the disentangled representations while data-aware weights are designed to focus on rare classes and domains. Finally, we devise a robust pixel-level semantic alignment loss to align retinal semantics decoupled from features, maintaining a balance between intra-class diversity and dense class features. Experimental results on multiple benchmarks demonstrate the effectiveness of our method on unseen domains. The code implementations are accessible on https://github.com/richard-peng-xia/DECO.",
    "authors": [
      "Peng Xia",
      "Ming Hu",
      "Feilong Tang",
      "Wenxue Li",
      "Wenhao Zheng",
      "Lie Ju",
      "Peibo Duan",
      "Huaxiu Yao",
      "Zongyuan Ge"
    ],
    "url": "http://arxiv.org/abs/2406.06384v1",
    "timestamp": 1718034236,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "90473736-f6c8-4a22-ab56-cba1b43d0a61": {
    "pk": "90473736-f6c8-4a22-ab56-cba1b43d0a61",
    "title": "Diffusion-RPO: Aligning Diffusion Models through Relative Preference Optimization",
    "abstract": "Aligning large language models with human preferences has emerged as a critical focus in language modeling research. Yet, integrating preference learning into Text-to-Image (T2I) generative models is still relatively uncharted territory. The Diffusion-DPO technique made initial strides by employing pairwise preference learning in diffusion models tailored for specific text prompts. We introduce Diffusion-RPO, a new method designed to align diffusion-based T2I models with human preferences more effectively. This approach leverages both prompt-image pairs with identical prompts and those with semantically related content across various modalities. Furthermore, we have developed a new evaluation metric, style alignment, aimed at overcoming the challenges of high costs, low reproducibility, and limited interpretability prevalent in current evaluations of human preference alignment. Our findings demonstrate that Diffusion-RPO outperforms established methods such as Supervised Fine-Tuning and Diffusion-DPO in tuning Stable Diffusion versions 1.5 and XL-1.0, achieving superior results in both automated evaluations of human preferences and style alignment. Our code is available at https://github.com/yigu1008/Diffusion-RPO",
    "authors": [
      "Yi Gu",
      "Zhendong Wang",
      "Yueqin Yin",
      "Yujia Xie",
      "Mingyuan Zhou"
    ],
    "url": "http://arxiv.org/abs/2406.06382v1",
    "timestamp": 1718034123,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "8d2a67dd-34ed-4802-bed0-7cc432256dcc": {
    "pk": "8d2a67dd-34ed-4802-bed0-7cc432256dcc",
    "title": "FinVerse: An Autonomous Agent System for Versatile Financial Analysis",
    "abstract": "With the significant advancements in cognitive intelligence driven by LLMs, autonomous agent systems have attracted extensive attention. Despite this growing interest, the development of stable and efficient agent systems poses substantial practical challenges. In this paper, we introduce FinVerse, a meticulously crafted agent system designed for a broad range of financial topics. FinVerse integrates over 600 financial APIs, enabling access to more accurate and extensive financial information compared to generalist agents. To enhance financial information processing capabilities, FinVerse is equipped with an embedded code interpreter, enabling the execution of complex data analysis tasks with precision and efficiency. Our work includes an empirical comparison of several LLMs in driving FinVerse. Specifically, we propose our own scheme for training LLMs using SFT to optimize LLM performance within FinVerse. Recognizing the scarcity of specialized datasets to build LLMs for agents, we have constructed a dataset and plan to make it open-source, providing a valuable resource for peer application developers. The demo video has been released on YouTube at https://www.youtube.com/watch?v=sk8L9_Wv7J4",
    "authors": [
      "Siyu An",
      "Qin Li",
      "Junru Lu",
      "Di Yin",
      "Xing Sun"
    ],
    "url": "http://arxiv.org/abs/2406.06379v1",
    "timestamp": 1718034023,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CE",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "55efae1f-d7c2-4456-a6d5-d55497d928b7": {
    "pk": "55efae1f-d7c2-4456-a6d5-d55497d928b7",
    "title": "Multicam-SLAM: Non-overlapping Multi-camera SLAM for Indirect Visual Localization and Navigation",
    "abstract": "This paper presents a novel approach to visual simultaneous localization and mapping (SLAM) using multiple RGB-D cameras. The proposed method, Multicam-SLAM, significantly enhances the robustness and accuracy of SLAM systems by capturing more comprehensive spatial information from various perspectives. This method enables the accurate determination of pose relationships among multiple cameras without the need for overlapping fields of view. The proposed Muticam-SLAM includes a unique multi-camera model, a multi-keyframes structure, and several parallel SLAM threads. The multi-camera model allows for the integration of data from multiple cameras, while the multi-keyframes and parallel SLAM threads ensure efficient and accurate pose estimation and mapping. Extensive experiments in various environments demonstrate the superior accuracy and robustness of the proposed method compared to conventional single-camera SLAM systems. The results highlight the potential of the proposed Multicam-SLAM for more complex and challenging applications. Code is available at \\url{https://github.com/AlterPang/Multi_ORB_SLAM}.",
    "authors": [
      "Shenghao Li",
      "Luchao Pang",
      "Xianglong Hu"
    ],
    "url": "http://arxiv.org/abs/2406.06374v1",
    "timestamp": 1718033783,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c73f0793-d0dc-445f-aa4e-c34023675c01": {
    "pk": "c73f0793-d0dc-445f-aa4e-c34023675c01",
    "title": "Improving Deep Learning-based Automatic Cranial Defect Reconstruction by Heavy Data Augmentation: From Image Registration to Latent Diffusion Models",
    "abstract": "Modeling and manufacturing of personalized cranial implants are important research areas that may decrease the waiting time for patients suffering from cranial damage. The modeling of personalized implants may be partially automated by the use of deep learning-based methods. However, this task suffers from difficulties with generalizability into data from previously unseen distributions that make it difficult to use the research outcomes in real clinical settings. Due to difficulties with acquiring ground-truth annotations, different techniques to improve the heterogeneity of datasets used for training the deep networks have to be considered and introduced. In this work, we present a large-scale study of several augmentation techniques, varying from classical geometric transformations, image registration, variational autoencoders, and generative adversarial networks, to the most recent advances in latent diffusion models. We show that the use of heavy data augmentation significantly increases both the quantitative and qualitative outcomes, resulting in an average Dice Score above 0.94 for the SkullBreak and above 0.96 for the SkullFix datasets. Moreover, we show that the synthetically augmented network successfully reconstructs real clinical defects. The work is a considerable contribution to the field of artificial intelligence in the automatic modeling of personalized cranial implants.",
    "authors": [
      "Marek Wodzinski",
      "Kamil Kwarciak",
      "Mateusz Daniol",
      "Daria Hemmerling"
    ],
    "url": "http://arxiv.org/abs/2406.06372v1",
    "timestamp": 1718033663,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "a6bff333-09c2-46e7-9013-e166a7f7c984": {
    "pk": "a6bff333-09c2-46e7-9013-e166a7f7c984",
    "title": "mHuBERT-147: A Compact Multilingual HuBERT Model",
    "abstract": "We present mHuBERT-147, the first general-purpose massively multilingual HuBERT speech representation model trained on 90K hours of clean, open-license data. To scale up the multi-iteration HuBERT approach, we use faiss-based clustering, achieving 5.2x faster label assignment over the original method. We also apply a new multilingual batching up-sampling strategy, leveraging both language and dataset diversity. After 3 training iterations and with only 95M parameters, mHuBERT-147 outperforms larger models trained on substantially more data. We rank second and first on the ML-SUPERB 10min/1h leaderboards respectively, with SOTA scores for all LID tasks. Across ASR/LID tasks, our model consistently surpasses XLS-R (300M params; 436K hours) and demonstrates strong competitiveness against the much larger MMS (1B params; 491K hours). Our findings suggest that mHuBERT-147 is a promising model for multilingual speech processing tasks, offering an unprecedented balance between high performance and parameter efficiency.",
    "authors": [
      "Marcely Zanon Boito",
      "Vivek Iyer",
      "Nikolaos Lagos",
      "Laurent Besacier",
      "Ioan Calapodescu"
    ],
    "url": "http://arxiv.org/abs/2406.06371v1",
    "timestamp": 1718033562,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "911db16c-ca22-4db7-811d-bf822c3616c9": {
    "pk": "911db16c-ca22-4db7-811d-bf822c3616c9",
    "title": "UMAD: Unsupervised Mask-Level Anomaly Detection for Autonomous Driving",
    "abstract": "Dealing with atypical traffic scenarios remains a challenging task in autonomous driving. However, most anomaly detection approaches cannot be trained on raw sensor data but require exposure to outlier data and powerful semantic segmentation models trained in a supervised fashion. This limits the representation of normality to labeled data, which does not scale well. In this work, we revisit unsupervised anomaly detection and present UMAD, leveraging generative world models and unsupervised image segmentation. Our method outperforms state-of-the-art unsupervised anomaly detection.",
    "authors": [
      "Daniel Bogdoll",
      "No\u00ebl Ollick",
      "Tim Joseph",
      "J. Marius Z\u00f6llner"
    ],
    "url": "http://arxiv.org/abs/2406.06370v1",
    "timestamp": 1718033536,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "03372b4b-c5ed-409e-b69b-440304a5fb0c": {
    "pk": "03372b4b-c5ed-409e-b69b-440304a5fb0c",
    "title": "Annotation alignment: Comparing LLM and human annotations of conversational safety",
    "abstract": "To what extent to do LLMs align with human perceptions of safety? We study this question via *annotation alignment*, the extent to which LLMs and humans agree when annotating the safety of user-chatbot conversations. We leverage the recent DICES dataset (Aroyo et al., 2023), in which 350 conversations are each rated for safety by 112 annotators spanning 10 race-gender groups. GPT-4 achieves a Pearson correlation of $r = 0.59$ with the average annotator rating, higher than the median annotator's correlation with the average ($r=0.51$). We show that larger datasets are needed to resolve whether GPT-4 exhibits disparities in how well it correlates with demographic groups. Also, there is substantial idiosyncratic variation in correlation *within* groups, suggesting that race & gender do not fully capture differences in alignment. Finally, we find that GPT-4 cannot predict when one demographic group finds a conversation more unsafe than another.",
    "authors": [
      "Rajiv Movva",
      "Pang Wei Koh",
      "Emma Pierson"
    ],
    "url": "http://arxiv.org/abs/2406.06369v1",
    "timestamp": 1718033413,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "65530866-36c2-4b84-9b22-60095deb55c2": {
    "pk": "65530866-36c2-4b84-9b22-60095deb55c2",
    "title": "MVGamba: Unify 3D Content Generation as State Space Sequence Modeling",
    "abstract": "Recent 3D large reconstruction models (LRMs) can generate high-quality 3D content in sub-seconds by integrating multi-view diffusion models with scalable multi-view reconstructors. Current works further leverage 3D Gaussian Splatting as 3D representation for improved visual quality and rendering efficiency. However, we observe that existing Gaussian reconstruction models often suffer from multi-view inconsistency and blurred textures. We attribute this to the compromise of multi-view information propagation in favor of adopting powerful yet computationally intensive architectures (\\eg, Transformers). To address this issue, we introduce MVGamba, a general and lightweight Gaussian reconstruction model featuring a multi-view Gaussian reconstructor based on the RNN-like State Space Model (SSM). Our Gaussian reconstructor propagates causal context containing multi-view information for cross-view self-refinement while generating a long sequence of Gaussians for fine-detail modeling with linear complexity. With off-the-shelf multi-view diffusion models integrated, MVGamba unifies 3D generation tasks from a single image, sparse images, or text prompts. Extensive experiments demonstrate that MVGamba outperforms state-of-the-art baselines in all 3D content generation scenarios with approximately only $0.1\\times$ of the model size.",
    "authors": [
      "Xuanyu Yi",
      "Zike Wu",
      "Qiuhong Shen",
      "Qingshan Xu",
      "Pan Zhou",
      "Joo-Hwee Lim",
      "Shuicheng Yan",
      "Xinchao Wang",
      "Hanwang Zhang"
    ],
    "url": "http://arxiv.org/abs/2406.06367v1",
    "timestamp": 1718033208,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "a07abf16-f330-4e64-abb4-f4e3a823c3c7": {
    "pk": "a07abf16-f330-4e64-abb4-f4e3a823c3c7",
    "title": "Symmetric Dot-Product Attention for Efficient Training of BERT Language Models",
    "abstract": "Initially introduced as a machine translation model, the Transformer architecture has now become the foundation for modern deep learning architecture, with applications in a wide range of fields, from computer vision to natural language processing. Nowadays, to tackle increasingly more complex tasks, Transformer-based models are stretched to enormous sizes, requiring increasingly larger training datasets, and unsustainable amount of compute resources. The ubiquitous nature of the Transformer and its core component, the attention mechanism, are thus prime targets for efficiency research. In this work, we propose an alternative compatibility function for the self-attention mechanism introduced by the Transformer architecture. This compatibility function exploits an overlap in the learned representation of the traditional scaled dot-product attention, leading to a symmetric with pairwise coefficient dot-product attention. When applied to the pre-training of BERT-like models, this new symmetric attention mechanism reaches a score of 79.36 on the GLUE benchmark against 78.74 for the traditional implementation, leads to a reduction of 6% in the number of trainable parameters, and reduces the number of training steps required before convergence by half.",
    "authors": [
      "Martin Courtois",
      "Malte Ostendorff",
      "Leonhard Hennig",
      "Georg Rehm"
    ],
    "url": "http://arxiv.org/abs/2406.06366v1",
    "timestamp": 1718033055,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "cd7b35de-39f8-4de3-a190-acf703477b20": {
    "pk": "cd7b35de-39f8-4de3-a190-acf703477b20",
    "title": "Automating Food Drop: The Power of Two Choices for Dynamic and Fair Food Allocation",
    "abstract": "Food waste and food insecurity are two closely related pressing global issues. Food rescue organizations worldwide run programs aimed at addressing the two problems. In this paper, we partner with a non-profit organization in the state of Indiana that leads \\emph{Food Drop}, a program that is designed to redirect rejected truckloads of food away from landfills and into food banks. The truckload to food bank matching decisions are currently made by an employee of our partner organization. In addition to this being a very time-consuming task, as perhaps expected from human-based matching decisions, the allocations are often skewed: a small percentage of the possible recipients receives the majority of donations. Our goal in this partnership is to completely automate Food Drop. In doing so, we need a matching algorithm for making real-time decisions that strikes a balance between ensuring fairness for the food banks that receive the food and optimizing efficiency for the truck drivers. In this paper, we describe the theoretical guarantees and experiments that dictated our choice of algorithm in the platform we built and deployed for our partner organization. Our work also makes contributions to the literature on load balancing and balls-into-bins games, that might be of independent interest. Specifically, we study the allocation of $m$ weighted balls into $n$ weighted bins, where each ball has two non-uniformly sampled random bin choices, and prove upper bounds, that hold with high probability, on the maximum load of any bin.",
    "authors": [
      "Marios Mertzanidis",
      "Alexandros Psomas",
      "Paritosh Verma"
    ],
    "url": "http://arxiv.org/abs/2406.06363v1",
    "timestamp": 1718032961,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.GT",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f2769281-1a8b-487d-a8cd-13c48cf590a9": {
    "pk": "f2769281-1a8b-487d-a8cd-13c48cf590a9",
    "title": "Challenges with Differentiable Quantum Dynamics",
    "abstract": "Differentiable quantum dynamics require automatic differentiation of a complex-valued initial value problem, which numerically integrates a system of ordinary differential equations from a specified initial condition, as well as the eigendecomposition of a matrix. We explored several automatic differentiation frameworks for these tasks, finding that no framework natively supports our application requirements. We therefore demonstrate a need for broader support of complex-valued, differentiable numerical integration in scientific computing libraries.",
    "authors": [
      "Sri Hari Krisha Narayanan",
      "Michael Perlin",
      "Robert Lewis-Swan",
      "Jeffrey Larson",
      "Matt Menickelly",
      "Jan H\u00fcckelheim",
      "Paul Hovland"
    ],
    "url": "http://arxiv.org/abs/2406.06361v1",
    "timestamp": 1718032890,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c3013a14-dda9-4ecd-9821-70286ea23ba3": {
    "pk": "c3013a14-dda9-4ecd-9821-70286ea23ba3",
    "title": "MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows",
    "abstract": "Scientific innovation relies on detailed workflows, which include critical steps such as analyzing literature, generating ideas, validating these ideas, interpreting results, and inspiring follow-up research. However, scientific publications that document these workflows are extensive and unstructured. This makes it difficult for both human researchers and AI systems to effectively navigate and explore the space of scientific innovation. To address this issue, we introduce MASSW, a comprehensive text dataset on Multi-Aspect Summarization of Scientific Workflows. MASSW includes more than 152,000 peer-reviewed publications from 17 leading computer science conferences spanning the past 50 years. Using Large Language Models (LLMs), we automatically extract five core aspects from these publications -- context, key idea, method, outcome, and projected impact -- which correspond to five key steps in the research workflow. These structured summaries facilitate a variety of downstream tasks and analyses. The quality of the LLM-extracted summaries is validated by comparing them with human annotations. We demonstrate the utility of MASSW through multiple novel machine-learning tasks that can be benchmarked using this new dataset, which make various types of predictions and recommendations along the scientific workflow. MASSW holds significant potential for researchers to create and benchmark new AI methods for optimizing scientific workflows and fostering scientific innovation in the field. Our dataset is openly available at \\url{https://github.com/xingjian-zhang/massw}.",
    "authors": [
      "Xingjian Zhang",
      "Yutong Xie",
      "Jin Huang",
      "Jinge Ma",
      "Zhaoying Pan",
      "Qijia Liu",
      "Ziyang Xiong",
      "Tolga Ergen",
      "Dongsub Shim",
      "Honglak Lee",
      "Qiaozhu Mei"
    ],
    "url": "http://arxiv.org/abs/2406.06357v1",
    "timestamp": 1718032749,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "6eb77d0d-178b-4b11-bcf7-8b651bede606": {
    "pk": "6eb77d0d-178b-4b11-bcf7-8b651bede606",
    "title": "Sustained Vowels for Pre- vs Post-Treatment COPD Classification",
    "abstract": "Chronic obstructive pulmonary disease (COPD) is a serious inflammatory lung disease affecting millions of people around the world. Due to an obstructed airflow from the lungs, it also becomes manifest in patients' vocal behaviour. Of particular importance is the detection of an exacerbation episode, which marks an acute phase and often requires hospitalisation and treatment. Previous work has shown that it is possible to distinguish between a pre- and a post-treatment state using automatic analysis of read speech. In this contribution, we examine whether sustained vowels can provide a complementary lens for telling apart these two states. Using a cohort of 50 patients, we show that the inclusion of sustained vowels can improve performance to up to 79\\% unweighted average recall, from a 71\\% baseline using read speech. We further identify and interpret the most important acoustic features that characterise the manifestation of COPD in sustained vowels.",
    "authors": [
      "Andreas Triantafyllopoulos",
      "Anton Batliner",
      "Wolfgang Mayr",
      "Markus Fendler",
      "Florian Pokorny",
      "Maurice Gerczuk",
      "Shahin Amiriparian",
      "Thomas Berghaus",
      "Bj\u00f6rn Schuller"
    ],
    "url": "http://arxiv.org/abs/2406.06355v1",
    "timestamp": 1718032637,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "fefefb8f-3de8-4436-bd62-baa8ba8e3649": {
    "pk": "fefefb8f-3de8-4436-bd62-baa8ba8e3649",
    "title": "Latent Directions: A Simple Pathway to Bias Mitigation in Generative AI",
    "abstract": "Mitigating biases in generative AI and, particularly in text-to-image models, is of high importance given their growing implications in society. The biased datasets used for training pose challenges in ensuring the responsible development of these models, and mitigation through hard prompting or embedding alteration, are the most common present solutions. Our work introduces a novel approach to achieve diverse and inclusive synthetic images by learning a direction in the latent space and solely modifying the initial Gaussian noise provided for the diffusion process. Maintaining a neutral prompt and untouched embeddings, this approach successfully adapts to diverse debiasing scenarios, such as geographical biases. Moreover, our work proves it is possible to linearly combine these learned latent directions to introduce new mitigations, and if desired, integrate it with text embedding adjustments. Furthermore, text-to-image models lack transparency for assessing bias in outputs, unless visually inspected. Thus, we provide a tool to empower developers to select their desired concepts to mitigate. The project page with code is available online.",
    "authors": [
      "Carolina Lopez Olmos",
      "Alexandros Neophytou",
      "Sunando Sengupta",
      "Dim P. Papadopoulos"
    ],
    "url": "http://arxiv.org/abs/2406.06352v1",
    "timestamp": 1718032431,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "26342916-7186-4827-98d0-ce4149550696": {
    "pk": "26342916-7186-4827-98d0-ce4149550696",
    "title": "Cascading Unknown Detection with Known Classification for Open Set Recognition",
    "abstract": "Deep learners tend to perform well when trained under the closed set assumption but struggle when deployed under open set conditions. This motivates the field of Open Set Recognition in which we seek to give deep learners the ability to recognize whether a data sample belongs to the known classes trained on or comes from the surrounding infinite world. Existing open set recognition methods typically rely upon a single function for the dual task of distinguishing between knowns and unknowns as well as making known class distinction. This dual process leaves performance on the table as the function is not specialized for either task. In this work, we introduce Cascading Unknown Detection with Known Classification (Cas-DC), where we instead learn specialized functions in a cascading fashion for both known/unknown detection and fine class classification amongst the world of knowns. Our experiments and analysis demonstrate that Cas-DC handily outperforms modern methods in open set recognition when compared using AUROC scores and correct classification rate at various true positive rates.",
    "authors": [
      "Daniel Brignac",
      "Abhijit Mahalanobis"
    ],
    "url": "http://arxiv.org/abs/2406.06351v1",
    "timestamp": 1718032387,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "194d40ce-7ee2-48b1-bf53-87864412cfcc": {
    "pk": "194d40ce-7ee2-48b1-bf53-87864412cfcc",
    "title": "Error Analysis and Numerical Algorithm for PDE Approximation with Hidden-Layer Concatenated Physics Informed Neural Networks",
    "abstract": "We present the hidden-layer concatenated physics informed neural network (HLConcPINN) method, which combines hidden-layer concatenated feed-forward neural networks, a modified block time marching strategy, and a physics informed approach for approximating partial differential equations (PDEs). We analyze the convergence properties and establish the error bounds of this method for two types of PDEs: parabolic (exemplified by the heat and Burgers' equations) and hyperbolic (exemplified by the wave and nonlinear Klein-Gordon equations). We show that its approximation error of the solution can be effectively controlled by the training loss for dynamic simulations with long time horizons. The HLConcPINN method in principle allows an arbitrary number of hidden layers not smaller than two and any of the commonly-used smooth activation functions for the hidden layers beyond the first two, with theoretical guarantees. This generalizes several recent neural-network techniques, which have theoretical guarantees but are confined to two hidden layers in the network architecture and the $\\tanh$ activation function. Our theoretical analyses subsequently inform the formulation of appropriate training loss functions for these PDEs, leading to physics informed neural network (PINN) type computational algorithms that differ from the standard PINN formulation. Ample numerical experiments are presented based on the proposed algorithm to validate the effectiveness of this method and confirm aspects of the theoretical analyses.",
    "authors": [
      "Yianxia Qian",
      "Yongchao Zhang",
      "Suchuan Dong"
    ],
    "url": "http://arxiv.org/abs/2406.06350v1",
    "timestamp": 1718032373,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.NA",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "921d139f-80b1-4d63-ba45-fd93f6cc3693": {
    "pk": "921d139f-80b1-4d63-ba45-fd93f6cc3693",
    "title": "Causal Discovery over High-Dimensional Structured Hypothesis Spaces with Causal Graph Partitioning",
    "abstract": "The aim in many sciences is to understand the mechanisms that underlie the observed distribution of variables, starting from a set of initial hypotheses. Causal discovery allows us to infer mechanisms as sets of cause and effect relationships in a generalized way -- without necessarily tailoring to a specific domain. Causal discovery algorithms search over a structured hypothesis space, defined by the set of directed acyclic graphs, to find the graph that best explains the data. For high-dimensional problems, however, this search becomes intractable and scalable algorithms for causal discovery are needed to bridge the gap. In this paper, we define a novel causal graph partition that allows for divide-and-conquer causal discovery with theoretical guarantees. We leverage the idea of a superstructure -- a set of learned or existing candidate hypotheses -- to partition the search space. We prove under certain assumptions that learning with a causal graph partition always yields the Markov Equivalence Class of the true causal graph. We show our algorithm achieves comparable accuracy and a faster time to solution for biologically-tuned synthetic networks and networks up to ${10^4}$ variables. This makes our method applicable to gene regulatory network inference and other domains with high-dimensional structured hypothesis spaces.",
    "authors": [
      "Ashka Shah",
      "Adela DePavia",
      "Nathaniel Hudson",
      "Ian Foster",
      "Rick Stevens"
    ],
    "url": "http://arxiv.org/abs/2406.06348v1",
    "timestamp": 1718032094,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "2677c99b-8a6a-4600-8125-5078dd2a7fde": {
    "pk": "2677c99b-8a6a-4600-8125-5078dd2a7fde",
    "title": "Parametric kernel low-rank approximations using tensor train decomposition",
    "abstract": "Computing low-rank approximations of kernel matrices is an important problem with many applications in scientific computing and data science. We propose methods to efficiently approximate and store low-rank approximations to kernel matrices that depend on certain hyperparameters. The main idea behind our method is to use multivariate Chebyshev function approximation along with the tensor train decomposition of the coefficient tensor. The computations are in two stages: an offline stage, which dominates the computational cost and is parameter-independent, and an online stage, which is inexpensive and instantiated for specific hyperparameters. A variation of this method addresses the case that the kernel matrix is symmetric and positive semi-definite. The resulting algorithms have linear complexity in terms of the sizes of the kernel matrices. We investigate the efficiency and accuracy of our method on parametric kernel matrices induced by various kernels, such as the Mat\\'ern kernel, through various numerical experiments. Our methods have speedups up to $200\\times$ in the online time compared to other methods with similar complexity and comparable accuracy.",
    "authors": [
      "Abraham Khan",
      "Arvind K. Saibaba"
    ],
    "url": "http://arxiv.org/abs/2406.06344v1",
    "timestamp": 1718031799,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.NA",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "ce352144-2892-46c0-b43e-828b45a271ad": {
    "pk": "ce352144-2892-46c0-b43e-828b45a271ad",
    "title": "A Guide to Stochastic Optimisation for Large-Scale Inverse Problems",
    "abstract": "Stochastic optimisation algorithms are the de facto standard for machine learning with large amounts of data. Handling only a subset of available data in each optimisation step dramatically reduces the per-iteration computational costs, while still ensuring significant progress towards the solution. Driven by the need to solve large-scale optimisation problems as efficiently as possible, the last decade has witnessed an explosion of research in this area. Leveraging the parallels between machine learning and inverse problems has allowed harnessing the power of this research wave for solving inverse problems. In this survey, we provide a comprehensive account of the state-of-the-art in stochastic optimisation from the viewpoint of inverse problems. We present algorithms with diverse modalities of problem randomisation and discuss the roles of variance reduction, acceleration, higher-order methods, and other algorithmic modifications, and compare theoretical results with practical behaviour. We focus on the potential and the challenges for stochastic optimisation that are unique to inverse imaging problems and are not commonly encountered in machine learning. We conclude the survey with illustrative examples from imaging problems to examine the advantages and disadvantages that this new generation of algorithms bring to the field of inverse problems.",
    "authors": [
      "Matthias J. Ehrhardt",
      "Zeljko Kereta",
      "Jingwei Liang",
      "Junqi Tang"
    ],
    "url": "http://arxiv.org/abs/2406.06342v1",
    "timestamp": 1718031750,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.NA",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "18781892-5723-416f-b46e-3c53efac0f30": {
    "pk": "18781892-5723-416f-b46e-3c53efac0f30",
    "title": "Propagation in rough waveguides: Forward and inverse problems",
    "abstract": "We discuss here the direct and inverse problems for wave propagation in a waveguide with rough internal surface and arbitrary mean shape. The high degree of multiple scattering inside the waveguide poses significant challenges both for the forward computation and for the recovery of the surface profile, and raises important questions about scattering cross-sections. This paper falls into two parts corresponding to these issues.   We first apply Left-Right (L-R) operator splitting to calculate the scattered fields in 2- and 3-dimensional waveguides. Using this we illustrate the scattered fields and the effect of surface roughness. In the second part we formulate an algorithm for surface recovery from field measurements along the waveguide axis, which generalises recent work on surfaces in 2 dimensions. This method utilizes forward scattering assumptions in effect by formulating an integral equation in the unknown surface field, treated as a function of the surface. Although discussed in the context of waveguides, the formulae are given in a form applicable to a variety of geometries, with coefficients which will depend on and be determined by each specific application.",
    "authors": [
      "Mark Spivack",
      "Orsola Rath Spivack"
    ],
    "url": "http://arxiv.org/abs/2406.06336v1",
    "timestamp": 1718031272,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "physics.comp-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "cf36735a-3d39-43c0-bbcd-2179e5d55d46": {
    "pk": "cf36735a-3d39-43c0-bbcd-2179e5d55d46",
    "title": "Feasibility of accelerating homogeneous catalyst discovery with fault-tolerant quantum computers",
    "abstract": "The industrial manufacturing of chemicals consumes a significant amount of energy and raw materials. In principle, the development of new catalysts could greatly improve the efficiency of chemical production. However, the discovery of viable catalysts can be exceedingly challenging because it is difficult to know the efficacy of a candidate without experimentally synthesizing and characterizing it. This study explores the feasibility of using fault-tolerant quantum computers to accelerate the discovery of homogeneous catalysts for nitrogen fixation, an industrially important chemical process. It introduces a set of ground-state energy estimation problems representative of calculations needed for the discovery of homogeneous catalysts and analyzes them on three dimensions: economic utility, classical hardness, and quantum resource requirements. For the highest utility problem considered, two steps of a catalytic cycle for the generation of cyanate anion from dinitrogen, the economic utility of running these computations is estimated to be $200,000, and the required runtime for double-factorized phase estimation on a fault-tolerant superconducting device is estimated under conservative assumptions to be 139,000 QPU-hours. The computational cost of an equivalent DMRG calculation is estimated to be about 400,000 CPU-hours. These results suggest that, with continued development, it will be feasible for fault-tolerant quantum computers to accelerate the discovery of homogeneous catalysts.",
    "authors": [
      "Nicole Bellonzi",
      "Alexander Kunitsa",
      "Joshua T. Cantin",
      "Jorge A. Campos-Gonzalez-Angulo",
      "Maxwell D. Radin",
      "Yanbing Zhou",
      "Peter D. Johnson",
      "Luis A. Mart\u00ednez-Mart\u00ednez",
      "Mohammad Reza Jangrouei",
      "Aritra Sankar Brahmachari",
      "Linjun Wang",
      "Smik Patel",
      "Monika Kodrycka",
      "Ignacio Loaiza",
      "Robert A. Lang",
      "Al\u00e1n Aspuru-Guzik",
      "Artur F. Izmaylov",
      "Jhonathan Romero Fontalvo",
      "Yudong Cao"
    ],
    "url": "http://arxiv.org/abs/2406.06335v1",
    "timestamp": 1718031140,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "65bff0dc-7bdd-48ca-bfe1-b961cdf5802b": {
    "pk": "65bff0dc-7bdd-48ca-bfe1-b961cdf5802b",
    "title": "An automatic analysis of ultrasound vocalisations for the prediction of interaction context in captive Egyptian fruit bats",
    "abstract": "Prior work in computational bioacoustics has mostly focused on the detection of animal presence in a particular habitat. However, animal sounds contain much richer information than mere presence; among others, they encapsulate the interactions of those animals with other members of their species. Studying these interactions is almost impossible in a naturalistic setting, as the ground truth is often lacking. The use of animals in captivity instead offers a viable alternative pathway. However, most prior works follow a traditional, statistics-based approach to analysing interactions. In the present work, we go beyond this standard framework by attempting to predict the underlying context in interactions between captive \\emph{Rousettus Aegyptiacus} using deep neural networks. We reach an unweighted average recall of over 30\\% -- more than thrice the chance level -- and show error patterns that differ from our statistical analysis. This work thus represents an important step towards the automatic analysis of states in animals from sound.",
    "authors": [
      "Andreas Triantafyllopoulos",
      "Alexander Gebhard",
      "Manuel Milling",
      "Simon Rampp",
      "Bj\u00f6rn Schuller"
    ],
    "url": "http://arxiv.org/abs/2406.06332v1",
    "timestamp": 1718031032,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.SD",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c7181cc7-54b0-413a-b391-5c258fc1cf2e": {
    "pk": "c7181cc7-54b0-413a-b391-5c258fc1cf2e",
    "title": "MedExQA: Medical Question Answering Benchmark with Multiple Explanations",
    "abstract": "This paper introduces MedExQA, a novel benchmark in medical question-answering, to evaluate large language models' (LLMs) understanding of medical knowledge through explanations. By constructing datasets across five distinct medical specialties that are underrepresented in current datasets and further incorporating multiple explanations for each question-answer pair, we address a major gap in current medical QA benchmarks which is the absence of comprehensive assessments of LLMs' ability to generate nuanced medical explanations. Our work highlights the importance of explainability in medical LLMs, proposes an effective methodology for evaluating models beyond classification accuracy, and sheds light on one specific domain, speech language pathology, where current LLMs including GPT4 lack good understanding. Our results show generation evaluation with multiple explanations aligns better with human assessment, highlighting an opportunity for a more robust automated comprehension assessment for LLMs. To diversify open-source medical LLMs (currently mostly based on Llama2), this work also proposes a new medical model, MedPhi-2, based on Phi-2 (2.7B). The model outperformed medical LLMs based on Llama2-70B in generating explanations, showing its effectiveness in the resource-constrained medical domain. We will share our benchmark datasets and the trained model.",
    "authors": [
      "Yunsoo Kim",
      "Jinge Wu",
      "Yusuf Abdulle",
      "Honghan Wu"
    ],
    "url": "http://arxiv.org/abs/2406.06331v1",
    "timestamp": 1718030824,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "e5aa5f9e-8149-452a-9d03-635592db11f3": {
    "pk": "e5aa5f9e-8149-452a-9d03-635592db11f3",
    "title": "A Parameter-efficient Language Extension Framework for Multilingual ASR",
    "abstract": "Covering all languages with a multilingual speech recognition model (MASR) is very difficult. Performing language extension on top of an existing MASR is a desirable choice. In this study, the MASR continual learning problem is probabilistically decomposed into language identity prediction (LP) and cross-lingual adaptation (XLA) sub-problems. Based on this, we propose an architecture-based framework for language extension that can fundamentally solve catastrophic forgetting, debudded as PELE. PELE is designed to be parameter-efficient, incrementally incorporating an add-on module to adapt to a new language. Specifically, different parameter-efficient fine-tuning (PEFT) modules and their variants are explored as potential candidates to perform XLA. Experiments are carried out on 5 new languages with a wide range of low-resourced data sizes. The best-performing PEFT candidate can achieve satisfactory performance across all languages and demonstrates superiority in three of five languages over the continual joint learning setting. Notably, PEFT methods focusing on weight parameters or input features are revealed to be limited in performance, showing significantly inferior extension capabilities compared to inserting a lightweight module in between layers such as an Adapter.",
    "authors": [
      "Wei Liu",
      "Jingyong Hou",
      "Dong Yang",
      "Muyong Cao",
      "Tan Lee"
    ],
    "url": "http://arxiv.org/abs/2406.06329v1",
    "timestamp": 1718030767,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "1f648f86-231a-4462-9360-3424e8aff91b": {
    "pk": "1f648f86-231a-4462-9360-3424e8aff91b",
    "title": "Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching",
    "abstract": "Large language models (LLMs) often struggle to provide up-to-date information due to their one-time training and the constantly evolving nature of the world. To keep LLMs current, existing approaches typically involve continued pre-training on new documents. However, they frequently face difficulties in extracting stored knowledge. Motivated by the remarkable success of the Feynman Technique in efficient human learning, we introduce Self-Tuning, a learning framework aimed at improving an LLM's ability to effectively acquire new knowledge from raw documents through self-teaching. Specifically, we develop a Self-Teaching strategy that augments the documents with a set of knowledge-intensive tasks created in a self-supervised manner, focusing on three crucial aspects: memorization, comprehension, and self-reflection. Additionally, we introduce three Wiki-Newpages-2023-QA datasets to facilitate an in-depth analysis of an LLM's knowledge acquisition ability concerning memorization, extraction, and reasoning. Extensive experimental results on Llama2 family models reveal that Self-Tuning consistently exhibits superior performance across all knowledge acquisition tasks and excels in preserving previous knowledge.",
    "authors": [
      "Xiaoying Zhang",
      "Baolin Peng",
      "Ye Tian",
      "Jingyan Zhou",
      "Yipeng Zhang",
      "Haitao Mi",
      "Helen Meng"
    ],
    "url": "http://arxiv.org/abs/2406.06326v1",
    "timestamp": 1718030540,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "8b0026f7-e526-4551-a444-aed730d8786e": {
    "pk": "8b0026f7-e526-4551-a444-aed730d8786e",
    "title": "Feasibility of accelerating incompressible computational fluid dynamics simulations with fault-tolerant quantum computers",
    "abstract": "Across industries, traditional design and engineering workflows are being upgraded to simulation-driven processes. Many workflows include computational fluid dynamics (CFD). Simulations of turbulent flow are notorious for high compute costs and reliance on approximate methods that compromise accuracy. Improvements in the speed and accuracy of CFD calculations would potentially reduce design workflow costs by reducing computational costs and eliminating the need for experimental testing. This study explores the feasibility of using fault-tolerant quantum computers to improve the speed and accuracy of CFD simulations in the incompressible or weakly compressible regime. For the example of simulation-driven ship design, we consider simulations for calculating the drag force in steady-state flows, and provide analysis on economic utility and classical hardness. As a waypoint toward assessing the feasibility of our chosen quantum approach, we estimate the quantum resources required for the simpler case of drag force on a sphere. We estimate the product of logical qubits $\\times$ $T$ gates to range from $10^{22}$ to $10^{28}$. These high initial estimates suggest that future quantum computers are unlikely to provide utility for incompressible CFD applications unless significant algorithmic advancements or alternative quantum approaches are developed. Encouraged by applications in quantum chemistry that have realized orders-of-magnitude improvements as they matured, we identify the most promising next steps for quantum resource reduction as we work to scale up our estimates from spheres to utility-scale problems with more complex geometry.",
    "authors": [
      "John Penuel",
      "Amara Katabarwa",
      "Peter D. Johnson",
      "Collin Farquhar",
      "Yudong Cao",
      "Michael C. Garrett"
    ],
    "url": "http://arxiv.org/abs/2406.06323v1",
    "timestamp": 1718030326,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "ea77b13b-73b5-476f-b271-7a7958041d75": {
    "pk": "ea77b13b-73b5-476f-b271-7a7958041d75",
    "title": "Optimal Preprocessing for Answering On-Line Product Queries",
    "abstract": "We examine the amount of preprocessing needed for answering certain on-line queries as fast as possible. We start with the following basic problem. Suppose we are given a semigroup $(S,\\circ )$. Let $s_1 ,\\ldots, s_n$ be elements of $S$. We want to answer on-line queries of the form, ``What is the product $s_i \\circ s_{i+1} \\circ \\cdots \\circ s_{j-1} \\circ s_j$?'' for any given $1\\le i\\le j\\le n$. We show that a preprocessing of $\\Theta(n \\lambda (k,n))$ time and space is both necessary and sufficient to answer each such query in at most $k$ steps, for any fixed $k$. The function $\\lambda (k,\\cdot)$ is the inverse of a certain function at the $\\lfloor {k/2}\\rfloor$-th level of the primitive recursive hierarchy. In case linear preprocessing is desired, we show that one can answer each such query in $O( \\alpha (n))$ steps and that this is best possible. The function $\\alpha (n)$ is the inverse Ackermann function.   We also consider the following extended problem. Let $T$ be a tree with an element of $S$ associated with each of its vertices. We want to answer on-line queries of the form, ``What is the product of the elements associated with the vertices along the path from $u$ to $v$?'' for any pair of vertices $u$ and $v$ in $T$. We derive results that are similar to the above, for the preprocessing needed for answering such queries.   All our sequential preprocessing algorithms can be parallelized efficiently to give optimal parallel algorithms which run in $O(\\log n)$ time on a CREW PRAM. These parallel algorithms are optimal in both running time and total number of operations.   Our algorithms, especially for the semigroup of the real numbers with the minimum or maximum operations, have various applications in certain graph algorithms, in the utilization of communication networks and in Database retrieval.",
    "authors": [
      "Noga Alon",
      "Baruch Schieber"
    ],
    "url": "http://arxiv.org/abs/2406.06321v1",
    "timestamp": 1718030218,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.DS",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b0d0d0c4-a70c-4e5d-91a1-d2451323d30e": {
    "pk": "b0d0d0c4-a70c-4e5d-91a1-d2451323d30e",
    "title": "Vehicle Vectors and Traffic Patterns from Planet Imagery",
    "abstract": "We explore methods to detect automobiles in Planet imagery and build a large scale vector field for moving objects. Planet operates two distinct constellations: high-resolution SkySat satellites as well as medium-resolution SuperDove satellites. We show that both static and moving cars can be identified reliably in high-resolution SkySat imagery. We are able to estimate the speed and heading of moving vehicles by leveraging the inter-band displacement (or \"rainbow\" effect) of moving objects. Identifying cars and trucks in medium-resolution SuperDove imagery is far more difficult, though a similar rainbow effect is observed in these satellites and enables moving vehicles to be detected and vectorized. The frequent revisit of Planet satellites enables the categorization of automobile and truck activity patterns over broad areas of interest and lengthy timeframes.",
    "authors": [
      "Adam Van Etten"
    ],
    "url": "http://arxiv.org/abs/2406.06320v1",
    "timestamp": 1718030159,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f97306c5-e343-4949-aa1e-5248c388957f": {
    "pk": "f97306c5-e343-4949-aa1e-5248c388957f",
    "title": "On the structure and diameter of graph associahedra of graphs with a set of true twins",
    "abstract": "Given a graph $G$, the graph associahedron $\\mathcal{A}(G)$ is a polytope whose 1-skeleton is the rotation graph of $G$, that is, the 1-skeleton of $\\mathcal{A}(G)$ is the graph $\\mathcal{R}(G)$ whose vertices are the search trees on $G$ and whose edges correspond to an application of a local operation on the search trees, called rotation. The rotation distance between two search trees on $G$ is the minimum number of rotations needed to transform one of the trees into the other. A challenging question is what is the maximum rotation distance between search trees on a graph, i.e. what is the combinatorial diameter of the corresponding graph associahedron. In this paper we study the relation between the structure of $\\mathcal{R}(G)$ and $\\mathcal{R}(G-S)$ for a particular choice of $S\\subseteq E(G)$. More specifically, we show that if $W$ is a set of true twins in $G$ and $S$ is the set of edges in $G$ with both endpoints in $W$, then $\\mathcal{R}(G-S)$ is a quotient graph of $\\mathcal{R}(G)$. We also give a lower bound for $\\text{diam} (\\mathcal{R}(G-S))$ in terms of $\\text{diam}(\\mathcal{R}(G))$. As a consequence, we obtain a new lower bound for the diameter of the graph associahedra of balanced complete bipartite graphs that allow us to compute the exact value of $\\text{diam}(\\mathcal{R}(K_{2,q}))$ for $q\\in\\{3,4,5,6,7,8\\}$.",
    "authors": [
      "Ana Gargantini",
      "Adri\u00e1n Pastine",
      "Pablo Torres"
    ],
    "url": "http://arxiv.org/abs/2406.06317v1",
    "timestamp": 1718030039,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.CO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "39461b0b-ad3c-4012-bcc4-024fe1a57e0e": {
    "pk": "39461b0b-ad3c-4012-bcc4-024fe1a57e0e",
    "title": "Should my Blockchain Learn to Drive? A Study of Hyperledger Fabric",
    "abstract": "Similar to other transaction processing frameworks, blockchain systems need to be dynamically reconfigured to adapt to varying workloads and changes in network conditions. However, achieving optimal reconfiguration is particularly challenging due to the complexity of the blockchain stack, which has diverse configurable parameters. This paper explores the concept of self-driving blockchains, which have the potential to predict workload changes and reconfigure themselves for optimal performance without human intervention. We compare and contrast our discussions with existing research on databases and highlight aspects unique to blockchains. We identify specific parameters and components in Hyperledger Fabric, a popular permissioned blockchain system, that are suitable for autonomous adaptation and offer potential solutions for the challenges involved. Further, we implement three demonstrative locally autonomous systems, each targeting a different layer of the blockchain stack, and conduct experiments to understand the feasibility of our findings. Our experiments indicate up to 11% improvement in success throughput and a 30% decrease in latency, making this a significant step towards implementing a fully autonomous blockchain system in the future.",
    "authors": [
      "Jeeta Ann Chacko",
      "Ruben Mayer",
      "Hans-Arno Jacobsen"
    ],
    "url": "http://arxiv.org/abs/2406.06318v1",
    "timestamp": 1718030039,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.DC",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "638c2c50-d46b-4c33-a777-ce54b5589fea": {
    "pk": "638c2c50-d46b-4c33-a777-ce54b5589fea",
    "title": "Tx-LLM: A Large Language Model for Therapeutics",
    "abstract": "Developing therapeutics is a lengthy and expensive process that requires the satisfaction of many different criteria, and AI models capable of expediting the process would be invaluable. However, the majority of current AI approaches address only a narrowly defined set of tasks, often circumscribed within a particular domain. To bridge this gap, we introduce Tx-LLM, a generalist large language model (LLM) fine-tuned from PaLM-2 which encodes knowledge about diverse therapeutic modalities. Tx-LLM is trained using a collection of 709 datasets that target 66 tasks spanning various stages of the drug discovery pipeline. Using a single set of weights, Tx-LLM simultaneously processes a wide variety of chemical or biological entities(small molecules, proteins, nucleic acids, cell lines, diseases) interleaved with free-text, allowing it to predict a broad range of associated properties, achieving competitive with state-of-the-art (SOTA) performance on 43 out of 66 tasks and exceeding SOTA on 22. Among these, Tx-LLM is particularly powerful and exceeds best-in-class performance on average for tasks combining molecular SMILES representations with text such as cell line names or disease names, likely due to context learned during pretraining. We observe evidence of positive transfer between tasks with diverse drug types (e.g.,tasks involving small molecules and tasks involving proteins), and we study the impact of model size, domain finetuning, and prompting strategies on performance. We believe Tx-LLM represents an important step towards LLMs encoding biochemical knowledge and could have a future role as an end-to-end tool across the drug discovery development pipeline.",
    "authors": [
      "Juan Manuel Zambrano Chaves",
      "Eric Wang",
      "Tao Tu",
      "Eeshit Dhaval Vaishnav",
      "Byron Lee",
      "S. Sara Mahdavi",
      "Christopher Semturs",
      "David Fleet",
      "Vivek Natarajan",
      "Shekoofeh Azizi"
    ],
    "url": "http://arxiv.org/abs/2406.06316v1",
    "timestamp": 1718029982,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "138aa0b3-7d4c-4754-a199-879083246202": {
    "pk": "138aa0b3-7d4c-4754-a199-879083246202",
    "title": "Topological transition in cyanobacteria: from motion to structure",
    "abstract": "Many active systems are capable of forming intriguing patterns at scales significantly larger than the size of their individual constituents. We recently introduced a model for gliding filamentous cyanobacteria, which form a reticulate pattern as an early-stage biofilm. Our observations reveal that the filaments' bodies follow the track of the head, and are subject to curvature fluctuations, defining a new class of active matter: active spaghetti. By identifying the dominant aspects of the filament's dynamics, our model achieves great computational efficiency, without coarse-graining past the scale of an individual filament. Here, we explore large-scale collective effects and rich dynamics of cyanobacteria colonies, while still retaining information about the individual constituents' dynamics and their interactions. We characterize the system's topological transition from an isotropic distribution to a state of large-scale reticulate patterns by quantifying both dynamical and structural observables. Although it is not a periodic structure, in the steady state the reticulate pattern possesses a well-defined length scale determined by the filaments' Peclet number, which controls the relative importance of activity and curvature fluctuations.",
    "authors": [
      "Jan Cammann",
      "Mixon K. Faluweki",
      "Nayara Dambacher",
      "Lucas Goehring",
      "Marco G. Mazza"
    ],
    "url": "http://arxiv.org/abs/2406.06314v1",
    "timestamp": 1718029926,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cond-mat.soft",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "ddf4a834-f1a2-402e-a4ea-0b03a4146675": {
    "pk": "ddf4a834-f1a2-402e-a4ea-0b03a4146675",
    "title": "NeuroMoCo: A Neuromorphic Momentum Contrast Learning Method for Spiking Neural Networks",
    "abstract": "Recently, brain-inspired spiking neural networks (SNNs) have attracted great research attention owing to their inherent bio-interpretability, event-triggered properties and powerful perception of spatiotemporal information, which is beneficial to handling event-based neuromorphic datasets. In contrast to conventional static image datasets, event-based neuromorphic datasets present heightened complexity in feature extraction due to their distinctive time series and sparsity characteristics, which influences their classification accuracy. To overcome this challenge, a novel approach termed Neuromorphic Momentum Contrast Learning (NeuroMoCo) for SNNs is introduced in this paper by extending the benefits of self-supervised pre-training to SNNs to effectively stimulate their potential. This is the first time that self-supervised learning (SSL) based on momentum contrastive learning is realized in SNNs. In addition, we devise a novel loss function named MixInfoNCE tailored to their temporal characteristics to further increase the classification accuracy of neuromorphic datasets, which is verified through rigorous ablation experiments. Finally, experiments on DVS-CIFAR10, DVS128Gesture and N-Caltech101 have shown that NeuroMoCo of this paper establishes new state-of-the-art (SOTA) benchmarks: 83.6% (Spikformer-2-256), 98.62% (Spikformer-2-256), and 84.4% (SEW-ResNet-18), respectively.",
    "authors": [
      "Yuqi Ma",
      "Huamin Wang",
      "Hangchi Shen",
      "Xuemei Chen",
      "Shukai Duan",
      "Shiping Wen"
    ],
    "url": "http://arxiv.org/abs/2406.06305v1",
    "timestamp": 1718029248,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  }
}